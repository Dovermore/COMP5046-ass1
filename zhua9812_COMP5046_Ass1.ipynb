{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "zhua9812_COMP5046_Ass1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dovermore/COMP5046-ass1/blob/master/zhua9812_COMP5046_Ass1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGHoy6KpQDfZ",
        "colab_type": "text"
      },
      "source": [
        "# COMP5046 Assignment 1\n",
        "*Make sure you change the file name with your unikey.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTf21j_oQIiD",
        "colab_type": "text"
      },
      "source": [
        "# Readme\n",
        "*If there is something to be noted for the user, please mention here.* \n",
        "\n",
        "*If you are planning to implement a program with Object Oriented Programming style*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXbQohXLKSgO",
        "colab_type": "text"
      },
      "source": [
        "***Visualising the comparison of different results is a good way to justify your decision.***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOrzMgW-bxIS",
        "colab_type": "text"
      },
      "source": [
        "## Please run EVERY cell in the object oriented section first"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34DVNKgqQY21",
        "colab_type": "text"
      },
      "source": [
        "# 1 - Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cWUxAQrGlq6",
        "colab_type": "text"
      },
      "source": [
        "## 1.1. Download Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7C4snIcNl22",
        "colab_type": "code",
        "outputId": "ab3e4e33-5c02-45c7-cce8-bd039153518f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Code to download file into Colaboratory:\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "id = '1vF3FqgBC1Y-RPefeVmY8zetdZG1jmHzT'\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('imdb_train.csv')\n",
        "\n",
        "id = '1XhaV8YMuQeSwozQww8PeyiWMJfia13G6'\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('imdb_test.csv')\n",
        "\n",
        "import pandas as pd\n",
        "df_train = pd.read_csv(\"imdb_train.csv\")\n",
        "df_test = pd.read_csv(\"imdb_test.csv\")\n",
        "\n",
        "reviews_train = df_train['review'].tolist()\n",
        "sentiments_train = df_train['sentiment'].tolist()\n",
        "reviews_test = df_test['review'].tolist()\n",
        "sentiments_test = df_test['sentiment'].tolist()\n",
        "\n",
        "print(\"Training set number:\",len(reviews_train))\n",
        "print(\"Testing set number:\",len(reviews_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training set number: 25000\n",
            "Testing set number: 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9gBSgBCQh24",
        "colab_type": "text"
      },
      "source": [
        "## 1.2. Preprocess data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8RdKI8E2KRwe",
        "colab_type": "text"
      },
      "source": [
        "*You are required to describe which data preprocessing techniques were conducted with justification of your decision. *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9J9jBjDj4WUY",
        "colab_type": "text"
      },
      "source": [
        "#### Observe raw distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHJXylptbOqx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def check_preprocessing_step(reviews):\n",
        "    null_params = ((\"rm_htmltag\",False), (\"expand_contraction\",True), (\"to_lower\",True), \n",
        "                   (\"rm_punctuation\",False), (\"cv_numbers\",False), (\"rm_accents\",False),\n",
        "                   (\"stop_words\",[]), (\"lemmatize\",False), (\"min_count\",0))\n",
        "    steps_tokens = {}\n",
        "    for i in range(len(processing_steps)+1):\n",
        "        # Convert to params\n",
        "        kwargs = dict(null_params[i:])\n",
        "        # Add each training step and check statistics\n",
        "        tokens = preprocess_texts(reviews, **kwargs)\n",
        "        steps = tuple(a for a, v in null_params[:i])\n",
        "        # Pair of processing steps applied/result tokens\n",
        "        steps_tokens[i] = (steps, tokens)\n",
        "    return steps_tokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tQn9d2wNvft0",
        "outputId": "9df95c10-5646-4855-b1f1-e2704132ddee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "raw_tokens = preprocess_texts(reviews_train, rm_htmltag=False, expand_contraction=False, \n",
        "                              to_lower=False, rm_punctuation=False, cv_numbers=False,\n",
        "                              stop_words=False, lemmatize=False, min_count=1)\n",
        "show_token_stats(raw_tokens)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "134450\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51JQ_tLI4cDQ",
        "colab_type": "text"
      },
      "source": [
        "#### Observe processed Distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtWPqYLL4ak0",
        "colab_type": "code",
        "outputId": "549a245e-ac55-4755-de2c-5376c1a70130",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "processed_tokens = preprocess_texts(reviews_train, min_count=5)\n",
        "show_token_stats(processed_tokens)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25365\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcGFbmqUog4E",
        "colab_type": "code",
        "outputId": "6c27b29f-bbb2-4cd6-c983-cdf467cc68c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "tpt = TextPreprocessTransformer()\n",
        "tokens_train = tpt.fit_transform(reviews_train)\n",
        "tokens_test = tpt.transform(reviews_test)\n",
        "\n",
        "total_len_train = 0\n",
        "for tokens in tokens_train:\n",
        "    total_len_train += len(tokens)\n",
        "\n",
        "total_len_test = 0\n",
        "for tokens in tokens_test:\n",
        "    total_len_test += len(tokens)\n",
        "\n",
        "print(tokens_train[:2])\n",
        "print(tokens_test[:2])\n",
        "\n",
        "print(total_len_train)\n",
        "print(total_len_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['enjoyed', 'movie', 'not', 'seen', 'andy', 'griffith', 'age', 'felt', 'fit', 'role', 'perfectly', 'associated', 'comedy', 'but', 'pleased', 'see', 'versatile', 'not', 'troubled', 'dotty', 'anxiety', 'disorder', 'may', 'not', 'verbatim', 'psychiatric', 'textbook', 'zillion', 'whatever', 'phobia', 'neurosis', 'broad', 'variety', 'form', 'clearly', 'sensitive', 'extra', 'sensory', 'power', 'understood', 'local', 'indian', 'but', 'not', 'anglos', 'not', 'surprising', 'character', 'vulnerable', 'eccentric', 'although', 'taken', 'light', 'family', 'movie', 'actually', 'sophisticated', 'seems', 'twist', 'came', 'pleasant', 'surprise', 'tied', 'preceding', 'action', 'together', 'bundle', 'fun', 'contemplate', 'possibility', 'spiritual', 'guidance'], ['whole', 'not', 'even', 'close', 'sum', 'part', 'no', 'problem', 'film', 'feature', 'line', 'creative', 'director', 'time', 'really', 'famous', 'name', 'cast', 'segment', 'devised', 'around', 'theme', 'love', 'paris', 'but', 'resemblance', 'end', 'actually', 'considering', 'approach', 'theme', 'different', 'director', 'take', 'many', 'form', 'amazing', 'even', 'feel', 'still', 'watching', 'film', 'no', 'great', 'effort', 'made', 'turn', 'comprehensive', 'whole', 'many', 'great', 'ingredient', 'glad', 'nobody', 'tried', 'put', 'single', 'dish']]\n",
            "[['course', 'going', 'think', 'great', 'movie', 'recognized', 'several', 'people', 'not', 'see', 'filming', 'playing', 'guard', 'hour', 'movie', 'death', 'row', 'exercise', 'yard', 'asking', 'light', 'cigarette', 'changed', 'scene', 'originally', 'set', 'go', 'rec', 'yard', 'straighten', 'inmate', 'turn', 'around', 'walk', 'director', 'said', 'taking', 'long', 'would', 'said', 'need', 'go', 'hook', 'arm', 'drag', 'backwards', 'way', 'camera', 'stay', 'set', 'lived', 'prison', 'young', 'child', 'father', 'assistant', 'warden', 'security', 'current', 'employee', 'tennessee', 'correction', 'supervisor', 'maximum', 'security', 'institution', 'even', 'though', 'lot', 'movie', 'joke', 'part', 'reality', 'enough', 'bar', 'scene', 'dancer', 'kicking', 'high', 'air', 'leaving', 'stage', 'actual', 'stripper', 'use', 'work', 'club', 'called', 'classic'], ['never', 'understood', 'type', 'spoof', 'movie', 'get', 'serious', 'semi', 'serious', 'movie', 'everyone', 'know', 'take', 'seriousness', 'immature', 'fart', 'joke', 'seen', 'many', 'many', 'time', 'never', 'really', 'funny', 'easy', 'way', 'laugh', 'something', 'not', 'understand', 'opinion', 'seems', 'obscure', 'le', 'liked', 'genre', 'though', 'honestly', 'not', 'see', 'anything', 'much', 'worse', 'spy', 'hard', 'hot', 'shot', 'movie', 'clearly', 'understood', 'simply', 'title', 'concentrate', 'making', 'childish', 'fun', 'pulp', 'fiction', 'main', 'reason', 'decided', 'watch', 'found', 'film', 'overly', 'indulgent', 'tarantino', 'sick', 'mind', 'powerfully', 'overrated', 'hoped', 'two', 'good', 'joke', 'making', 'fun', 'overly', 'violent', 'pointless', 'type', 'movie', 'pulp', 'fiction', 'every', 'aspect', 'anything', 'but', 'humble', 'opinion', 'sorely', 'disappointed', 'plot', 'pretty', 'much', 'rip', 'tarantino', 'film', 'scene', 'spoofing', 'often', 'better', 'film', 'childish', 'humorless', 'fashion', 'pacing', 'poor', 'often', 'able', 'guess', 'outcome', 'every', 'scene', 'predicting', 'every', 'joke', 'often', 'thinking', 'better', 'spot', 'bored', 'mind', 'acting', 'bad', 'character', 'cliche', 'stereotype', 'intentionally', 'paper', 'thin', 'order', 'make', 'fun', 'character', 'based', 'problem', 'not', 'work', 'make', 'movie', 'much', 'harder', 'humor', 'juvenile', 'lame', 'positive', 'thing', 'say', 'film', 'managed', 'find', 'actor', 'looked', 'like', 'people', 'supposed', 'look', 'like', 'film', 'awful', 'waste', 'actual', 'real', 'actor', 'involved', 'possibly', 'slightly', 'entertaining', 'fan', 'typical', 'spoof', 'movie', 'kind', 'recommend', 'people', 'truly', 'loathed', 'pulp', 'fiction', 'fan', 'zucker', 'parody', 'film', 'everyone', 'else', 'avoid', '1', '2num']]\n",
            "2985185\n",
            "2912866\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bi9n4bYwondw",
        "colab_type": "code",
        "outputId": "5513db5a-e022-4fd6-f7d2-ccd73b69e6ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(sorted(list(set(sentiments_train))))\n",
        "label_train = label_encoder.transform(sentiments_train)\n",
        "label_test = label_encoder.transform(sentiments_test)\n",
        "print(label_train[:50])\n",
        "print(label_test[:50])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 1 1 0 0 0 1 1 0 0 0 0 1 1 0 0 1 0 0 0 0 1 0 1 0 0 1 1 1 1 0 1 0 0 0 0 0\n",
            " 0 0 0 0 1 1 0 0 1 0 0 1 1]\n",
            "[1 0 0 0 0 0 1 1 0 1 0 1 0 1 1 0 0 1 1 1 0 1 1 0 1 1 0 0 0 1 1 0 1 0 0 1 0\n",
            " 1 1 1 0 0 0 0 1 0 0 0 1 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AgZ1ozZiI3L_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save processed data\n",
        "save_feather(tokens_train, label_train, sentiments_train, train_path)\n",
        "save_feather(tokens_test, label_test, sentiments_test, test_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gB8pPuMAVP7g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load from processed data\n",
        "tokens_train, label_train, sentiments_train = load_feather(train_path)\n",
        "tokens_test, label_test, sentiments_test = load_feather(test_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NAYv0ThQVhlY"
      },
      "source": [
        "# 2 - Model Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "daDvAftceIvr",
        "colab_type": "text"
      },
      "source": [
        "## 2.1. Word Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbzm-NWBTmM-",
        "colab_type": "text"
      },
      "source": [
        "*You are required to describe which model was implemented (i.e. Word2Vec with CBOW, FastText with SkipGram, etc.) with justification of your decision *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXgFpxIgl-_G",
        "colab_type": "text"
      },
      "source": [
        "### 2.1.1. Data Preprocessing for Word Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJrVHGYSmYMg",
        "colab_type": "text"
      },
      "source": [
        "*You are required to describe which preprocessing techniques were used with justification of your decision.*\n",
        "\n",
        "**Important**: If you are going to use the code from lab3 word2vec preprocessing. Please note that `word_list = list(set(word_list)) ` has randomness. So to make sure the word_list is the same every time you run it, you can put `word_list.sort()` after that line of code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbUw3gEwGqa7",
        "colab_type": "code",
        "outputId": "cf308c67-ff3b-479a-fc18-2f3a7af45194",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Profile sample time with training data\n",
        "sgt = VocabSkipGramTransformer(drop_prob=0)\n",
        "sgt.fit(tokens_train)\n",
        "datagen = sgt.generator(tokens_train)\n",
        "%timeit -n 1000 next(datagen)\n",
        "datagen = sgt.generator(tokens_train, algorithm=2)\n",
        "%timeit -n 1000 next(datagen)\n",
        "datagen = sgt.generator(tokens_train, algorithm=3)\n",
        "%timeit -n 1000 next(datagen)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000 loops, best of 3: 1.06 ms per loop\n",
            "1000 loops, best of 3: 764 µs per loop\n",
            "1000 loops, best of 3: 1.8 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhAgWf_AmbZ8",
        "colab_type": "text"
      },
      "source": [
        "### 2.1.2. Build Word Embeddings Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJ8rU7JbiBVS",
        "colab_type": "text"
      },
      "source": [
        "*You are required to describe how hyperparameters were decided with justification of your decision.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZiCbqdxA4lgV",
        "colab_type": "code",
        "outputId": "74367674-7393-4754-f179-f97a7cf59d77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 928
        }
      },
      "source": [
        "test_w2v_model = make_w2v_model(X=toy_num_data, embedding_dim=2, \n",
        "                                window=3, ckpt_base=\"test_w2v\", addtime=True)\n",
        "datagen = test_w2v_model.data_generator(toy_num_data, batch_size=2)\n",
        "print(next(datagen))\n",
        "# Before\n",
        "vocab_list = test_w2v_model.data_transformer.token_list\n",
        "plot_annotate(*list(zip(*test_w2v_model.net.embedding.weight.detach().numpy())), vocab_list)\n",
        "plt.show()\n",
        "test_w2v_model.train(train_data=toy_num_data, epochs=500, batch_size=2, \n",
        "                     batch_display_interval=0, epoch_display_interval=100, ckpt_interval=100)\n",
        "# After\n",
        "test_w2v_model.load_model()\n",
        "# Overfit the small dataset\n",
        "plot_annotate(*list(zip(*test_w2v_model.net.embedding.weight.detach().numpy())), vocab_list)\n",
        "plt.show()\n",
        "# I think this works?"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(tensor([3, 7]), tensor([1, 6]), False)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "Saving net to:  /content/drive/My Drive/COMP5046-assignment1/test_w2v04140916/model0.pt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type W2VSkipGramNet. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(0m 9s) Epoch: 100, batch: 11700, loss: 2.2704\n",
            "best\n",
            "Saving net to:  /content/drive/My Drive/COMP5046-assignment1/test_w2v04140916/modelbest.pt\n",
            "1\n",
            "Saving net to:  /content/drive/My Drive/COMP5046-assignment1/test_w2v04140916/model1.pt\n",
            "(0m 18s) Epoch: 200, batch: 23400, loss: 2.2241\n",
            "2\n",
            "Saving net to:  /content/drive/My Drive/COMP5046-assignment1/test_w2v04140916/model2.pt\n",
            "(0m 27s) Epoch: 300, batch: 35100, loss: 2.2207\n",
            "3\n",
            "Saving net to:  /content/drive/My Drive/COMP5046-assignment1/test_w2v04140916/model3.pt\n",
            "(0m 36s) Epoch: 400, batch: 46800, loss: 2.2204\n",
            "4\n",
            "Saving net to:  /content/drive/My Drive/COMP5046-assignment1/test_w2v04140916/model4.pt\n",
            "(0m 45s) Epoch: 500, batch: 58500, loss: 2.2194\n",
            "5\n",
            "Saving net to:  /content/drive/My Drive/COMP5046-assignment1/test_w2v04140916/model5.pt\n",
            "Loading net from:  /content/drive/My Drive/COMP5046-assignment1/test_w2v04140916/model5.pt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qiTm0V7Jvii",
        "colab_type": "code",
        "outputId": "649dcbe4-a427-46a7-e5b7-9d9f41e659ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "test_embedding_dim = 6\n",
        "test_window = 3\n",
        "perplexity = 3\n",
        "test_w2v_model = make_w2v_model(X=toy_data, embedding_dim=test_embedding_dim, \n",
        "                                window=test_window, ckpt_base=\"test_w2v\", addtime=True)\n",
        "_ = plot_w2v_topk(test_w2v_model, toy_data, method=\"TSNE\", k=100, perplexity=perplexity)\n",
        "# _ = plot_w2v_topk(test_w2v_model, toy_data, method=\"PCA\", k=100)\n",
        "# vocab_list = test_w2v_model.data_transformer.token_list\n",
        "# plot_annotate(*list(zip(*test_w2v_model.net.embedding.weight.detach().numpy())), vocab_list)\n",
        "# plt.show()\n",
        "test_w2v_model.train(train_data=toy_data, epochs=2000, batch_display_interval=50)\n",
        "_ = plot_w2v_topk(test_w2v_model, toy_data, method=\"TSNE\", k=100, perplexity=perplexity)\n",
        "# _ = plot_w2v_topk(test_w2v_model, toy_data, method=\"PCA\", k=100)\n",
        "# vocab_list = test_w2v_model.data_transformer.token_list\n",
        "# plot_annotate(*list(zip(*test_w2v_model.net.embedding.weight.detach().numpy())), vocab_list)\n",
        "# plt.show()\n",
        "\n",
        "\n",
        "# Negative words seems to have clustered together"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAHSCAYAAADFbUO+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3de5xVdb3/8deXS4CCDAYpIgkYKrdh0EEoAjRM0C5oQnIERTHJo6TZ0XPwaElX6xd5jTQvpBYmBl5QK0nMIxoGQw13CLDxAhgIDoJcZOD7+2M206CD3GZmz3fm9Xw89mP2+qy11/58hz28Z6393WtCjBFJkpSOetluQJIkHRjDW5KkxBjekiQlxvCWJCkxhrckSYkxvCVJSkyDbDewv1q2bBnbtWuX7TYkSaoWc+fOfTvG2KqidYcc3iGEtsBDwFFABO6JMd4eQjgSmAy0A4qAr8YY3wkhBOB24GxgC3BxjPFv+3qedu3aUVBQcKjtSpKUhBDCa3tbVxmnzUuA/4oxdgZ6A1eGEDoDY4EZMcaOwIzMMsBZQMfMbTRwVyX0IElSnXHI4R1jXLP7yDnGuAlYArQBBgMPZjZ7EDgnc38w8FAs9QqQE0Jofah9SJJUV1TqhLUQQjugB/BX4KgY45rMqrcoPa0OpcH+RrmHvZmpVbS/0SGEghBCwbp16yqzVUmSklVp4R1CaApMBb4ZY3y3/LpYegH1A76Ieozxnhhjfowxv1WrCt+zlySpzqmU8A4hNKQ0uCfFGB/LlP+1+3R45uvaTH0V0Lbcw4/N1CRJ0n445PDOzB6/H1gSY7yl3KppwMjM/ZHAk+XqF4VSvYGN5U6vS5KkfaiMI+8+wIXA50IIhZnb2cCPgc+HEJYDZ2SWAX4PvAqsAO4FrqiEHiRJOmh33303Dz30EAAPPPAAq1evLlv3ta99jcWLF2ertQqFVP6ed35+fvRz3pKkqnbaaacxfvx48vPzs9pHCGFujLHCJrw8qiQpaUVFRZx00kkMHz6cTp06MWTIELZs2cKMGTPo0aMH3bp1Y9SoUWzfvh2AsWPH0rlzZ3Jzc7n22msBGDduHOPHj2fKlCkUFBQwfPhw8vLy2Lp1K6eddhoFBQXcfffdXHfddWXP+8ADDzBmzBgAfvOb33DqqaeSl5fH17/+dXbu3FmlYza8JUnJW7ZsGVdccQVLlizhiCOO4JZbbuHiiy9m8uTJLFiwgJKSEu666y7Wr1/P448/zqJFi5g/fz433njjHvsZMmQI+fn5TJo0icLCQpo0aVK27rzzzuPxxx8vW548eTLDhg1jyZIlTJ48mZdffpnCwkLq16/PpEmTqnS8hrckKXlt27alT58+AIwYMYIZM2bQvn17TjjhBABGjhzJiy++SPPmzWncuDGXXnopjz32GIcddth+P0erVq3o0KEDr7zyCuvXr2fp0qX06dOHGTNmMHfuXHr27EleXh4zZszg1VdfrZJx7pbMHyaRJGlvSj/49G85OTmsX7/+Q9s1aNCA2bNnM2PGDKZMmcLPf/5znn/++f1+nmHDhvHoo49y0kknce655xJCIMbIyJEjufnmmw95HPvLI29JUvJef/11Zs2aBcDDDz9Mfn4+RUVFrFixAoBf//rX9O/fn82bN7Nx40bOPvtsbr31VubNm/ehfTVr1oxNmzZV+DznnnsuTz75JL/97W8ZNmwYAAMGDGDKlCmsXVt6OZMNGzbw2mt7/ZsilcIjb0lS8k488UQmTJjAqFGj6Ny5M3fccQe9e/dm6NChlJSU0LNnTy6//HI2bNjA4MGD2bZtGzFGbrnllg/t6+KLL+byyy+nSZMmZb8Q7NaiRQs6derE4sWLOfXUUwHo3LkzP/jBDzjzzDPZtWsXDRs2ZMKECRx33HFVNl4/KiZJSlpRURFf/OIXWbhwYbZbqVR+VEySpCqy8amnWP65ASzp1JnlnxvAxqeeqvLn9LS5JClp7dq1y9pR98annmLNt79D3LYNgJLVq1nz7e8A0PxLX6qy5/XIW5Kkg7T21tvKgnu3uG0ba2+9rUqf1/CWJOkglayp+O9q7a1eWQxvSZIOUoPWrQ+oXlkMb0mSDtInrvkmoXHjPWqhcWM+cc03q/R5nbAmSdJB2j0pbe2tt1GyZg0NWrfmE9d8s0onq4HhLUnSIWn+pS9VeVh/kKfNJUlKjOEtSVJiDG9JkhJjeEuSlBjDW5KkxBjekiQlxvCWJCkxhrckSYkxvCVJSozhLUlSYgxvSZISY3hLkpQYw1uSpMQY3pIkJcbwliQpMYa3JEmJMbwlSUqM4S1JUmIMb0mSEmN4S5KUGMNbkqTEGN6SJCXG8JYkKTGGtyRJiTG8JUlKjOEtSVJiDG9JkhJjeEuSlBjDW5KkxBjekiQlxvCWJCkxhrckSYmplPAOIUwMIawNISwsVxsXQlgVQijM3M4ut+76EMKKEMKyEMLAyuhBkqS6orKOvB8ABlVQvzXGmJe5/R4ghNAZGAZ0yTzmFyGE+pXUhyRJtV6lhHeM8UVgw35uPhh4JMa4Pcb4T2AFcGpl9CFJEkBRURFdu3at9sdWl6p+z3tMCGF+5rR6i0ytDfBGuW3ezNQkSdJ+qMrwvgs4HsgD1gA/O9AdhBBGhxAKQggF69atq+z+JEm1WElJCcOHD6dTp04MGTKELVu28L3vfY+ePXvStWtXRo8eTYwRgLlz59K9e3e6d+/OhAkTstz5vlVZeMcY/xVj3Blj3AXcy79Pja8C2pbb9NhMraJ93BNjzI8x5rdq1aqqWpUk1ULLli3jiiuuYMmSJRxxxBH84he/YMyYMcyZM4eFCxeydetWnn76aQAuueQS7rzzTubNm5flrvdPlYV3CKF1ucVzgd0z0acBw0IIjUII7YGOwOyq6kOSVDe1bduWPn36ADBixAheeukl/vznP9OrVy+6devG888/z6JFiyguLqa4uJh+/foBcOGFF2az7f3SoDJ2EkL4LXAa0DKE8CZwE3BaCCEPiEAR8HWAGOOiEMKjwGKgBLgyxrizMvqQJGm3EMKHlq+44goKCgpo27Yt48aNY9u2bVnq7tBU1mzz/4gxto4xNowxHhtjvD/GeGGMsVuMMTfG+OUY45py2/8wxnh8jPHEGOMfKqMHSZLKe/3115k1axYADz/8MJ/97GcBaNmyJZs3b2bKlCkA5OTkkJOTw0svvQTApEmTstPwAaiUI29JkmqaE088kQkTJjBq1Cg6d+7Mf/7nf/LOO+/QtWtXjj76aHr27Fm27a9+9StGjRpFCIEzzzwzi13vn7B7pl1Nl5+fHwsKCrLdhiRJ1SKEMDfGmF/ROo+8JUl12vz585kxYwYbN26kefPmDBgwgNzc3Gy39ZEMb0lSnTV//nyeeuopduzYAcDGjRt56qmnAGp0gPtXxSRJddaMGTPKgnu3HTt2MGPGjCx1tH8Mb0lSnbVx48YDqtcUhrckqc5q3rz5AdVrCsNbklRnDRgwgIYNG+5Ra9iwIQMGDMhSR/vHCWuSpDpr96Q0Z5tLkpSQ3NzcGh/WH+Rpc0mSEmN4S5KUGMNbkqTEGN6SJCXG8JYkKTGGtyRJiTG8JUlKjOEtSVJiDG9JkhJjeEuSlBjDW5KkxBjekiQlxvCWJCkxhrckSYkxvCVJSozhLUlSYgxvSZISY3hLkpQYw1uSpMQY3pIkJcbwliQpMYa3JEmJMbwlSUqM4S1JUmIMb0mSEmN4S5KUGMNbkqTEGN6SJCXG8JYkKTGGdy32wAMPsHr16my3IUmqZIZ3LWZ4S1LtZHgnpKioiE6dOnHZZZfRpUsXzjzzTLZu3UphYSG9e/cmNzeXc889l3feeYcpU6ZQUFDA8OHDycvLY+vWrdluX5JUSQzvxCxfvpwrr7ySRYsWkZOTw9SpU7nooov4yU9+wvz58+nWrRvf/e53GTJkCPn5+UyaNInCwkKaNGmS7dYlSZXE8E5M+/btycvLA+CUU05h5cqVFBcX079/fwBGjhzJiy++mM0WJUlVzPBOTKNGjcru169fn+Li4ix2I0nKBsM7cc2bN6dFixbMnDkTgF//+tdlR+HNmjVj06ZN2WxPklQFGmS7AR26Bx98kMsvv5wtW7bQoUMHfvWrXwFw8cUXc/nll9OkSRNmzZrl+96SVEuEGGO2e9gv+fn5saCgINtt1GjPvPoMt//tdt567y2OPvxorj75ar7Q4QvZbkuSdBBCCHNjjPkVrauU0+YhhIkhhLUhhIXlakeGEP4UQlie+doiUw8hhDtCCCtCCPNDCCdXRg913TOvPsO4v4xjzXtriETWvLeGcX8ZxzOvPpPt1iRJlayy3vN+ABj0gdpYYEaMsSMwI7MMcBbQMXMbDdxVST3Uabf/7Xa27dy2R23bzm3c/rfbs9SRJKmqVEp4xxhfBDZ8oDwYeDBz/0HgnHL1h2KpV4CcEELryuijLnvrvbcOqC5JSldVzjY/Ksa4JnP/LeCozP02wBvltnszU9MhOPrwow+oLklKV7V8VCyWzoo74JlxIYTRIYSCEELBunXrqqCz2uPqk6+mcf3Ge9Qa12/M1SdfnaWOJElVpSrD+1+7T4dnvq7N1FcBbcttd2ym9iExxntijPkxxvxWrVpVYavp+0KHLzDuM+NofXhrAoHWh7dm3GfGOdtckmqhqvyc9zRgJPDjzNcny9XHhBAeAXoBG8udXtch+EKHLxjWklQHVEp4hxB+C5wGtAwhvAncRGloPxpCuBR4DfhqZvPfA2cDK4AtwCWV0YMkSXVFpYR3jPE/9rJqQAXbRuDKynheSZLqIq9tLklSYgxvSZISY3hLkpQYw1uSpMQY3pIkJcbwliQpMYa3JEmJMbwlSUqM4S1JUmIMb0mSEmN4S5KUGMNbkqTEGN6SJCXG8JYkKTGGtyRJiTG8JUlKjOEtSVJiDG9JkhJjeEuSlBjDW5KkxBjekiQlxvCWJCkxhrckSYkxvFVrlZSUZLsFSaoShrdqnKKiIk466SQuvvhiTjjhBIYPH85zzz1Hnz596NixI7Nnz2bDhg2cc8455Obm0rt3b+bPnw/AuHHjuPDCC+nTpw8XXngh69at47zzzqNnz5707NmTl19+Ocujk6RD1yDbDUgVWbFiBb/73e+YOHEiPXv25OGHH+all15i2rRp/OhHP6Jt27b06NGDJ554gueff56LLrqIwsJCABYvXsxLL71EkyZNuOCCC7jmmmv47Gc/y+uvv87AgQNZsmRJlkcnSYfG8FaN1L59e7p16wZAly5dGDBgACEEunXrRlFREa+99hpTp04F4HOf+xzr16/n3XffBeDLX/4yTZo0AeC5555j8eLFZft999132bx5M02bNq3mEUlS5TG8VSM1atSo7H69evXKluvVq0dJSQkNGzbc62MPP/zwsvu7du3ilVdeoXHjxlXXrCRVM9/zVpL69u3LpEmTAHjhhRdo2bIlRxxxxIe2O/PMM7nzzjvLlnefWpeklBneStK4ceOYO3cuubm5jB07lgcffLDC7e644w4KCgrIzc2lc+fO3H333dXcqSRVvhBjzHYP+yU/Pz8WFBRkuw0l5L2/r+XdZ4vYWbyd+jmNOGJgOw7v8YlstyVJ+yWEMDfGmF/ROt/zVq303t/XUvzYcuKOXQDsLN5O8WPLAQxwScnztLlqpXefLSoL7t3ijl28+2xRdhqSpEpkeKtW2lm8/YDqkpQSw1u1Uv2cRgdUl6SUGN6qlY4Y2I7QcM+Xd2hYjyMGtstOQ5JUiZywplpp96Q0Z5tLqo0Mb9Vah/f4hGEtqVbytLkkSYkxvCVJSozhLUlSYgxvSZISY3hLkpQYw1uSpMQY3pIkJcbwliQpMYa3JEmJMbwlSUpMlV8eNYRQBGwCdgIlMcb8EMKRwGSgHVAEfDXG+E5V9yJJUm1QXUfep8cY82KM+ZnlscCMGGNHYEZmWZIk7YdsnTYfDDyYuf8gcE6W+pAkKTnVEd4RmB5CmBtCGJ2pHRVjXJO5/xZwVDX0IUlSrVAdfxL0szHGVSGETwB/CiEsLb8yxhhDCLGiB2bCfjTAJz/5yarvVJKkBFT5kXeMcVXm61rgceBU4F8hhNYAma9r9/LYe2KM+THG/FatWlV1q5IkJaFKwzuEcHgIodnu+8CZwEJgGjAys9lI4Mmq7EOSpNqkqk+bHwU8HkLY/VwPxxj/GEKYAzwaQrgUeA34ahX3IUlSrVGl4R1jfBXoXkF9PTCgKp9bkqTayiusSZKUGMNbkqTEGN6SJCXG8JYkKTGGtyRJiTG8JUlKjOEtSVJiDG9JkhJjeEuSlBjDW5KkxBjekiQlxvCWJCkxhrckSYkxvCVJSozhLUlSYgxvSZISY3hLkpQYw1uSpMQY3pIkJcbwliQpMYa3JEmJMbwlSUqM4S1JUmIMb0mSEmN4S5KUGMNbkqTEGN6SJCXG8JYkKTGGtyRJiTG8JUlKjOEtSVJiDG9JkhJjeEu1QFFREV27ds12G5KqieEtqVpV9S8aRUVFPPzww2XLBQUFXHXVVQBs376dM844g7y8PCZPnrzXfTzwwAOMGTOmynqUDlWDbDcg1UXf//73+c1vfkOrVq1o27Ytp5xyCmeccQaXX345W7Zs4fjjj2fixIm0aNGCwsLCCutz585l1KhRAJx55plZHlHNsTu8L7jgAgDy8/PJz88H4O9//zsAhYWFWetPqgweeUvVbM6cOUydOpV58+bxhz/8gYKCAgAuuugifvKTnzB//ny6devGd7/73Y+sX3LJJdx5553Mmzcva2M5WCUlJQwfPpxOnToxZMgQtmzZwty5c+nfvz+nnHIKAwcOZM2aNQDce++99OzZk+7du3PeeeexZcsWAC6++GKmTJlSts+mTZsCMHbsWGbOnEleXh633norL7zwAl/84hdZu3YtI0aMYM6cOeTl5bFy5UratWvH22+/DZQeoZ922mnV+42QDpLhLVWzl19+mcGDB9O4cWOaNWvGl770Jd577z2Ki4vp378/ACNHjuTFF19k48aNFdaLi4spLi6mX79+AFx44YVZG8/BWLZsGVdccQVLlizhiCOOYMKECXzjG99gypQpZWcUbrjhBgC+8pWvMGfOHObNm0enTp24//77P3LfP/7xj+nbty+FhYVcc801ZfVPfOIT3HfffWXrjj/++Codo1SVPG0uqdq1bduWPn36ADBixAh+9KMfsXDhQj7/+c8DsHPnTlq3bg3AwoULufHGGykuLmbz5s0MHDgwa31LNYVH3lI169OnD0899RTbtm1j8+bNPP300xx++OG0aNGCmTNnAvDrX/+a/v3707x58wrrOTk55OTk8NJLLwEwadKkrI3nYIQQ9lhu1qwZXbp0obCwkMLCQhYsWMD06dOB0tPjP//5z1mwYAE33XQT27ZtA6BBgwbs2rULgF27dvH+++8fcB/l97F7v1IKDG+pmvXs2ZMvf/nL5ObmctZZZ9GtWzeaN2/Ogw8+yHXXXUdubi6FhYV85zvfAdhr/Ve/+hVXXnkleXl5xBizOaQD9vrrrzNr1iwAHn74YXr37s26devKajt27GDRokUAbNq0idatW7Njx449fklp164dc+fOBWDatGns2LEDKP1FYNOmTfvVR/l9TJ06tXIGJ1UDT5tLWXDttdcybtw4tmzZQr9+/TjllFPIy8vjlVde+dC2e6s3K2nDt77wCzZv2E7TBo342v3fqo7WK8WJJ57IhAkTGDVqFJ07d+Yb3/gGAwcO5KqrrmLjxo2UlJTwzW9+ky5duvD973+fXr160apVK3r16lUWzJdddhmDBw+me/fuDBo0iMMPPxyA3Nxc6tevT/fu3bn44ovp0aPHXvu46aabuPTSS/n2t7/tZDUlJaTyG3t+fn7cPStXSt0FF1zA4sWL2bZtGyNHjuT6668/oMf/469v8edJSyl5f1dZrcHH6nH68JM4odfRld1urbdk5p+Z+chDbFr/Ns0+3pK+wy6iU9/Ts92W6rgQwtwYY35F6zzylrKg/EVEDsasJ1fuEdwAJe/vYtaTKw3vA7Rk5p+Zfs/PKXl/OwCb3l7H9Ht+DmCAq8byPW8pQZs3bD+guvZu5iMPlQX3biXvb2fmIw9lqSNp3wxvKUFNj2x0QHXt3ab1bx9QXaoJDG8pQZ8efDwNPrbnj2+Dj9Xj04O98MiBavbxlgdUl2oCw1tK0Am9jub04SeVHWk3PbKRk9UOUt9hF9HgY3uesWjwsUb0HXZRljqS9i1rE9ZCCIOA24H6wH0xxh9nqxcpRSf0OtqwrgS7J6U521wpyUp4hxDqAxOAzwNvAnNCCNNijIuz0Y+kuq1T39MNayUlW6fNTwVWxBhfjTG+DzwCDM5SL5IkJSVb4d0GeKPc8puZmiRJ2ocaPWEthDA6hFAQQihYt25dttuRJKlGyFZ4rwLalls+NlPbQ4zxnhhjfowxv1WrVtXWnCRJNVm2wnsO0DGE0D6E8DFgGDAtS71IkpSUrMw2jzGWhBDGAM9S+lGxiTHGRdnoRZKk1GTtc94xxt8Dv8/W80uSlKoaPWFNkiR9mOEtSVJialx4hxDuCyF0PpjHrl69miFDhlR2S5Ik1Sg1LrxjjF872MukHnPMMUyZMqWyW1IWvfDCC3zxi1/MdhuSVKNkNbxDCIeHEJ4JIcwLISwMIZwfQnghhJCfWb85hPDDEMK8pUuX8q9//QuAlStX0rt3b7p168aNN95I06ZNASgqKqJr164APPDAA3zlK19h0KBBdOzYkf/+7/8ue97777+fE044gVNPPZXLLruMMWPGVPfQJUk6aNk+8h4ErI4xdo8xdgX++IH1hwOvxBi7N23alHvvvReAq6++mquvvpoFCxZw7LHH7nXnhYWFTJ48mQULFjB58mTeeOMNVq9ezfe//31eeeUVXn75ZZYuXVpVY1MFyv+CBTB+/HjGjRvHnDlzyM3NJS8vj+uuu26PbQB27dpFx44d2X2lvV27dvGpT30Kr7wnqS7KdngvAD4fQvhJCKFvjHHjB9a/DzwNcNhhh1FUVATArFmzGDp0KAAXXHDBXnc+YMAAmjdvTuPGjencuTOvvfYas2fPpn///hx55JE0bNiwbD/KrksuuYRf/vKXFBYWUr9+/Q+tr1evHiNGjGDSpEkAPPfcc3Tv3h2vvCepLspqeMcY/wGcTGmI/yCE8J0PbLIjxhgBQgiUlJQc0P4bNWpUdr9+/foH/HhVj+LiYjZt2sSnP/1pYO+/kI0aNYqHHnoIgIkTJ3LJJZdUW4+SVJNk+z3vY4AtMcbfAD+lNMj3qXfv3kydOhWARx555ICes2fPnvzf//0f77zzDiUlJWX7UfVo0KABu3btKlvetm3bfj+2bdu2HHXUUTz//PPMnj2bs846qypalKQaL9unzbsBs0MIhcBNwA/250G33XYbt9xyC7m5uaxYsYLmzZvv9xO2adOG//3f/+XUU0+lT58+tGvX7oAer0Nz1FFHsXbtWtavX8/27dt5+umnycnJoVmzZvz1r38FPvoXsq997WuMGDGCoUOHVnh6XZLqgpA5K13j5efnx4KCAgC2bNlCkyZNCCHwyCOP8Nvf/pYnn3xyv/e1efNmmjZtSklJCeeeey6jRo3i3HPPrarW9QF33HEHt99+O23atKFDhw60a9eOs846i8suu4x69erRv39/CgoKePnll3nhhRcYP348Tz/9NAA7duzg4x//OLNnz+akk07K8kgkqeqEEObGGPMrXJdieM+cOZMxY8YQYyQnJ4eJEyfyqU99ar/288TfV3Hl1dewblkBDWIJnxtwBk89fD8hhKpsX/uw+xcqgB//+MesWbOG22+//UPbFRQUcM011zBz5szqblGqlVavXs1VV13lNTJqoFoX3gfrib+v4vrHFrB1x86yWpOG9bn5K904p0ebQ21Rh2Dy5MncfPPNlJSUcNxxx/HAAw+UzSSf+tYGbn51Dct+9Uvef2oK3/7lfdw4+OwsdyxJVeujwjvb73lXq58+u2yP4AbYumMnP312WZY60m7nn38+hYWFLFy4kGeeeWaP4L522Ru8uX0Hh18wiha//T3357Rh6lsbstyxlJ6xY8cyYcKEsuVx48Yxfvz4susq7Ny5k+uuu46ePXuSm5vLL3/5SwCuvPJKpk2bBlD2ViOUfurjhhtuqOZRCOpYeK8u3npAdWXfza+uYeuuPc8Obd0VufnVNVnqSErX+eefz6OPPlq2/Oijj9KrV6+y5fvvv5/mzZszZ84c5syZw7333ss///lP+vbtW/ZW1apVq1i8uPQK1jNnzqRfv37VOwgBdSy8j8lpckB1Zd+q7TsOqC5p73r06MHatWtZvXo18+bNo0WLFrRt27Zs/fTp03nooYfIy8ujV69erF+/nuXLl5eF9+LFi+ncuTNHHXUUa9asYdasWXzmM5/J4ojqrgbZbqA6XTfwxArf875u4IlZ7EofpU2jhrxZQVC3adQwC91I6Rs6dChTpkzhrbfe4vzzz99jXYyRO++8k4EDB37occXFxfzxj3+kX79+bNiwgUcffZSmTZvSrFmz6mpd5dSpI+9zerTh5q90o01OEwLQJqeJk9VquOs7tKZJvT0/CdCkXuD6Dq2z1JGUtvPPP59HHnmEKVOmfOjy0AMHDuSuu+5ix47SX5j/8Y9/8N577wGlF8e67bbb6NevH3379mX8+PH07du32vtXqTp15A2lAW5Yp+O8o48ESt/7XrV9B20aNeT6Dq3L6pIOTJcuXdi0aRNt2rShdevWZX8zAkovglRUVMTJJ59MjJFWrVrxxBNPANC3b1+mT5/Opz71KY477jg2bNhgeGdRnfqomCRJqfioj4rVuSNvSdLBWfPWk7y6cjzbtq+hcaPWdDj+WlofPTjbbdVJhrckaZ/WvPUkS5fewK5dpR+t3bZ9NUuXln7G2wCvfnVqwpok6eC8unJ8WXDvtmvXVl5dOT5LHdVthrckaZ+2ba/4wkh7q6tqGd6SpH1q3Kjij2fura6qZXhLkvapw/HXUq/enlejrFevCR2OvzZLHdVtTliTJO3T7klpzjavGQxvSdJ+aX30YMO6hvC0uSRJiTG8JUlKjOEtSVJiDG9JkhJjeEuSlBjDW1I1wRYAAA9USURBVJKkxBjekiQlxvCWJCkxhrckSYkxvCVJSozhLUlSYgxvSZISY3hLkpQYw1uSpMQY3pIkJcbwliQpMYa3JEmJMbwlSUqM4S1JUmIMb0mSElNl4R1CGBdCWBVCKMzczi637voQwooQwrIQwsCq6kGSpNqoQRXv/9YY4/jyhRBCZ2AY0AU4BnguhHBCjHFnFfciSVKtkI3T5oOBR2KM22OM/wRWAKdmoQ9JkpJU1eE9JoQwP4QwMYTQIlNrA7xRbps3MzVJkrQfDim8QwjPhRAWVnAbDNwFHA/kAWuAnx3E/keHEApCCAXr1q07lFYlSao1Duk97xjjGfuzXQjhXuDpzOIqoG251cdmahXt/x7gHoD8/Px48J1KklR7VOVs89blFs8FFmbuTwOGhRAahRDaAx2B2VXVhyRJtU1Vzjb/fyGEPCACRcDXAWKMi0IIjwKLgRLgSmeaS5K0/6osvGOMF37Euh8CP6yq55YkqTbzCmuSJCXG8JYkKTGGtyRJiTG8JUlKjOEtSVJiDG9JkhJjeEuSlBjDW5KkxBjekiQlxvCWJCkxhrckSYkxvCVJSozhLUlSYgxvSZISY3hLkpQYw1uSpMQY3pIkJcbwliQpMYa3JEmJMbwlSUqM4S1JUmIMb0mSEmN4S5KUGMNbkqTEGN6SJCXG8JYkKTGGtyRJiTG8JUlKjOEtSVJiDG9JkhJjeEuSlBjDW5KkxBjekiQlxvBWpWnatGm2W5CkOsHwliQpMYa3qsRPf/pTevbsSW5uLjfddBMA7733Hl/4whfo3r07Xbt2ZfLkyQCMHTuWzp07k5uby7XXXpvNtiUpCQ2y3YBqn+nTp7N8+XJmz55NjJEvf/nLvPjii6xbt45jjjmGZ555BoCNGzeyfv16Hn/8cZYuXUoIgeLi4ix3L0k1n0feqnTTp09n+vTp9OjRg5NPPpmlS5eyfPlyunXrxp/+9Cf+53/+h5kzZ9K8eXOaN29O48aNufTSS3nsscc47LDDst2+JNV4hrcqXYyR66+/nsLCQgoLC1mxYgWXXnopJ5xwAn/729/o1q0bN954I9/73vdo0KABs2fPZsiQITz99NMMGjQo2+1LUo3naXNVuoEDB/Ltb3+b4cOH07RpU1atWkXDhg0pKSnhyCOPZMSIEeTk5HDfffexefNmtmzZwtlnn02fPn3o0KFDttuXpBrP8FalO/PMM1myZAmf/vSngdKPkP3mN79hxYoVXHfdddSrV4+GDRty1113sWnTJgYPHsy2bduIMXLLLbdkuXtJqvlCjDHbPeyX/Pz8WFBQkO02VIme+PsqfvrsMlYXb+WYnCZcN/BEzunRJtttSVKNEEKYG2PMr2idR97Kiif+vorrH1vA1h07AVhVvJXrH1sAYIBL0j44YU1Z8dNnl5UF925bd+zkp88uy1JHkpQOw1tZsbp46wHVJUn/ZngrK47JaXJAdUnSvxneyorrBp5Ik4b196g1aVif6waemKWOJCkdTlhTVuyelOZsc0k6cIcU3iGEocA4oBNwaoyxoNy664FLgZ3AVTHGZzP1QcDtQH3gvhjjjw+lB6XrnB5tDGtJOgiHetp8IfAV4MXyxRBCZ2AY0AUYBPwihFA/hFAfmACcBXQG/iOzrSRJ2k+HdOQdY1wCEEL44KrBwCMxxu3AP0MIK4BTM+tWxBhfzTzukcy2iw+lD0mS6pKqmrDWBnij3PKbmdre6pIkaT/t88g7hPAccHQFq26IMT5Z+S3t8dyjgdEAn/zkJ6vyqSRJSsY+wzvGeMZB7HcV0Lbc8rGZGh9Rr+i57wHugdJrmx9EH5Ik1TpVddp8GjAshNAohNAe6AjMBuYAHUMI7UMIH6N0Utu0KupBkqRa6VA/KnYucCfQCngmhFAYYxwYY1wUQniU0oloJcCVMcadmceMAZ6l9KNiE2OMiw5pBJIk1TH+SVBJkmqgj/qToF4eVZKkxBjekiQlxvCWJCkxhrckSYkxvCVJSozhLUlSYgxvSZISY3hLkpQYw1uSpMQY3pIkJcbwliQpMYa3JEmJMbwlSUqM4S1JUmIMb0mSEmN4S5KUGMNbkqTEGN6SJCXG8JYkKTGGtyRJiTG8JUlKjOEtSVJiDG9JkhJjeEuSlBjDW5KkxBjekiQlxvCWJCkxhrckSYkxvCVJSozhLUlSYgxvSZISY3hLkpQYw1uSpMQY3pIkJcbwliQpMYa3JEmJMbwlSUqM4S1JUmIMb0mSEmN4S5KUGMNbkqTEGN6SJCXG8JYkKTGGtyRJiTG8JUlKjOEtSVJiDG9JkhJjeEuSlJhDCu8QwtAQwqIQwq4QQn65ersQwtYQQmHmdne5daeEEBaEEFaEEO4IIYRD6UGSpLrmUI+8FwJfAV6sYN3KGGNe5nZ5ufpdwGVAx8xt0CH2IElSnXJI4R1jXBJjXLa/24cQWgNHxBhfiTFG4CHgnEPpQZKkuqYq3/NuH0L4ewjh/0IIfTO1NsCb5bZ5M1OrUAhhdAihIIRQsG7duipsVZKkdDTY1wYhhOeAoytYdUOM8cm9PGwN8MkY4/oQwinAEyGELgfaXIzxHuAegPz8/Higj5ckqTba55F3jPGMGGPXCm57C25ijNtjjOsz9+cCK4ETgFXAseU2PTZTUyW67bbb2LJlS9ny2WefTXFx8V63HzduHOPHj6+O1iRJlaBKTpuHEFqFEOpn7negdGLaqzHGNcC7IYTemVnmFwF7/SVAB27nzp0fCu/f//735OTkZLErSVJlOtSPip0bQngT+DTwTAjh2cyqfsD8EEIhMAW4PMa4IbPuCuA+YAWlR+R/OJQe6ppzzjmHU045hS5dunDPPfcA0LRpU/7rv/6L7t2788Mf/pDVq1dz+umnc/rppwPQrl073n77bQAeeughcnNz6d69OxdeeOGH9r9y5UoGDRrEKaecQt++fVm6dGn1DU6StF/2+Z73R4kxPg48XkF9KjB1L48pALoeyvPWZRMnTuTII49k69at9OzZk/POO4/33nuPXr168bOf/axsmz//+c+0bNlyj8cuWrSIH/zgB/zlL3+hZcuWbNiw4UP7Hz16NHfffTcdO3bkr3/9K1dccQXPP/98tYxNkrR/Dim8Vf3uuOMOHn+89PelN954g+XLl1O/fn3OO++8fT72+eefZ+jQoWWhfuSRR+6xfvPmzfzlL39h6NChZbXt27dXYveSpMpgeCfkhRde4LnnnmPWrFkcdthhnHbaaWzbto3GjRtTv379Q97/rl27yMnJobCwsBK6lSRVFa9tnpCNGzfSokULDjvsMJYuXcorr7xS4XbNmjVj06ZNH6p/7nOf43e/+x3r168H+NBp8yOOOIL27dvzu9/9DoAYI/PmzavkUUiSDpXhnZBBgwZRUlJCp06dGDt2LL17965wu9GjRzNo0KCyCWu7denShRtuuIH+/fvTvXt3vvWtb33osZMmTeL++++ne/fudOnShSef9MMAklTThNKrlNZ8+fn5saCgINttSJJULUIIc2OM+RWt88hb/zb/Ubi1K4zLKf06/9FsdyRJqoAT1lRq/qPw1FWwY2vp8sY3SpcBcr+avb4kSR/ikbdKzfjev4N7tx1bS+uSpBrF8FapjW8eWF2SlDWGt0o1P/bA6pKkrDG8VWrAd6Bhkz1rDZuU1iVJNYrhrVK5X4Uv3QHN2wKh9OuX7nCymiTVQM4217/lftWwlqQEeOQtSVJiDG9JkhJjeEuSlBjDW5KkxBjekiQlxvCWJCkxhrckSYkxvCVJSozhLUlSYgxvSZISY3hLkpQYw1uSpMQY3pIkJcbwliQpMYa3JEmJCTHGbPewX0II64DXst1HFWgJvJ3tJrKkLo8dHL/jr7vjr8tjh/0f/3ExxlYVrUgmvGurEEJBjDE/231kQ10eOzh+x193x1+Xxw6VM35Pm0uSlBjDW5KkxBje2XdPthvIoro8dnD8jr/uqstjh0oYv+95S5KUGI+8JUlKjOFdTUIIQ0MIi0IIu0II+R9Yd30IYUUIYVkIYWC5+qBMbUUIYWz1d101QgjjQgirQgiFmdvZ5dZV+L2obWrrv+3ehBCKQggLMv/eBZnakSGEP4UQlme+tsh2n5UlhDAxhLA2hLCwXK3C8YZSd2ReC/NDCCdnr/PKsZfx15mf+xBC2xDCn0MIizP/71+dqVfeayDG6K0abkAn4ETgBSC/XL0zMA9oBLQHVgL1M7eVQAfgY5ltOmd7HJX0vRgHXFtBvcLvRbb7rYLx19p/248YcxHQ8gO1/weMzdwfC/wk231W4nj7AScDC/c1XuBs4A9AAHoDf812/1U0/jrzcw+0Bk7O3G8G/CMzzkp7DXjkXU1ijEtijMsqWDUYeCTGuD3G+E9gBXBq5rYixvhqjPF94JHMtrXZ3r4XtU1d/LetyGDgwcz9B4FzsthLpYoxvghs+EB5b+MdDDwUS70C5IQQWldPp1VjL+Pfm1r3cx9jXBNj/Fvm/iZgCdCGSnwNGN7Z1wZ4o9zym5na3uq1xZjM6aGJ5U6X1vYx71ZXxlleBKaHEOaGEEZnakfFGNdk7r8FHJWd1qrN3sZbl14Pde7nPoTQDugB/JVKfA0Y3pUohPBcCGFhBbc6d1S1j+/FXcDxQB6wBvhZVptVdfhsjPFk4CzgyhBCv/IrY+m5wzrz0Ze6Nt6MOvdzH0JoCkwFvhljfLf8ukN9DTQ4xN5UTozxjIN42CqgbbnlYzM1PqJe4+3v9yKEcC/wdGbxo74XtUldGWeZGOOqzNe1IYTHKT0t+q8QQusY45rMKcK1WW2y6u1tvHXi9RBj/Nfu+3Xh5z6E0JDS4J4UY3wsU66014BH3tk3DRgWQmgUQmgPdARmA3OAjiGE9iGEjwHDMtsm7wPv5ZwL7J6RurfvRW1Ta/9tKxJCODyE0Gz3feBMSv/NpwEjM5uNBJ7MTofVZm/jnQZclJlx3BvYWO7Uaq1Rl37uQwgBuB9YEmO8pdyqynsNZHtWXl25UfpifRPYDvwLeLbcuhsonWG5DDirXP1sSmcprgRuyPYYKvF78WtgATA/86Jtva/vRW271dZ/272MtQOls4nnAYt2jxf4ODADWA48BxyZ7V4rccy/pfTU8I7Mz/2lexsvpTOMJ2ReCwso92mUVG97GX+d+bkHPkvpKfH5QGHmdnZlvga8wpokSYnxtLkkSYkxvCVJSozhLUlSYgxvSZISY3hLkpQYw1uSpMQY3pIkJcbwliQpMf8fl0pHLY7rITUAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving net to:  /content/drive/My Drive/COMP5046-assignment1/test_w2v04141224/zhua9812_word0.pt\n",
            "    (0m 0s) Batch: 50, loss: 2.4123\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type W2VSkipGramNet. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "    (0m 0s) Batch: 100, loss: 2.3094\n",
            "    (0m 0s) Batch: 150, loss: 2.2298\n",
            "    (0m 0s) Batch: 200, loss: 2.1658\n",
            "    (0m 0s) Batch: 250, loss: 2.1127\n",
            "    (0m 0s) Batch: 300, loss: 2.0672\n",
            "    (0m 0s) Batch: 350, loss: 2.0270\n",
            "    (0m 0s) Batch: 400, loss: 1.9910\n",
            "    (0m 0s) Batch: 450, loss: 1.9585\n",
            "    (0m 0s) Batch: 500, loss: 1.9294\n",
            "    (0m 0s) Batch: 550, loss: 1.9033\n",
            "    (0m 1s) Batch: 600, loss: 1.8802\n",
            "    (0m 1s) Batch: 650, loss: 1.8598\n",
            "    (0m 1s) Batch: 700, loss: 1.8418\n",
            "    (0m 1s) Batch: 750, loss: 1.8255\n",
            "    (0m 1s) Batch: 800, loss: 1.8106\n",
            "    (0m 1s) Batch: 850, loss: 1.7965\n",
            "    (0m 1s) Batch: 900, loss: 1.7830\n",
            "    (0m 1s) Batch: 950, loss: 1.7695\n",
            "    (0m 1s) Batch: 1000, loss: 1.7559\n",
            "    (0m 1s) Batch: 1050, loss: 1.7420\n",
            "    (0m 1s) Batch: 1100, loss: 1.7280\n",
            "    (0m 1s) Batch: 1150, loss: 1.7140\n",
            "    (0m 2s) Batch: 1200, loss: 1.7003\n",
            "    (0m 2s) Batch: 1250, loss: 1.6873\n",
            "    (0m 2s) Batch: 1300, loss: 1.6750\n",
            "    (0m 2s) Batch: 1350, loss: 1.6636\n",
            "    (0m 2s) Batch: 1400, loss: 1.6532\n",
            "    (0m 2s) Batch: 1450, loss: 1.6437\n",
            "    (0m 2s) Batch: 1500, loss: 1.6348\n",
            "    (0m 2s) Batch: 1550, loss: 1.6264\n",
            "    (0m 2s) Batch: 1600, loss: 1.6184\n",
            "    (0m 2s) Batch: 1650, loss: 1.6107\n",
            "    (0m 2s) Batch: 1700, loss: 1.6032\n",
            "    (0m 2s) Batch: 1750, loss: 1.5962\n",
            "    (0m 2s) Batch: 1800, loss: 1.5896\n",
            "    (0m 3s) Batch: 1850, loss: 1.5838\n",
            "    (0m 3s) Batch: 1900, loss: 1.5788\n",
            "    (0m 3s) Batch: 1950, loss: 1.5745\n",
            "    (0m 3s) Batch: 2000, loss: 1.5709\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNys5HOdISK-",
        "colab_type": "text"
      },
      "source": [
        "### 2.1.3. Train Word Embeddings Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArS4cMxbmGz6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_dim, window, drop_prob = 64, 5, 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0DdvEHVokpL",
        "colab_type": "code",
        "outputId": "dc177cb7-6cb6-4536-fabb-ce5795a29e55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "w2v_model = make_w2v_model(tokens_train, embedding_dim, window, drop_prob)\n",
        "# 100 is the most I can run, else colab disconnects\n",
        "w2v_model_trails = w2v_model.train(train_data=tokens_train, epochs=100, batch_size=1024, \n",
        "                                   batch_display_interval=10000, epoch_display_interval=1, ckpt_interval=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving net to:  /content/drive/My Drive/COMP5046-assignment1/word/zhua9812_word0.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMCv3YI1IfUo",
        "colab_type": "text"
      },
      "source": [
        "### 2.1.4. Save Word Embeddings Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LwsGbOFBQsZ",
        "colab_type": "code",
        "outputId": "37ab1871-8660-4e13-dd47-c6c8a45abaf8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Adding _ to the end because it should already be saved once\n",
        "w2v_model.save_model(\"best_\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving net to:  /content/drive/My Drive/COMP5046-assignment1/word/zhua9812_wordbest_.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yn16xrDrIs8B",
        "colab_type": "text"
      },
      "source": [
        "### 2.1.5. Load Word Embeddings Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IebpYFsIvgh",
        "colab_type": "code",
        "outputId": "dd234d25-3c81-4fe7-9863-2b9d1d201041",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Setup\n",
        "w2v_model_load = make_w2v_model(tokens_train, embedding_dim, window, drop_prob)\n",
        "w2v_model_load.load_model(\"best\")\n",
        "w2v_model_load.mode(False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading net from:  /content/drive/My Drive/COMP5046-assignment1/word/zhua9812_wordbest.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "T0ap96aeGlIk"
      },
      "source": [
        "## 2.2. Character Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "d16v3oKaGlI0"
      },
      "source": [
        "### 2.2.1. Data Preprocessing for Character Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AKbLnN-3GlI1"
      },
      "source": [
        "*You are required to describe which preprocessing techniques were used with justification of your decision.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNu7LLBF4oRL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cet = VocabCharacterTransformer().fit(toy_num_data)\n",
        "cet.transform(toy_num_data)\n",
        "# It works"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zgiOPcsTGlI6"
      },
      "source": [
        "### 2.2.2. Build Character Embeddings Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4NtqFFcjGlI7"
      },
      "source": [
        "*You are required to describe how hyperparameters were decided with justification of your decision.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bu95_tXs3Pwl",
        "colab_type": "code",
        "outputId": "6ff2494b-3792-4dfa-f8bd-8926f0b8fe39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "test_embedding = test_w2v_model.net.embedding\n",
        "test_char_model = make_char_model(toy_data, test_embedding, ckpt_base=\"test_char\", addtime=True)\n",
        "_ = test_char_model.train(train_data=toy_data, epochs=5000, batch_display_interval=1000)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving net to:  /content/drive/My Drive/COMP5046-assignment1/test_char04141224/zhua9812_character0.pt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type CharacterEmbedNet. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "    (0m 9s) Batch: 1000, loss: 0.0009\n",
            "    (0m 17s) Batch: 2000, loss: 0.0001\n",
            "    (0m 26s) Batch: 3000, loss: 0.0000\n",
            "    (0m 34s) Batch: 4000, loss: 0.0000\n",
            "    (0m 42s) Batch: 5000, loss: 0.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "46W0zFfWGlI_"
      },
      "source": [
        "### 2.1.4. Train Character Embeddings Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UWQn-VyNGlJA",
        "outputId": "2da5d973-67d1-4ae3-8e1b-40dad3d00d0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "embedding = w2v_model_load.net.embedding\n",
        "char_model = make_char_model(tokens_train, embedding=embedding, hidden_size=128)\n",
        "char_model_trails = char_model.train(train_data=tokens_train, epochs=1, batch_display_interval=5000, \n",
        "                                     epoch_display_interval=1, ckpt_interval=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving net to:  /content/drive/My Drive/COMP5046-assignment1/character/zhua9812_character0.h5\n",
            "(11m 16s) Epoch: 1, batch: 2916, loss: 0.6825\n",
            "Saving net to:  /content/drive/My Drive/COMP5046-assignment1/character/zhua9812_character1.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "R5Bym9bBGlJE"
      },
      "source": [
        "### 2.1.5. Save Character Embeddings Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ggTsYIm7GlJF",
        "outputId": "eaa089dd-478f-48c8-efb3-74151f5d6cee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "char_model.save_model(\"best_\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving net to:  /content/drive/My Drive/COMP5046-assignment1/character/zhua9812_characterbest.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JwOI-wIKGlJI"
      },
      "source": [
        "### 2.1.6. Load Character Embeddings Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-jyj-lOHWWj",
        "colab_type": "code",
        "outputId": "00506a6b-b7cf-401c-aa88-82f2cb57bfe9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "embedding = w2v_model_load.net.embedding\n",
        "char_model_load = make_char_model(tokens_train, embedding, ckpt_base=\"character\")\n",
        "char_model_load.load_model(\"best\")\n",
        "char_model_load.mode(False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading net from:  /content/drive/My Drive/COMP5046-assignment1/character/zhua9812_characterbest.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlCeWT8eeLnd",
        "colab_type": "text"
      },
      "source": [
        "## 2.3. Sequence model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwA-NN3EJ4Ig",
        "colab_type": "text"
      },
      "source": [
        "### 2.3.1. Apply/Import Word Embedding and Character Embedding Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UAMJrxx-iOVn",
        "colab_type": "text"
      },
      "source": [
        "*You are required to describe how hyperparameters were decided with justification of your decision.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpYCL17JKZxl",
        "colab_type": "text"
      },
      "source": [
        "### 2.3.2. Build Sequence Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R204UIyDKhZ4",
        "colab_type": "text"
      },
      "source": [
        "*You are required to describe how hyperparameters were decided with justification of your decision.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BaOiaGRLW7R",
        "colab_type": "text"
      },
      "source": [
        "### 2.3.3. Train Sequence Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8kUEZFhqe-1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Test model\n",
        "test_hidden_size = 3\n",
        "test_char_net = test_char_model.net\n",
        "seq_net = make_sequence_model(toy_full_data11, test_embedding, test_char_net, test_hidden_size, \n",
        "                              ckpt_base=\"test_seq\", addtime=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVQnUSX1LZ6C",
        "colab_type": "code",
        "outputId": "b39f5531-b8c8-41ee-bec7-ac59640a2740",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "test_run = wandb_init({\"hidden_size\": 3, \"rnn_type\": \"LSTM\"}, tags=[\"test_seq\"])\n",
        "with test_run:\n",
        "    seq_net.train(train_data=toy_full_data11, val_data=toy_full_data_test, epochs=3200, batch_size=6, \n",
        "                epoch_display_interval=200, ckpt_interval=10000, epoch_validation_interval=400,\n",
        "                wandb_log=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/dovermore/comp5046-assignment1\" target=\"_blank\">https://app.wandb.ai/dovermore/comp5046-assignment1</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/dovermore/comp5046-assignment1/runs/2nao0dos\" target=\"_blank\">https://app.wandb.ai/dovermore/comp5046-assignment1/runs/2nao0dos</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving net to:  /content/drive/My Drive/COMP5046-assignment1/test_seq04141252/zhua9812_sequence0.h5\n",
            "(0m 6s) Epoch: 200, batch: 400, loss: 0.1665\n",
            "Validation - epoch 400:\n",
            "    Loss: 0.6282\n",
            "    accuracy: 71.43%\n",
            "    F1: 0.8000\n",
            "(0m 12s) Epoch: 400, batch: 800, loss: 0.0353\n",
            "(0m 18s) Epoch: 600, batch: 1200, loss: 0.0149\n",
            "Validation - epoch 800:\n",
            "    Loss: 0.8137\n",
            "    accuracy: 71.43%\n",
            "    F1: 0.8000\n",
            "(0m 24s) Epoch: 800, batch: 1600, loss: 0.0081\n",
            "(0m 30s) Epoch: 1000, batch: 2000, loss: 0.0046\n",
            "Validation - epoch 1200:\n",
            "    Loss: 0.9380\n",
            "    accuracy: 71.43%\n",
            "    F1: 0.8000\n",
            "(0m 37s) Epoch: 1200, batch: 2400, loss: 0.0031\n",
            "(0m 43s) Epoch: 1400, batch: 2800, loss: 0.0022\n",
            "Validation - epoch 1600:\n",
            "    Loss: 1.0248\n",
            "    accuracy: 71.43%\n",
            "    F1: 0.8000\n",
            "(0m 49s) Epoch: 1600, batch: 3200, loss: 0.0016\n",
            "(0m 56s) Epoch: 1800, batch: 3600, loss: 0.0012\n",
            "Validation - epoch 2000:\n",
            "    Loss: 1.1092\n",
            "    accuracy: 71.43%\n",
            "    F1: 0.8000\n",
            "(1m 2s) Epoch: 2000, batch: 4000, loss: 0.0010\n",
            "(1m 8s) Epoch: 2200, batch: 4400, loss: 0.0007\n",
            "Validation - epoch 2400:\n",
            "    Loss: 1.1946\n",
            "    accuracy: 71.43%\n",
            "    F1: 0.8000\n",
            "(1m 14s) Epoch: 2400, batch: 4800, loss: 0.0006\n",
            "(1m 21s) Epoch: 2600, batch: 5200, loss: 0.0005\n",
            "Validation - epoch 2800:\n",
            "    Loss: 1.2805\n",
            "    accuracy: 71.43%\n",
            "    F1: 0.8000\n",
            "(1m 27s) Epoch: 2800, batch: 5600, loss: 0.0004\n",
            "(1m 33s) Epoch: 3000, batch: 6000, loss: 0.0003\n",
            "Validation - epoch 3200:\n",
            "    Loss: 1.3679\n",
            "    accuracy: 71.43%\n",
            "    F1: 0.8000\n",
            "(1m 39s) Epoch: 3200, batch: 6400, loss: 0.0002\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-169-9d51cd7c5203>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     seq_net.train(train_data=toy_full_data11, val_data=toy_full_data_test, epochs=3200, batch_size=6, \n\u001b[1;32m      4\u001b[0m                 \u001b[0mepoch_display_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_validation_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                 wandb_log=True)\n\u001b[0m",
            "\u001b[0;32m<ipython-input-163-0aa2fce5ae12>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_data, val_data, epochs, batch_size, batch_display_interval, epoch_display_interval, epoch_validation_interval, ckpt_interval, wandb_log, return_trail)\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0;31m# Return trail if needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_trail\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mepoch_loss_trail\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_val_loss_trail\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_val_eval_trail\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mepoch_loss_trail\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'val' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0zSNtNxjzVL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Actual model\n",
        "hidden_size = embedding_dim // 4\n",
        "seq_net = make_sequence_model([tokens_train, label_train], w2v_model_load.net.embedding, \n",
        "                               char_model_load.net, hidden_size, ckpt_base=\"seq\")\n",
        "seq_net_trail = seq_net.train([tokens_train, label_train], 100, batch_display_interval=5000, \n",
        "                              epoch_display_interval=1, ckpt_interval=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2feNpG-LZx2",
        "colab_type": "text"
      },
      "source": [
        "### 2.3.4. Save Sequence Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sflUAgV4L1o8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seq_net.save_model(\"best_\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zFo6YppL6w3",
        "colab_type": "text"
      },
      "source": [
        "### 2.3.5. Load Sequence Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtNxLzDGMCan",
        "colab_type": "code",
        "outputId": "e0f23a74-5ed6-4544-b298-1d6b2038c8d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        }
      },
      "source": [
        "# Please comment your code\n",
        "hidden_size = w2v_model_load.net.embedding.embedding_dim / 4\n",
        "seq_net = make_sequence_model([tokens_train, label_train], w2v_model_load.net.embedding, \n",
        "                            char_model_load.net, hidden_size, ckpt_base=\"seq\")\n",
        "seq_net_load.load_model(\"best\")\n",
        "seq_net_load.mode(False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-139-44095871c458>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhidden_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw2v_model_load\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_dim\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m seq_net = make_sequence_net([tokens_train, label_train], w2v_model_load.net.embedding, \n\u001b[1;32m      3\u001b[0m                             char_model_load.net, hidden_size, ckpt_base=\"seq\")\n\u001b[1;32m      4\u001b[0m \u001b[0mseq_net_load\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"best\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mseq_net_load\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'w2v_model_load' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4mpRpocePLN",
        "colab_type": "text"
      },
      "source": [
        "# 3 - Evaluation\n",
        "\n",
        "(*Please show your empirical evidence*)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEW1zMgVMREr",
        "colab_type": "text"
      },
      "source": [
        "## 3.1. Performance Evaluation\n",
        "\n",
        "\n",
        "You are required to provide the table with precision, recall, f1 of test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPHCb-bneTI9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Please comment your code"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P28Z1k36MZuo",
        "colab_type": "text"
      },
      "source": [
        "## 3.2. Hyperparameter Testing\n",
        "*You are required to draw a graph(y-axis: f1, x-axis: epoch) for test set and explain the optimal number of epochs based on the learning rate you have already chosen.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTLyQEeZMZ2f",
        "colab_type": "code",
        "outputId": "6861dcc2-8b25-461a-e94f-0e369c3bcebe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Please comment your code\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 289
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfv8rWTKPzeb",
        "colab_type": "text"
      },
      "source": [
        "## Object Oriented Programming codes here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TS23AjBRSZaX",
        "colab_type": "text"
      },
      "source": [
        "*You can use multiple code snippets. Just add more if needed* "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KBPwoQWMtLb",
        "colab_type": "code",
        "outputId": "b7749846-49e5-40b4-e505-7e6d55e523c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        }
      },
      "source": [
        "# install some other necessary libraries\n",
        "# Expand contractions\n",
        "%pip install unicode\n",
        "%pip install contractions\n",
        "%pip install torchviz\n",
        "%pip install wandb\n",
        "!wandb login 313fbc32f5d8eafb89fc6611be0e05e4a71ef77f\n",
        "\n",
        "# Setup saving and loading\n",
        "from google.colab import files, drive\n",
        "from pathlib import Path\n",
        "\n",
        "# All imports\n",
        "import copy\n",
        "from copy import deepcopy\n",
        "import re\n",
        "import os\n",
        "import time\n",
        "from datetime import datetime\n",
        "import math\n",
        "from collections import Counter\n",
        "from random import shuffle, getrandbits, sample\n",
        "import json\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.base import TransformerMixin\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "from unidecode import unidecode\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "import contractions\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords as sw\n",
        "from nltk import FreqDist\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils import data\n",
        "from torch.optim import Adam\n",
        "from torch.nn import functional as F\n",
        "from torch.nn.utils.rnn import pack_sequence\n",
        "\n",
        "from torchviz import make_dot\n",
        "\n",
        "import wandb"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: unicode in /usr/local/lib/python3.6/dist-packages (2.7)\n",
            "Requirement already satisfied: contractions in /usr/local/lib/python3.6/dist-packages (0.0.24)\n",
            "Requirement already satisfied: textsearch in /usr/local/lib/python3.6/dist-packages (from contractions) (0.0.17)\n",
            "Requirement already satisfied: Unidecode in /usr/local/lib/python3.6/dist-packages (from textsearch->contractions) (1.1.1)\n",
            "Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.6/dist-packages (from textsearch->contractions) (1.4.0)\n",
            "Requirement already satisfied: torchviz in /usr/local/lib/python3.6/dist-packages (0.0.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchviz) (1.4.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from torchviz) (0.10.1)\n",
            "Requirement already up-to-date: wandb in /usr/local/lib/python3.6/dist-packages (0.8.31)\n",
            "Requirement already satisfied, skipping upgrade: subprocess32>=3.5.3 in /usr/local/lib/python3.6/dist-packages (from wandb) (3.5.4)\n",
            "Requirement already satisfied, skipping upgrade: shortuuid>=0.5.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: configparser>=3.8.1 in /usr/local/lib/python3.6/dist-packages (from wandb) (5.0.0)\n",
            "Requirement already satisfied, skipping upgrade: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (7.352.0)\n",
            "Requirement already satisfied, skipping upgrade: GitPython>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (3.1.1)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from wandb) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: docker-pycreds>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied, skipping upgrade: requests>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (2.21.0)\n",
            "Requirement already satisfied, skipping upgrade: psutil>=5.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: PyYAML>=3.10 in /usr/local/lib/python3.6/dist-packages (from wandb) (3.13)\n",
            "Requirement already satisfied, skipping upgrade: Click>=7.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (7.1.1)\n",
            "Requirement already satisfied, skipping upgrade: watchdog>=0.8.3 in /usr/local/lib/python3.6/dist-packages (from wandb) (0.10.2)\n",
            "Requirement already satisfied, skipping upgrade: sentry-sdk>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (0.14.3)\n",
            "Requirement already satisfied, skipping upgrade: gql==0.2.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (0.2.0)\n",
            "Requirement already satisfied, skipping upgrade: gitdb<5,>=4.0.1 in /usr/local/lib/python3.6/dist-packages (from GitPython>=1.0.0->wandb) (4.0.4)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->wandb) (2020.4.5.1)\n",
            "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->wandb) (2.8)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->wandb) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: pathtools>=0.1.1 in /usr/local/lib/python3.6/dist-packages (from watchdog>=0.8.3->wandb) (0.1.2)\n",
            "Requirement already satisfied, skipping upgrade: graphql-core<2,>=0.5.0 in /usr/local/lib/python3.6/dist-packages (from gql==0.2.0->wandb) (1.1)\n",
            "Requirement already satisfied, skipping upgrade: promise<3,>=2.0 in /usr/local/lib/python3.6/dist-packages (from gql==0.2.0->wandb) (2.3)\n",
            "Requirement already satisfied, skipping upgrade: smmap<4,>=3.0.1 in /usr/local/lib/python3.6/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (3.0.2)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[32mSuccessfully logged in to Weights & Biases!\u001b[0m\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YJNGNzLMtEl",
        "colab_type": "code",
        "outputId": "cf8fbce9-8d3f-4915-f3f6-c0516dd516f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "## Setup some variables\n",
        "# Prepare some Toy data\n",
        "toy_token_1data = [[\"hello\"]]\n",
        "toy_token_10data = [[\"hello\", \"below\", \"allow\", \"law\", \"low\", \"all\", \"halo\", \n",
        "                     \"hellobelowallow\", \"lawlow\", \"halo\"]]\n",
        "\n",
        "toy_token_data11 = [\n",
        "                      [\"good\", \"article\"],\n",
        "                      [\"beautiful\", \"article\", \"good\"],\n",
        "                      [\"beautiful\", \"singing\", \"more\"],\n",
        "                      [\"not\", \"bad\", \"view\"],\n",
        "                      [\"not\", \"ugly\", \"singing\", \"positive\"],\n",
        "                      [\"more\", \"positive\", \"singing\"],\n",
        "                      [\"less\", \"positive\", \"article\"],\n",
        "                      [\"bad\", \"singing\"],\n",
        "                      [\"not\", \"positive\", \"article\"],\n",
        "                      [\"not\", \"good\", \"singing\"],\n",
        "                      [\"ugly\", \"view\"],\n",
        "                      ]\n",
        "toy_sentiment_data11 = [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]\n",
        "\n",
        "toy_token_data_test = [\n",
        "                    # Test if it can handle unseen words (should ignore it)\n",
        "                      [\"more\", \"impressive\", \"singing\", \"not\", \"bad\"],\n",
        "\n",
        "                      [\"not\", \"ugly\", \"article\"],\n",
        "                      [\"beautiful\", \"view\"],\n",
        "                      [\"more\", \"good\", \"singing\", \"positive\"],\n",
        "                      [\"less\", \"bad\", \"view\"],\n",
        "                      [\"less\", \"good\", \"article\"],\n",
        "                      [\"not\", \"beautiful\", \"view\"],\n",
        "                      ]\n",
        "toy_sentiment_data_test = [1, 1, 1, 1, 0, 0, 0]\n",
        "\n",
        "toy_full_data11 = [toy_token_data11, toy_sentiment_data11]\n",
        "toy_full_data_test = [toy_token_data_test, toy_sentiment_data_test]\n",
        "toy_data = toy_token_data11\n",
        "toy_num_data = np.array(list(range(20)) * 2 + [0]).reshape(1, -1).tolist()\n",
        "\n",
        "# Setup drive path\n",
        "drive.mount('/content/drive')\n",
        "drive_path = Path(\"/content/drive/My Drive/COMP5046-assignment1/\")\n",
        "\n",
        "# Processed train and test data\n",
        "train_path = drive_path/\"data\"/\"train.feather\"\n",
        "test_path = drive_path/\"data\"/\"test.feather\"\n",
        "\n",
        "# Setup device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# device = torch.device(\"cpu\")\n",
        "print(\"device is \", device)\n",
        "\n",
        "# For reproducibility\n",
        "# Also the ultimita solution to universe -- The Hitchhiker's Guide to the Galaxy\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# List of generic hyperparameters\n",
        "# optimizer: lr, *args, **kwargs\n",
        "# epochs, batch_size\n",
        "# w2v: embedding_dim, window, drop_prob\n",
        "w2v_configs_path = drive_path/\"config\"/\"w2v_configs.json\"\n",
        "# char: ?[gru, lstm, rnn], hidden_size, dropout, num_layers\n",
        "char_configs_path = drive_path/\"config\"/\"char_configs.json\"\n",
        "# seq: ?[gru, lstm, rnn], hidden_size, dropout, num_layers\n",
        "seq_configs_path = drive_path/\"config\"/\"seq_configs.json\"\n",
        "\n",
        "wandb_dir = drive_path\n",
        "wandb_api_"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "device is  cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBdzKSoONajg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Setup helper functions\n",
        "def read_json(path):\n",
        "    \"\"\"\n",
        "    Load json config\n",
        "    \"\"\"\n",
        "    with open(path, \"r\") as fp:\n",
        "        config = json.load(fp)\n",
        "    return config\n",
        "\n",
        "\n",
        "def wandb_init(config_dict, tags=[], project=\"comp5046-assignment1\", wandb_dir=wandb_dir, \n",
        "               reinit=True, *args, **kwargs):\n",
        "    \"\"\"\n",
        "    Simply set some default parameters\n",
        "    \"\"\"\n",
        "    return wandb.init(config=config_dict, tags=tags, project=project, dir=str(wandb_dir), \n",
        "                      reinit=reinit, *args, **kwargs)\n",
        "\n",
        "\n",
        "def get_time_str(*args, **kwargs):\n",
        "    \"\"\"\n",
        "    Get current time in string format\n",
        "    \"\"\"\n",
        "    return datetime.now(*args, **kwargs).strftime(\"%m%d%H%M\")\n",
        "\n",
        "    \n",
        "def check_create_parent(path):\n",
        "    \"\"\"\n",
        "    Check and create the parent path of a given file path\n",
        "    \"\"\"\n",
        "    path = Path(path)\n",
        "    if not (path.parent.exists() and path.parent.is_dir()):\n",
        "        path.parent.mkdir(parents=True, exist_ok=False)\n",
        "\n",
        "\n",
        "# Create df to store the data\n",
        "def save_feather(tokens, labels, sentiments, path):\n",
        "    \"\"\"\n",
        "    Save processed data in feather format for faster loading\n",
        "    \"\"\"\n",
        "    df = pd.DataFrame(columns=[\"tokens\", \"labels\", \"sentiments\"])\n",
        "    df[\"tokens\"] = [\" \".join(t) for t in tokens]\n",
        "    df[\"labels\"] = labels \n",
        "    df[\"sentiments\"] = sentiments\n",
        "    check_create_parent(path)\n",
        "    df.to_feather(path)\n",
        "\n",
        "\n",
        "def load_feather(path):\n",
        "    \"\"\"\n",
        "    Load processed data saved in feather format for faster loading\n",
        "    \"\"\"\n",
        "    df = pd.read_feather(path)\n",
        "    tokens = df[\"tokens\"]\n",
        "    labels = df[\"labels\"]\n",
        "    sentiments = df[\"sentiments\"]\n",
        "    tokens = [t.split(\" \") for t in tokens]\n",
        "    return tokens, labels, sentiments\n",
        "\n",
        "\n",
        "def time_since(since):\n",
        "    \"\"\"\n",
        "    Format the time since a given timepoint in string\n",
        "    Accreditation: https://pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html\n",
        "    \"\"\"\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def birnn_last_concat(rnn, X):\n",
        "    \"\"\"\n",
        "    Pass data X through a given rnn (lstm, gru) and return the final concat result as tensor\n",
        "    \"\"\"\n",
        "    if isinstance(rnn, nn.LSTM):\n",
        "        out_seq, (h_n, c_n) = rnn(X)\n",
        "    else:\n",
        "        out_seq, h_n = rnn(X)\n",
        "    # h_n of shape (num_layers * num_directions, batch, hidden_size): \n",
        "    #     tensor containing the hidden state for t = seq_len.\n",
        "    h_n = h_n.view(rnn.num_layers, 2, -1, rnn.hidden_size)\n",
        "    # concat the last hidden state from two direction\n",
        "    out = torch.cat((h_n[-1,0,:,:], h_n[-1,1,:,:]),1)\n",
        "    return out\n",
        "\n",
        "\n",
        "def sort_pack_chars(X, num_classes):\n",
        "    \"\"\"\n",
        "    Sort and pack uneven length character arrays in torch to one-hot encoded packed sequence\n",
        "    \"\"\"\n",
        "    # Sort by length and convert to tensor\n",
        "    X, idxs = mysorted([torch.from_numpy(np.array(x)) for x in X], \n",
        "                                key=lambda x: len(x), reverse=True)\n",
        "    # Change to one hot encoding and word vector\n",
        "    X = pack_sequence([F.one_hot(seq, num_classes=num_classes).float() for seq in X])\n",
        "    return X, idxs\n",
        "\n",
        "\n",
        "def unpack_sequence(packed_sequence):\n",
        "    \"\"\"\n",
        "    Unpack a packedsequence provided in sort_pack_chars (but won't reverse the order)\n",
        "    \"\"\"\n",
        "    batch_sizes = packed_X.batch_sizes.clone().numpy()\n",
        "    lengths = []\n",
        "    while batch_sizes[0]:\n",
        "        lengths.append(sum(batch_sizes > 0))\n",
        "        batch_sizes -= 1\n",
        "    head = 0\n",
        "    trailing_dims = packed_sequence.data.shape[1:]\n",
        "    unpacked_sequence = [torch.zeros(l, *trailing_dims) for l in lengths]\n",
        "    # l_idx - goes from 0 - maxLen-1\n",
        "    for l_idx, b_size in enumerate(packed_sequence.batch_sizes):\n",
        "        for b_idx in range(b_size):\n",
        "            unpacked_sequence[b_idx][l_idx] = packed_sequence.data[head]\n",
        "            head += 1\n",
        "    return unpacked_sequence\n",
        "\n",
        "\n",
        "def get_net_dict(net:nn.Module):\n",
        "    \"\"\"\n",
        "    Deepcopy and extract the state_dict of a module\n",
        "    \"\"\"\n",
        "    return deepcopy(net.state_dict())\n",
        "\n",
        "\n",
        "def mysorted(seq, key=None, reverse=False):\n",
        "    \"\"\"\n",
        "    Emulate torch.sort behaviour for a regular list\n",
        "    returns the sorte seqeunce and the index list to sort it\n",
        "    \"\"\"\n",
        "    idxs, seq = list(zip(*sorted(enumerate(seq), key=lambda x: key(x[1]), reverse=reverse)))\n",
        "    return seq, list(idxs)\n",
        "\n",
        "\n",
        "def plot_annotate(x, y, labels, ax=None):\n",
        "    \"\"\"\n",
        "    Plot and annotate points given by x, y with list of labels\n",
        "    \"\"\"\n",
        "    for i in range(len(x)):\n",
        "        plt.scatter(x[i], y[i])\n",
        "        plt.annotate(labels[i],\n",
        "                    xy=(x[i], y[i]),\n",
        "                    xytext=(5, 2),\n",
        "                    textcoords='offset points',\n",
        "                    ha='right',\n",
        "                    va='bottom')\n",
        "\n",
        "\n",
        "def plot_embedding_tsne(embedding, labels, *args, **kwargs):\n",
        "    embedding_data = embedding.weight.clone().detach().numpy()\n",
        "    if isinstance(labels, dict):\n",
        "        labels, idx = zip(*list(labels.items()))\n",
        "        embedding_data = embedding_data[list(idx)]\n",
        "    tsne = TSNE(*args, **kwargs)\n",
        "    tsne_embedding = tsne.fit_transform(embedding_data).tolist()\n",
        "    plot_annotate(*list(zip(*tsne_embedding)), labels)\n",
        "    plt.show()\n",
        "    return tsne_embedding, embedding_data, tsne\n",
        "\n",
        "\n",
        "def plot_embedding_pca(embedding, labels, n_components=2, *args, **kwargs):\n",
        "    embedding_data = embedding.weight.clone().detach().numpy()\n",
        "    if isinstance(labels, dict):\n",
        "        labels, idx = zip(*list(labels.items()))\n",
        "        embedding_data = embedding_data[list(idx)]\n",
        "    pca = PCA(n_components, *args, **kwargs)\n",
        "    pca_embedding = pca.fit_transform(embedding_data).tolist()\n",
        "    plot_annotate(*list(zip(*pca_embedding)), labels)\n",
        "    plt.show()\n",
        "    return pca_embedding, embedding_data, pca\n",
        "\n",
        "\n",
        "class FileNameGenerator:\n",
        "    def __init__(self, prefix, postfix=\".pt\"):\n",
        "        self.prefix = prefix\n",
        "        self.postfix = postfix\n",
        "\n",
        "    def _gen_fname(self, offset=0):\n",
        "        i = 0\n",
        "        path = self._format_path(i)\n",
        "        while path.exists():\n",
        "            i += 1\n",
        "            path = self._format_path(i)\n",
        "        if i + offset < 0:\n",
        "            return None\n",
        "        return self._format_path(i + offset)\n",
        "    \n",
        "    def read_fname(self, serial=None):\n",
        "        if serial is None:\n",
        "            return self._gen_fname(offset=-1)\n",
        "        return self._format_path(serial)\n",
        "\n",
        "    def write_fname(self, serial=None):\n",
        "        if serial is None:\n",
        "            return self._gen_fname()\n",
        "        return self._format_path(serial)\n",
        "    \n",
        "    def _format_path(self, serial):\n",
        "        return Path(\"%s%s%s\" % (self.prefix, str(serial), self.postfix))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1T7zI6wSRKms",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Base NN model training and testing frame\n",
        "class BaseModel:\n",
        "    def __init__(self, net:nn.Module, optimizer, ckpt_fname_gen:FileNameGenerator, \n",
        "                 device=device, save_dict=False):\n",
        "        super().__init__()\n",
        "        # data transformer for transforming/generating data\n",
        "        self.data_transformer = VocabCardinalTransformer()\n",
        "        # store optimizer\n",
        "        self.optimizer = optimizer\n",
        "        # ckpt name generator\n",
        "        self.ckpt_fname_gen = ckpt_fname_gen\n",
        "        # loss (should be overridden if needed)\n",
        "        self._loss = nn.CrossEntropyLoss()\n",
        "        # device this is trained on\n",
        "        self.device = device\n",
        "        # State of the model\n",
        "        self.training = True\n",
        "        self.best_net_dict = None\n",
        "\n",
        "        # Determines the format to save model (h5 or pt)\n",
        "        self.save_dict = save_dict\n",
        "\n",
        "        self._net = None\n",
        "        if net is not None:\n",
        "            self.net = net\n",
        "\n",
        "    def train_step(self, X_batch, y_batch):\n",
        "        # zero the parameter gradients\n",
        "        self.optimizer.zero_grad()\n",
        "    \n",
        "        # forward + backward + optimize\n",
        "        outputs = self.net.forward(X_batch)\n",
        "        loss = self.loss(outputs, y_batch)\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "        return outputs, loss\n",
        "\n",
        "    def train(self, train_data, val_data=None, epochs=100, batch_size=1024, batch_display_interval=0, \n",
        "              epoch_display_interval=0, epoch_validation_interval=1, ckpt_interval=0, wandb_log=False, \n",
        "              return_trail=True):\n",
        "        if batch_display_interval <= 0:\n",
        "            batch_display_interval = 1e10\n",
        "        if epoch_display_interval <= 0:\n",
        "            epoch_display_interval = 1e10\n",
        "        if ckpt_interval <= 0:\n",
        "            ckpt_interval = 1e10\n",
        "\n",
        "        self.net.to(self.device)\n",
        "        data_gen = self.data_generator(train_data, batch_size=batch_size)\n",
        "\n",
        "        X_val, y_val, val_flag = None, None, False\n",
        "        if epoch_validation_interval <= 0:\n",
        "            epoch_validation_interval = 1000000000\n",
        "        elif val_data is not None:\n",
        "            X_val, y_val = self.data_transformer.transform(val_data)\n",
        "            X_val, y_val = self.process_npbatch(X_val, y_val)\n",
        "            X_val = X_val.to(device)\n",
        "            y_val = y_val.to(device)\n",
        "            val_flag = True\n",
        "\n",
        "        batch = 0\n",
        "        start = time.time()\n",
        "        best_net_loss = np.inf\n",
        "        epoch_loss_trail = {}\n",
        "        epoch_val_loss_trail = {}\n",
        "        epoch_val_eval_trail = {}\n",
        "\n",
        "        # Turns on automatic logging as well\n",
        "        if wandb_log is True:\n",
        "            wandb.watch(self.net, log=\"all\")\n",
        "\n",
        "        if 0 < ckpt_interval < 1e10:\n",
        "            self.save_model(0)\n",
        "        for epoch in range(epochs):\n",
        "            epoch_loss = 0\n",
        "            epoch_size = 0\n",
        "            for X_batch, y_batch, end_epoch in data_gen:\n",
        "                # Send data to the device\n",
        "                X_batch = X_batch.to(self.device)\n",
        "                y_batch = y_batch.to(self.device)\n",
        "                # Train\n",
        "                outputs, loss = self.train_step(X_batch, y_batch)\n",
        "                # Weigh the loss by batch size\n",
        "                epoch_loss += loss * y_batch.size(0)\n",
        "                epoch_size += batch_size\n",
        "\n",
        "                if batch % batch_display_interval == batch_display_interval - 1: \n",
        "                    print('    (%s) Batch: %d, loss: %.4f' %(time_since(start), batch + 1, loss))\n",
        "                batch += 1\n",
        "                # End epoch if data generator exhausted\n",
        "                if end_epoch:\n",
        "                    break\n",
        "\n",
        "            epoch_loss /= epoch_size\n",
        "            epoch_loss_trail[epoch+1] = epoch_loss\n",
        "\n",
        "            # If Validation set is given, then choose the best model according to val set\n",
        "            if val_flag:\n",
        "                if (epoch % epoch_validation_interval == epoch_validation_interval - 1):\n",
        "                    with torch.no_grad():\n",
        "                        # forward\n",
        "                        val_out = self.net.forward(X_val)\n",
        "                        val_loss = self.loss(val_out, y_val)\n",
        "\n",
        "                        # evaluate based on given metrics\n",
        "                        val_eval = self.eval(val_out, y_val)\n",
        "                        epoch_val_loss_trail[epoch+1] = val_loss\n",
        "                        epoch_val_eval_trail[epoch+1] = val_eval\n",
        "\n",
        "                        # print the valiation detail if needed\n",
        "                        self.eval_print(val_eval, epoch+1)\n",
        "\n",
        "                        # Update best model if needed\n",
        "                        if val_loss < best_net_loss:\n",
        "                            best_net_loss = val_loss\n",
        "                            self.best_net_dict = get_net_dict(self.net)\n",
        "                            self.save_model(\"best\")\n",
        "\n",
        "            # Log training loss\n",
        "            if wandb_log is True:\n",
        "                # Validation data also evaluated this epoch\n",
        "                if val_flag and (epoch % epoch_validation_interval == epoch_validation_interval - 1):\n",
        "                    # Log validation evaluations\n",
        "                    wandb.log(\n",
        "                        dict({\"val_loss\": val_loss}, \n",
        "                             **{(\"val_\" + k): v for k, v in val_eval.items()}), \n",
        "                              step=epoch+1, commit=False)\n",
        "                # Log training loss and commit\n",
        "                wandb.log({\"train_loss\": epoch_loss, \n",
        "                           \"epoch\"=epoch+1}, step=epoch+1, commit=True)\n",
        "\n",
        "            # Print training loss\n",
        "            if epoch % epoch_display_interval == epoch_display_interval - 1: \n",
        "                print('(%s) Epoch: %d, batch: %d, loss: %.4f' %(time_since(start), epoch + 1, \n",
        "                                                                batch, epoch_loss))\n",
        "\n",
        "            # If Validation set is given, then use training set to determine best model\n",
        "            elif epoch_loss < best_net_loss:\n",
        "                best_net_loss = epoch_loss\n",
        "                self.best_net_dict = get_net_dict(self.net)\n",
        "                if epoch % ckpt_interval == ckpt_interval - 1: \n",
        "                    self.save_model(\"best\")\n",
        "\n",
        "            # Save a checkpoint of training incase the notebook dc\n",
        "            if epoch % ckpt_interval == ckpt_interval - 1: \n",
        "                self.save_model((epoch+1) // ckpt_interval)\n",
        "\n",
        "        # Finished trianing, load back the best dict\n",
        "        self.net.load_state_dict(self.best_net_dict)\n",
        "\n",
        "        # Log that this run finished (in case of disconnect)\n",
        "        if wandb_log is True:\n",
        "            wandb.log({\"finish\": True})\n",
        "\n",
        "        # Return trail if needed\n",
        "        if return_trail:\n",
        "            if val_flag:\n",
        "                return epoch_loss_trail, epoch_val_loss_trail, epoch_val_eval_trail\n",
        "            return epoch_loss_trail\n",
        "            \n",
        "    def data_generator(self, X, batch_size):\n",
        "        if self.training:\n",
        "            self.fit_transformer(X)\n",
        "        X, y = self.data_transformer.transform(X)\n",
        "        batch_per_epoch = math.ceil(y.shape[0]/batch_size)\n",
        "        while True:\n",
        "            indices = np.arange(y.shape[0])\n",
        "            np.random.shuffle(indices)\n",
        "            X = X[indices]\n",
        "            y = y[indices]\n",
        "            for m in range(batch_per_epoch):\n",
        "                X_batch = X[m * batch_size : (m + 1) * batch_size]\n",
        "                y_batch = y[m * batch_size : (m + 1) * batch_size]\n",
        "                X_batch, y_batch = self.process_npbatch(X_batch, y_batch)\n",
        "                end_epoch = False\n",
        "                if m == batch_per_epoch - 1: end_epoch = True \n",
        "                yield X_batch, y_batch, end_epoch\n",
        "    \n",
        "    def process_npbatch(self, X_batch, y_batch):\n",
        "        return torch.from_numpy(X_batch), torch.from_numpy(y_batch)\n",
        "\n",
        "    def save_model(self, serial=None):\n",
        "        if self.save_dict is False:\n",
        "            self.ckpt_fname_gen.postfix = \".pt\"\n",
        "            save_obj = self.net\n",
        "        else:\n",
        "            self.ckpt_fname_gen.postfix = \".h5\"\n",
        "            save_obj = self.net.state_dict()\n",
        "        path = Path(self.ckpt_fname_gen.write_fname(serial))\n",
        "        print(\"Saving net to: \" , path)\n",
        "        check_create_parent(path)\n",
        "        torch.save(save_obj, path)\n",
        "\n",
        "\n",
        "    def load_model(self, serial=None):\n",
        "        if self.save_dict is False:\n",
        "            self.ckpt_fname_gen.postfix = \".pt\"\n",
        "            path = self.ckpt_fname_gen.read_fname(serial)\n",
        "            print(\"Loading net from: \" , path)\n",
        "            self.net = torch.load(path, map_location=self.device)\n",
        "        else:\n",
        "            self.ckpt_fname_gen.postfix = \".h5\"\n",
        "            path = self.ckpt_fname_gen.read_fname(serial)\n",
        "            print(\"Loading net from: \" , path)\n",
        "            self.net.load_state_dict(torch.load(path, map_location=self.device))\n",
        "\n",
        "    def mode(self, training=True):\n",
        "        self.training = training\n",
        "        self.net.train(training)\n",
        "\n",
        "    @property\n",
        "    def net(self):\n",
        "        return self._net\n",
        "\n",
        "    @net.setter\n",
        "    def net(self, net):\n",
        "        # Store model\n",
        "        self._net = net \n",
        "        # Send to the device\n",
        "        self._net.to(self.device)\n",
        "        # Update best dict\n",
        "        self.best_net_dict = get_net_dict(self._net)\n",
        "\n",
        "    def fit_transformer(self, X):\n",
        "        self.data_transformer.fit(X)\n",
        "        return self\n",
        "\n",
        "    def loss(self, input, target):\n",
        "        return self._loss(input, target)\n",
        "\n",
        "    def eval(self, output, target):\n",
        "        with torch.no_grad():\n",
        "            return None\n",
        "\n",
        "    def eval_print(self, eval, epoch):\n",
        "        pass\n",
        "\n",
        "    def eval_log(self, eval, epoch, type=\"val\"):\n",
        "        pass\n",
        "\n",
        "\n",
        "\n",
        "def visualise_loss_graph(model, data):\n",
        "    \"\"\"\n",
        "    Visualise the computation graph of a model's loss\n",
        "    \"\"\"\n",
        "    X_batch, y_batch, _ = next(model.data_generator(data, batch_size=2))\n",
        "    out, loss = model.train_step(X_batch, y_batch)\n",
        "    param_dict = dict(list(model.net.named_parameters()))\n",
        "    make_dot(loss, params=param_dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzQLkdH2Ms7S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Setup preprocessing\n",
        "\n",
        "# These words affect the reasoning of the sentence\n",
        "negative_words = set([\"no\", \"nor\", \"not\", \"but\"])\n",
        "stop_words = set(sw.words()) - negative_words\n",
        "# Lemmatise the words\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def remove_punctuation(x):\n",
        "    \"\"\"\n",
        "    Remove all non white space or word character in function x\n",
        "    :param x: The sentence to process\n",
        "    :return: str with all non white space or word character removed\n",
        "    \"\"\"\n",
        "    x = re.sub(r'[^\\w\\s]',' ',x)\n",
        "    return x\n",
        "\n",
        "def convert_numbers(x):\n",
        "    \"\"\"\n",
        "    Convert numbers to number token\n",
        "    :param x: The sentence to process\n",
        "    :return: str with all numbers converted accordingly\n",
        "    \"\"\"\n",
        "    # Replace digit of different length with corresponding token\n",
        "    x = re.sub(r'[0-9]{5,}', '5num', x)\n",
        "    x = re.sub(r'[0-9]{4}', '4num', x)\n",
        "    x = re.sub(r'[0-9]{3}', '3num', x)\n",
        "    x = re.sub(r'[0-9]{2}', '2num', x)\n",
        "    # Remove fraction symbols (and other other category symbol)\n",
        "    x = re.sub(r'[½¾]', '', x)\n",
        "    return x\n",
        "\n",
        "def preprocess_texts(X, rm_htmltag=True, expand_contraction=True, to_lower=True, rm_punctuation=True,\n",
        "                     cv_numbers=True, rm_accents=True, stop_words=stop_words, lemmatize=True, min_count=5):\n",
        "    \"\"\"\n",
        "    Preprocess texts with the specified preprocessing procedures\n",
        "    :param X: A list of texts to be processed\n",
        "    :param rm_htmltag: If html tags should be removed\n",
        "    :param expand_contraction: If contraction should be expanded\n",
        "    :param to_lower: If cases should be converted to lower case\n",
        "    :param rm_punctuation: If punctuation should be removed\n",
        "    :param lemmatize: If tokens should be lemmatized\n",
        "    :return: list[list[processed token]]\n",
        "    \"\"\"\n",
        "    if rm_htmltag:\n",
        "        # Use beautiful soup to remove html tags if any\n",
        "        X = [BeautifulSoup(s).get_text() for s in X]\n",
        "\n",
        "    if expand_contraction:\n",
        "        # expand contactions (english only) to normalise text (this before lower case because this will give uppercase)\n",
        "        X = [contractions.fix(s) for s in X]\n",
        "\n",
        "    if to_lower:\n",
        "        # Case folding is necessary to reduce the unique words and removing some irregular case formulation for words.\n",
        "        # Though this may cause the loss of some information (for instance, all CAPPED words have strong emotion),\n",
        "        # it is generally beneficial to smooth the occurances of words\n",
        "        X = [s.lower() for s in X]\n",
        "\n",
        "    if rm_punctuation:\n",
        "        # Remove punctuations is necessary for almost the same reason as the case folding. Here because each tweet is self\n",
        "        # contained, no need to add end of sentence token.\n",
        "        X = [remove_punctuation(s) for s in X]\n",
        "\n",
        "    if cv_numbers:\n",
        "        X = [convert_numbers(s) for s in X]\n",
        "    \n",
        "    if rm_accents:\n",
        "        X = [unidecode(s) for s in X]\n",
        "\n",
        "    # Tokenization is necessary to extract each individual words instead of feeding in raw sentences.\n",
        "    X = [word_tokenize(sent) for sent in X]\n",
        "\n",
        "    # Stop words are NOT removed (yet) for they sometimes affect the sentiment by a lot (like word not, wouldn't)\n",
        "    # If I can get better list and spend more time understanding the data then I will remove them\n",
        "    if stop_words is not False and len(stop_words):\n",
        "        X = [[w for w in tokens if not w in stop_words] for tokens in X]\n",
        "\n",
        "    if lemmatize:\n",
        "        # Lemmatise tokens to reduce the number of unique words, and make the training process easier by reducing the labels\n",
        "        X = [[lemmatizer.lemmatize(w) for w in tokens] for tokens in X]\n",
        "    \n",
        "    if min_count > 1:\n",
        "        all_tokens = [w for tokens in X for w in tokens]\n",
        "        token_set = set(k for k, v in FreqDist(all_tokens).items() if v >= min_count)\n",
        "        X = [[w for w in tokens if w in token_set] for tokens in X]\n",
        "\n",
        "    return X\n",
        "\n",
        "\n",
        "class TextPreprocessTransformer(TransformerMixin):\n",
        "    \"\"\"\n",
        "    Simple transformer class to wrap the previous transformation\n",
        "    \"\"\"\n",
        "    def __init__(self, **kwargs):\n",
        "        self.kwargs = kwargs\n",
        "\n",
        "    def fit(self, X, y=None, **fit_params):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X, y=None):\n",
        "        return preprocess_texts(X, **self.kwargs)\n",
        "\n",
        "\n",
        "# Token -> Ordinal\n",
        "class VocabCardinalTransformer(TransformerMixin):\n",
        "    \"\"\"\n",
        "    Base transformer handling vocabulary related tasks by fitting a vocabulary\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.token_list = []\n",
        "        self.token_dict = {}\n",
        "\n",
        "    def fit(self, X, y=None, **fit_params):\n",
        "        \"\"\"\n",
        "        Fit this transformer with training data to obtain vocabulary\n",
        "        :param X: Training data to be fitted\n",
        "        :param y: Ignored\n",
        "        :param refit: Specifies if this fit should be a refit (reinitialise vocab list) or build upon previous vocab list\n",
        "        :return: itself for chaining\n",
        "        \"\"\"\n",
        "        refit = fit_params.get(\"refit\", False)\n",
        "        token_set = set()\n",
        "        for tokens in X:\n",
        "            token_set |= set(tokens)\n",
        "        if refit:\n",
        "            self.token_list = sorted(token_set)\n",
        "        else:\n",
        "            token_set -= set(self.token_list)\n",
        "            self.token_list += sorted(token_set)\n",
        "        self.token_dict = {w: i for i, w in enumerate(self.token_list)}\n",
        "        return self\n",
        "\n",
        "    def transform(self, X, y=None):\n",
        "        mapped_tokens = []\n",
        "        for tokens in X:\n",
        "            mapped_tokens.append([self.token_dict[t] for t in tokens if t in self.token_dict])\n",
        "        return mapped_tokens\n",
        "\n",
        "\n",
        "def get_topk_tokens(tokens, k=None):\n",
        "    \"\"\"\n",
        "    Get top k tokens from a list of list of tokens with the correspoding count\n",
        "    \"\"\"\n",
        "    tokens = [\" \".join(t) for t in tokens]\n",
        "    cv = CountVectorizer(lowercase=False).fit(tokens)\n",
        "    bag_of_words = cv.transform(tokens)\n",
        "    sum_words = bag_of_words.sum(axis=0) \n",
        "    words_freq = [(word, sum_words[0, idx]) for word, idx in cv.vocabulary_.items()]\n",
        "    words_freq = sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
        "    return words_freq[:k]\n",
        "\n",
        "\n",
        "def show_token_stats(tokens):\n",
        "    \"\"\"\n",
        "    Display the statistics of a list of list of tokens (data)\n",
        "    \"\"\"\n",
        "    tokens = [w for tokens in tokens for w in tokens]\n",
        "    fd = FreqDist(tokens)\n",
        "    sns.distplot([v for v in fd.values() if v < 1000], bins=10, norm_hist=False)\n",
        "    print(len(list(fd.keys())))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqFX-GQvQDkC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# W2V related definitions\n",
        "# First define a dataset generator\n",
        "class SkipGramTransformer(TransformerMixin):\n",
        "    \"\"\"\n",
        "    Transformer class to convert raw list of list of tokens to data to be trained for skipgram model\n",
        "    \"\"\"\n",
        "    def __init__(self, window=10, drop_prob=0):\n",
        "        \"\"\"\n",
        "        Init this transformer with a given window size for sampling skip grams\n",
        "        :param window: The window size for sampling. Note this is the size of one side,\n",
        "            the total number of context sampled is 2 * window\n",
        "        :param drop_prob: Probability dropping a target word, used to increase the stochasticity\n",
        "            and mixing the training data better\n",
        "        \"\"\"\n",
        "        self.window = window\n",
        "        self.drop_prob = drop_prob\n",
        "\n",
        "    def fit(self, X, y=None, **fit_params):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X, y=None):\n",
        "        \"\"\"\n",
        "        Transforms a given dataset (list of list of tokens) to negative gram data (target, context) pair\n",
        "        :param X: The input data\n",
        "        :param y: Ignored\n",
        "        :return: One array of targets and one array of contexts\n",
        "        \"\"\"\n",
        "        skip_grams = []\n",
        "        for tokens in X:\n",
        "            for i in range(len(tokens)):\n",
        "                target = tokens[i]\n",
        "                if np.random.uniform() < self.drop_prob: continue\n",
        "                for k in range(max(i - self.window, 0), min(i + self.window + 1, len(tokens))):\n",
        "                    if k == i: continue\n",
        "                    context = tokens[k]\n",
        "                    skip_grams.append([target, context])\n",
        "        X, y = list(zip(*skip_grams))\n",
        "        return np.array(X), np.array(y)\n",
        "        \n",
        "    def generator(self, X, batch_size=1024): \n",
        "        \"\"\" \n",
        "        Generates a generator for transforming a given dataset (list of list of tokens) to negative \n",
        "        gram data (target, context) pair. The generated generator will generate an array of \n",
        "        target words and array of context words both of shape (batch_size, ). \n",
        "        This is needed because the previous way of generating will exceed the memory \n",
        "        capacity \n",
        "        :param X: The input data \n",
        "        :param y: Ignored \n",
        "        :return: A generator whose __next__ output the following data:\n",
        "            Array of targets, array of contexts, flag specifying if this is the end of a epoch \n",
        "        \"\"\" \n",
        "        # TODO optimise the running time of this\n",
        "        X = copy.deepcopy(X)\n",
        "        skip_gram_pool = np.zeros((0, 2), dtype=int)\n",
        "        idx = 0\n",
        "        while True:\n",
        "            # While the pool is not filled and the data is not cycled to the end, populate pool\n",
        "            # and advance the idx\n",
        "            while skip_gram_pool.shape[0] < batch_size * 3 and idx < len(X):\n",
        "                tokens = X[idx]\n",
        "                skip_grams = []\n",
        "                for i in range(len(tokens)):\n",
        "                    target = tokens[i]\n",
        "                    if np.random.uniform() < self.drop_prob: continue\n",
        "                    for k in range(max(i - self.window, 0), min(i + self.window + 1, len(tokens))):\n",
        "                        if k == i: continue\n",
        "                        context = tokens[k]\n",
        "                        skip_grams.append([target, context])\n",
        "                if len(skip_grams):\n",
        "                    skip_gram_pool = np.concatenate([skip_gram_pool, skip_grams], axis=0)\n",
        "                # Advance idx\n",
        "                idx += 1\n",
        "\n",
        "            # Batch sampling of index\n",
        "            batch_idx = np.random.choice(skip_gram_pool.shape[0], \n",
        "                                         size=min(batch_size, skip_gram_pool.shape[0]), \n",
        "                                         replace=False)\n",
        "            # Epoch end if the data has been cycled through and pool will be empty\n",
        "            end_epoch = (idx >= len(X) and batch_size >= skip_gram_pool.shape[0])\n",
        "            # print(end_epoch, skip_gram_pool.shape[0])\n",
        "            yield skip_gram_pool[batch_idx, 0], skip_gram_pool[batch_idx, 1].reshape(-1), end_epoch\n",
        "            # If this epoch ended, start a new cycle\n",
        "            if end_epoch:\n",
        "                idx %= len(X)\n",
        "                shuffle(X)\n",
        "            skip_gram_pool = np.delete(skip_gram_pool, batch_idx, axis=0)\n",
        "\n",
        "    def generator2(self, X, batch_size=1024): \n",
        "        \"\"\" \n",
        "        Generates a generator for transforming a given dataset (list of list of tokens) to negative \n",
        "        gram data (target, context) pair. The generated generator will generate an array of \n",
        "        target words and array of context words both of shape (batch_size, ). \n",
        "        This is needed because the previous way of generating will exceed the memory \n",
        "        capacity \n",
        "        :param X: The input data \n",
        "        :param y: Ignored \n",
        "        :return: A generator whose __next__ output the following data:\n",
        "            Array of targets, array of contexts, flag specifying if this is the end of a epoch \n",
        "        \"\"\" \n",
        "        X = deepcopy(X)\n",
        "        shuffle(X)\n",
        "        skip_gram_pool = np.zeros((0, 2), dtype=int)\n",
        "        idx = 0\n",
        "        while True:\n",
        "            # While the pool is not filled and the data is not cycled to the end, populate pool\n",
        "            # and advance the idx\n",
        "            while skip_gram_pool.shape[0] < batch_size and idx < len(X):\n",
        "                tokens = X[idx]\n",
        "                skip_grams = []\n",
        "                for i in range(len(tokens)):\n",
        "                    target = tokens[i]\n",
        "                    if np.random.uniform() < self.drop_prob: continue\n",
        "                    for k in range(max(i - self.window, 0), min(i + self.window + 1, len(tokens))):\n",
        "                        if k == i: continue\n",
        "                        context = tokens[k]\n",
        "                        skip_grams.append([target, context])\n",
        "                if len(skip_grams):\n",
        "                    skip_gram_pool = np.concatenate([skip_gram_pool, skip_grams], axis=0)\n",
        "                # Advance idx\n",
        "                idx += 1\n",
        "\n",
        "            # Epoch end if the data has been cycled through and pool will be empty\n",
        "            end_epoch = (idx >= len(X) and batch_size >= skip_gram_pool.shape[0])\n",
        "            # print(end_epoch, skip_gram_pool.shape[0])\n",
        "            yield skip_gram_pool[:batch_size, 0], skip_gram_pool[:batch_size, 1].reshape(-1), end_epoch\n",
        "            # If this epoch ended, start a new cycle\n",
        "            if end_epoch:\n",
        "                idx %= len(X)\n",
        "                shuffle(X)\n",
        "            skip_gram_pool = skip_gram_pool[batch_size:]\n",
        "\n",
        "    def generator3(self, X, batch_size=1024): \n",
        "        \"\"\" \n",
        "        Generates a generator for transforming a given dataset (list of list of tokens) to negative \n",
        "        gram data (target, context) pair. The generated generator will generate an array of \n",
        "        target words and array of context words both of shape (batch_size, ). \n",
        "        This is needed because the previous way of generating will exceed the memory \n",
        "        capacity \n",
        "        :param X: The input data \n",
        "        :param y: Ignored \n",
        "        :return: A generator whose __next__ output the following data:\n",
        "            Array of targets, array of contexts, flag specifying if this is the end of a epoch \n",
        "        \"\"\" \n",
        "        X = copy.deepcopy(X)\n",
        "        skip_gram_pool = set()\n",
        "        idx = 0\n",
        "        while True:\n",
        "            # While the pool is not filled and the data is not cycled to the end, populate pool\n",
        "            # and advance the idx\n",
        "            while len(skip_gram_pool) < batch_size * 3 and idx < len(X):\n",
        "                tokens = X[idx]\n",
        "                for i in range(len(tokens)):\n",
        "                    target = tokens[i]\n",
        "                    if np.random.uniform() < self.drop_prob: continue\n",
        "                    for k in range(max(i - self.window, 0), min(i + self.window + 1, len(tokens))):\n",
        "                        if k == i: continue\n",
        "                        context = tokens[k]\n",
        "                        skip_gram_pool.add((target, context, getrandbits(16)))\n",
        "                # Advance idx\n",
        "                idx += 1\n",
        "\n",
        "            # Epoch end if the data has been cycled through and pool will be empty\n",
        "            end_epoch = (idx >= len(X) and batch_size >= len(skip_gram_pool))\n",
        "            # Generate random sample from the pool\n",
        "            samples = sample(skip_gram_pool, min(batch_size, len(skip_gram_pool)))\n",
        "            X_batch, y_batch, _ = zip(*samples)\n",
        "            yield np.array(X_batch), np.array(y_batch), end_epoch\n",
        "            # If this epoch ended, start a new cycle\n",
        "            if end_epoch:\n",
        "                idx %= len(X)\n",
        "                shuffle(X)\n",
        "            skip_gram_pool -= set(samples)\n",
        "\n",
        "\n",
        "class VocabSkipGramTransformer(TransformerMixin):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        self.vocab_transformer = VocabCardinalTransformer()\n",
        "        self.skip_gram_transformer = SkipGramTransformer(*args, **kwargs)\n",
        "    \n",
        "    def fit(self, X, y=None, **fit_params):\n",
        "        self.vocab_transformer.fit(X, y, **fit_params)\n",
        "        return self\n",
        "\n",
        "    def transform(self, X, y=None):\n",
        "        return self.skip_gram_transformer.transform(self.vocab_transformer.transform(X))\n",
        "\n",
        "    def generator(self, X, batch_size=1024, algorithm=1):\n",
        "        if algorithm == 1: \n",
        "            return (self.skip_gram_transformer\n",
        "                    .generator(self.vocab_transformer.transform(X), \n",
        "                            batch_size=batch_size))\n",
        "        elif algorithm == 2: \n",
        "            return (self.skip_gram_transformer\n",
        "                    .generator2(self.vocab_transformer.transform(X), \n",
        "                            batch_size=batch_size))\n",
        "        elif algorithm == 3: \n",
        "            return (self.skip_gram_transformer\n",
        "                    .generator3(self.vocab_transformer.transform(X), \n",
        "                            batch_size=batch_size))\n",
        "    \n",
        "    @property\n",
        "    def token_list(self):\n",
        "        return copy.copy(self.vocab_transformer.token_list)\n",
        "\n",
        "    @property\n",
        "    def token_dict(self):\n",
        "        return copy.copy(self.vocab_transformer.token_dict)\n",
        "\n",
        "\n",
        "class W2VSkipGramModel(BaseModel):\n",
        "    def __init__(self, window=10, drop_prob=0, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        # text transformer\n",
        "        self.drop_prob = drop_prob\n",
        "        self.data_transformer = VocabSkipGramTransformer(window, drop_prob)\n",
        "\n",
        "    def data_generator(self, X, batch_size):\n",
        "        # Fit vocab only if training\n",
        "        if self.training:\n",
        "            self.fit_transformer(X)\n",
        "        datagen = self.data_transformer.generator(X, batch_size=batch_size)\n",
        "        while True:\n",
        "            X_batch, y_batch, end_epoch = next(datagen)\n",
        "            X_batch = torch.from_numpy(X_batch)\n",
        "            y_batch = torch.from_numpy(y_batch)\n",
        "            yield X_batch, y_batch, end_epoch\n",
        "\n",
        "    def predict(self, X, topk=1, cardinal=False):\n",
        "        with torch.no_grad():\n",
        "            output = self.net.forward(X)\n",
        "            args = torch.argsort(output, dim=1, descending=True).numpy()[:, :topk]\n",
        "            if cardinal:\n",
        "                return args\n",
        "            # single token list\n",
        "            token_list = np.array(self.data_transformer.token_list)\n",
        "            token_lists = np.repeat(token_list[None,...], args.shape[0], axis=0)\n",
        "            return np.take_along_axis(token_lists, args, axis=1)\n",
        "\n",
        "    def lookup(self, X):\n",
        "        with torch.no_grad():\n",
        "            return self.net.embedding(X)\n",
        "\n",
        "    def mode(self, training=True):\n",
        "        super().mode(training)\n",
        "        if not self.training:\n",
        "            self.data_transformer.drop_prob = 0\n",
        "        else:\n",
        "            self.data_transformer.drop_prob = self.drop_prob\n",
        "\n",
        "\n",
        "class W2VSkipGramNet(nn.Module):\n",
        "    def __init__(self, num_embeddings, embedding_dim):\n",
        "        super().__init__()\n",
        "        # linear embedding\n",
        "        self.embedding = nn.Embedding(num_embeddings, embedding_dim)\n",
        "        # linear mapping\n",
        "        self.forward_layer = nn.Linear(embedding_dim, num_embeddings, bias=False)\n",
        "\n",
        "    def forward(self, X):\n",
        "        # forward pass\n",
        "        X = self.embedding(X)\n",
        "        X = self.forward_layer(X)\n",
        "        return X\n",
        "\n",
        "\n",
        "def make_w2v_model(X, embedding_dim, window=5, drop_prob=0, lr=0.001, device=device, \n",
        "                   ckpt_base=\"word\", addtime=False, ckpt_root=drive_path, \n",
        "                   save_dict=True):\n",
        "    \"\"\"\n",
        "    Factory method for generating a w2v sg model\n",
        "    \"\"\"\n",
        "    if addtime:\n",
        "        ckpt_base = ckpt_base + get_time_str()\n",
        "    w2v_fname_gen = FileNameGenerator(Path(ckpt_root)/ckpt_base/\"zhua9812_word\")\n",
        "    num_embeddings = len(VocabSkipGramTransformer(window=window, drop_prob=drop_prob)\n",
        "                          .fit(X).token_list)\n",
        "    w2v_net = W2VSkipGramNet(num_embeddings=num_embeddings, embedding_dim=embedding_dim)\n",
        "    optimizer = Adam(w2v_net.parameters(), lr=lr)\n",
        "    model = W2VSkipGramModel(window=window, drop_prob=drop_prob, net=w2v_net, \n",
        "                             optimizer=optimizer, ckpt_fname_gen=w2v_fname_gen, \n",
        "                             device=device, save_dict=save_dict).fit_transformer(X)\n",
        "    return model\n",
        "\n",
        "\n",
        "def plot_w2v_topk(w2vmodel, tokens_train, method=\"PCA\", k=100, figsize=[8, 8], *args, **kwargs):\n",
        "    # visualise\n",
        "    top_100_tokens, counts = list(zip(*get_topk_tokens(tokens_train, k=k)))\n",
        "    token_dict = w2vmodel.data_transformer.token_dict\n",
        "    top_token_dict = {t: token_dict[t] for t in top_100_tokens}\n",
        "    plt.figure(figsize=figsize)\n",
        "    if method == \"TSNE\":\n",
        "        return plot_embedding_tsne(w2vmodel.net.embedding, top_token_dict, *args, **kwargs)\n",
        "    if method == \"PCA\":\n",
        "        return plot_embedding_pca(w2vmodel.net.embedding, top_token_dict, *args, **kwargs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1hVmx4E52dXS",
        "colab": {}
      },
      "source": [
        "# Character word embedding related\n",
        "class VocabCharacterTransformer(VocabCardinalTransformer):\n",
        "    \"\"\"\n",
        "    Transformer class to convert raw list of list of tokens to data for character embeddig model\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.character_list = []\n",
        "        self.character_dict = {}\n",
        "\n",
        "    def fit(self, X, y=None, **fit_params):\n",
        "        super().fit(X, y, **fit_params)\n",
        "        refit = fit_params.get(\"refit\", False)\n",
        "        character_set = set()\n",
        "        for token in self.token_list:\n",
        "            character_set |= set(token)\n",
        "        if refit:\n",
        "            self.character_list = sorted(character_set)\n",
        "        else:\n",
        "            # get new characters\n",
        "            character_set -= set(self.character_list)\n",
        "            self.character_list += sorted(character_set)\n",
        "        self.character_dict = {w: i for i, w in enumerate(self.character_list)}\n",
        "        return self\n",
        "\n",
        "    def transform(self, X, y=None, include_token=True):\n",
        "        \"\"\"\n",
        "        Transforms a given dataset (list of list of tokens) to character embedding model data\n",
        "        :param X: The input data\n",
        "        :param y: Ignored\n",
        "        :return: One array of cardinal characters and one array of cardinal tokens\n",
        "        \"\"\"\n",
        "        token_list = [token for tokens in X for token in tokens]\n",
        "        # Transform to characters/tokens\n",
        "        characters_list = []\n",
        "        max_len = max([len(token) for token in token_list])\n",
        "\n",
        "        for token in token_list:\n",
        "            characters_list.append([self.character_dict[c] for c in token])\n",
        "        \n",
        "        if include_token:\n",
        "            # Transform token to cardinal form, if found unknown token then mark it with -1\n",
        "            cardinal_token_list = [self.token_dict[token] if token in self.token_dict else -1\n",
        "                                   for token in token_list]\n",
        "            return np.array(characters_list), np.array(cardinal_token_list)\n",
        "        return np.array(characters_list)\n",
        "\n",
        "\n",
        "class CharacterEmbedModel(BaseModel):\n",
        "    def __init__(self, embedding, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.data_transformer = VocabCharacterTransformer()\n",
        "        self._loss = nn.MSELoss()\n",
        "        # embedding for words (freeze the layer to prevent update)\n",
        "        self.embedding = embedding\n",
        "\n",
        "    def predict(self, X):\n",
        "        X = [X]\n",
        "        X, y = self.data_transformer.transform(X)\n",
        "        X, y = self.process_npbatch(X, y)\n",
        "        X = X.to(device)\n",
        "        with torch.no_grad():\n",
        "            return self.net.forward(X)\n",
        "\n",
        "    def get_tokens_embedding(self, X):\n",
        "        X = [X]\n",
        "        X, y = self.data_transformer.transform(X)\n",
        "        X, y = self.process_npbatch(X, y)\n",
        "        y = y.to(device)\n",
        "        return self.embedding(y)\n",
        "\n",
        "    def process_npbatch(self, X, y=None):\n",
        "        X, idxs = sort_pack_chars(X, len(self.data_transformer.character_list))\n",
        "        if y is not None:\n",
        "            y = torch.from_numpy(np.array(y)[idxs])\n",
        "        return X, y\n",
        "\n",
        "    @property\n",
        "    def embedding(self):\n",
        "        return self._embedding\n",
        "\n",
        "    @embedding.setter\n",
        "    def embedding(self, new_embedding):\n",
        "        self._embedding = copy.deepcopy(new_embedding).to(self.device)\n",
        "        for param in self._embedding.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "    def loss(self, input, target):\n",
        "        target = self.embedding(target)\n",
        "        return self._loss(input, target)\n",
        "\n",
        "\n",
        "class CharacterEmbedNet(nn.Module):\n",
        "    def __init__(self, n_input, hidden_size, embedding_dim, dropout=0, num_layers=1, rnn_type=nn.LSTM):\n",
        "        super().__init__()\n",
        "        self.n_input = n_input\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.num_layers = num_layers\n",
        "        \n",
        "        self.rnn = rnn_type(self.n_input, self.hidden_size // 2, self.num_layers, \n",
        "                            batch_first=True, bidirectional=True, dropout=dropout)\n",
        "        self.linear = nn.Linear(self.hidden_size, self.embedding_dim)\n",
        "\n",
        "        self._forward_cache = {}\n",
        "\n",
        "    def forward(self, X):\n",
        "        out = birnn_last_concat(self.rnn, X)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "    def cached_forward(self, X):\n",
        "        # Should check for class, but I am lazy\n",
        "        unpacked_sequences = unpack_sequence(X)\n",
        "        out = []\n",
        "        for sequence in unpacked_sequences:\n",
        "            key = tuple(sequence.detach().numpy().argmax(axis=1))\n",
        "            if key in self._forward_cache:\n",
        "                value = self._forward_cache[key]\n",
        "            else:\n",
        "                value = self.forward(sequence[None])\n",
        "                self._forward_cache[key] = value\n",
        "                value.requires_grad = False\n",
        "            out.append(value)\n",
        "        return torch.cat(out, dim=0)\n",
        "\n",
        "\n",
        "def make_char_model(X, embedding, hidden_size=None, dropout=0, num_layers=1, \n",
        "                    lr=0.001, device=device, ckpt_base=\"character\", addtime=False,\n",
        "                    ckpt_root=drive_path, save_dict=True):\n",
        "    \"\"\"\n",
        "    Factory method for generating a char embedding model\n",
        "    \"\"\"\n",
        "    if addtime:\n",
        "        ckpt_base = ckpt_base + get_time_str()\n",
        "    char_fname_gen = FileNameGenerator(Path(ckpt_root)/ckpt_base/\"zhua9812_character\")\n",
        "    vct = VocabCharacterTransformer().fit(X)\n",
        "    n_input = len(vct.character_list)\n",
        "    embedding_dim = embedding.embedding_dim\n",
        "    if hidden_size is None:\n",
        "        hidden_size = embedding.embedding_dim * 2\n",
        "    char_net = CharacterEmbedNet(n_input=n_input, \n",
        "                                 hidden_size=hidden_size, \n",
        "                                 embedding_dim=embedding_dim,\n",
        "                                 dropout=dropout, \n",
        "                                 num_layers=num_layers)\n",
        "    optimizer = Adam(char_net.parameters(), lr=lr)\n",
        "    model = CharacterEmbedModel(embedding=embedding, net=char_net, optimizer=optimizer, \n",
        "                                ckpt_fname_gen=char_fname_gen, device=device, \n",
        "                                save_dict=save_dict).fit_transformer(X)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iirgBXh9RheN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Sequence model related\n",
        "class SequenceVocabCharacterSentimentTransformer(VocabCharacterTransformer):\n",
        "    def fit(self, X, y=None, **fit_params):\n",
        "        X, y = X\n",
        "        return super().fit(X, y, **fit_params)\n",
        "    \n",
        "    def transform(self, X, y=None):\n",
        "        X, y = X\n",
        "        all_cardinals = np.empty((len(X), 2), dtype=object)\n",
        "        for i, tokens in enumerate(X):\n",
        "            # Only keep valid tokens\n",
        "            tokens = [tokens]\n",
        "            cardinal_chars, cardinal_tokens = super().transform(X=tokens)\n",
        "            all_cardinals[i, 0] = cardinal_chars\n",
        "            all_cardinals[i, 1] = cardinal_tokens\n",
        "        if y is None: \n",
        "            return all_cardinals\n",
        "        return all_cardinals, np.array(y)\n",
        "\n",
        "        \n",
        "class SequenceModel(BaseModel):\n",
        "    def __init__(self, embedding, char_net, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.embedding = embedding\n",
        "        self.char_net = char_net\n",
        "        self.data_transformer = SequenceVocabCharacterSentimentTransformer()\n",
        "\n",
        "    def process_npbatch(self, X_batch, y_batch=None):\n",
        "        cardinal_chars, cardinal_tokens = X_batch[:, 0], X_batch[:, 1]\n",
        "        # for all example in batch\n",
        "        embeddings = []\n",
        "        for n in range(X_batch.shape[0]):\n",
        "            # Data of a sentence\n",
        "            array_chars_list, array_tokens = cardinal_chars[n], cardinal_tokens[n]\n",
        "            # Check if any token is unseen (-1)\n",
        "            missing_idx = [i for i, t in enumerate(array_tokens) if t == -1]\n",
        "            array_tokens = np.array([t if t != -1 else 0 for t in array_tokens])\n",
        "            # Sort to get char embedding\n",
        "            packed_chars, idxs = sort_pack_chars(\n",
        "                array_chars_list, len(self.data_transformer.character_list))\n",
        "            rev_idxs = np.argsort(idxs)\n",
        "            # Get char embedding, and reorder to the original order\n",
        "            char_embedding = self.char_net.forward(packed_chars.to(self.device))[rev_idxs]\n",
        "            # Get token embedding\n",
        "            token_embedding = self.embedding(torch.from_numpy(np.array(array_tokens)).to(self.device))\n",
        "            # Use character base token to impute the token embedding\n",
        "            for idx in missing_idx:\n",
        "                token_embedding[idx] = char_embedding[idx]\n",
        "            # Concat to get the new embedding\n",
        "            embedding = torch.cat([token_embedding, char_embedding], axis=1)\n",
        "            embeddings.append(embedding)\n",
        "        # Sort all embeddings by the sequence length (first dim)\n",
        "        embeddings, idxs = mysorted(embeddings, key=lambda x: x.size(0), reverse=True)\n",
        "        if y_batch is None:\n",
        "            return pack_sequence(embeddings)\n",
        "        return pack_sequence(embeddings), torch.from_numpy(y_batch[idxs])\n",
        "\n",
        "    def forward(self, X):\n",
        "        with torch.no_grad():\n",
        "            X = self.data_transformer.transform([X, None])\n",
        "            X = self.process_npbatch(X)\n",
        "            X = self.net.forward(X)\n",
        "            return X\n",
        "\n",
        "    def predict(self, X):\n",
        "        with torch.no_grad():\n",
        "            X = self.forward(X)\n",
        "            return torch.argmax(X, dim=1)\n",
        "\n",
        "    @property\n",
        "    def char_net(self):\n",
        "        return self._char_net\n",
        "\n",
        "    @char_net.setter\n",
        "    def char_net(self, new_char_net):\n",
        "        self._char_net = copy.deepcopy(new_char_net).to(self.device)\n",
        "        for param in self._char_net.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "    @property\n",
        "    def embedding(self):\n",
        "        return self._embedding\n",
        "\n",
        "    @embedding.setter\n",
        "    def embedding(self, new_embedding):\n",
        "        self._embedding = copy.deepcopy(new_embedding).to(self.device)\n",
        "        for param in self._embedding.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "    def eval(self, out, target):\n",
        "        \"\"\"\n",
        "        Evaluates the output based on Accuracy, F1, Precision, Recall\n",
        "        \"\"\"\n",
        "        with torch.no_grad():\n",
        "            pred = torch.argmax(out, dim=1)\n",
        "            return dict(\n",
        "                loss = self.loss(out, target),\n",
        "                accuracy = accuracy_score(target, pred),\n",
        "                f1 = f1_score(target, pred),\n",
        "                precision = precision_score(target, pred),\n",
        "                recall = recall_score(target, pred))\n",
        "    \n",
        "    def eval_print(self, eval, epoch):\n",
        "        print(\"Validation - epoch %d:\" % epoch)\n",
        "        print(\"    Loss: %.4f\" % eval[\"loss\"])\n",
        "        print(\"    accuracy: %.2f%%\" % (eval[\"accuracy\"] * 100))\n",
        "        print(\"    F1: %.4f\" % eval[\"f1\"])\n",
        "\n",
        "\n",
        "class SequenceNet(nn.Module):\n",
        "    def __init__(self, n_input, hidden_size, dropout=0, num_layers=1, rnn_type=nn.LSTM):\n",
        "        super().__init__()\n",
        "        self.n_input = n_input\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.rnn = rnn_type(self.n_input, self.hidden_size, self.num_layers, \n",
        "                            batch_first=True, bidirectional=True, dropout=dropout)\n",
        "        self.linear = nn.Linear(self.hidden_size * 2, 2)\n",
        "\n",
        "    def forward(self, X):\n",
        "        out = birnn_last_concat(self.rnn, X)\n",
        "        # print(out.size())\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "def make_sequence_model(X, embedding, char_net, hidden_size, dropout=0, num_layers=1, \n",
        "                        lr=0.001, device=device, ckpt_base=\"sequence\", addtime=False, \n",
        "                        ckpt_root=drive_path, save_dict=True):\n",
        "    \"\"\"\n",
        "    Factory method for generating a sequence classification model\n",
        "    \"\"\"\n",
        "    if addtime:\n",
        "        ckpt_base = ckpt_base + get_time_str()\n",
        "    n_input = embedding.embedding_dim * 2\n",
        "    seq_fname_gen = FileNameGenerator(Path(ckpt_root)/ckpt_base/\"zhua9812_sequence\")\n",
        "    seq_net = SequenceNet(n_input=n_input, hidden_size=hidden_size, \n",
        "                          dropout=dropout, num_layers=num_layers)\n",
        "    optimizer = Adam(seq_net.parameters(), lr=lr)\n",
        "    model = SequenceModel(embedding=embedding, char_net=char_net, net=seq_net, \n",
        "                          optimizer=optimizer, ckpt_fname_gen=seq_fname_gen, \n",
        "                          device=device, save_dict=save_dict).fit_transformer(X)\n",
        "    return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRh612wNRsF7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# List of generic hyperparameters\n",
        "# optimizer: lr, *args\n",
        "# epochs, batch_size\n",
        "# w2v: embedding_dim, window, drop_prob\n",
        "# char: ?[gru, lstm, rnn], hidden_size, dropout, num_layers\n",
        "# seq: ?[gru, lstm, rnn], hidden_size, dropout, num_layers\n",
        "\n",
        "def run_seq_model_experiments(configs_path=seq_configs_path, train_path=train_path, val_path=test_path):\n",
        "    configs = read_json(seq_configs_path)\n",
        "    num_configs = len(configs[\"lr\"])\n",
        "    for config in configs:\n",
        "        # This hasn't been done yet\n",
        "        if config.get(\"id\", None) is not None:\n",
        "            continue\n",
        "        tokens_train, label_train, sentiments_train = load_feather(train_path)\n",
        "        tokens_test, label_test, sentiments_test = load_feather(test_path)\n",
        "        ckpt_root = Path(config[\"ckpt_root\"])\n",
        "\n",
        "        w2v_model = make_w2v_model(tokens_train, embedding_dim=config[\"w2v.embedding_dim\"], \n",
        "                                   ckpt_root=ckpt_root)\n",
        "        w2v_model.load_model(\"best\")\n",
        "        w2v_model.training(False)\n",
        "        w2v_embedding = w2v_model.net.embedding\n",
        "\n",
        "        char_model = make_char_model(tokens_train, embedding=w2v_embedding, \n",
        "                                     hidden_size=config[\"char.hidden_size\"], \n",
        "                                     ckpt_root=ckpt_root)\n",
        "        char_model.load_model(\"best\")\n",
        "        char_model.training(False)\n",
        "        char_net = char_model.net\n",
        "\n",
        "        train_data = [tokens_train, label_train]\n",
        "        val_data = [tokens_test, label_test]\n",
        "\n",
        "        sequence_model = make_sequence_model([tokens_train, label_train], embedding=w2v_embedding, \n",
        "                                             char_net=char_net, hidden_size=config[\"seq.hidden_size\"], \n",
        "                                             lr=config[\"lr\"], ckpt_root=ckpt_root)\n",
        "\n",
        "        sequence_model.training(True)\n",
        "        seq_net.train(train_data=train_data, val_data=val_data, epochs=config[\"epochs\"], \n",
        "                      batch_size=config[\"batch_size\"], epoch_display_interval=1, ckpt_interval=1, \n",
        "                      wandb_log=True, return_trail=False)\n",
        "\n",
        "\n",
        "def add_seq_model_config(config_path=seq_configs_path, embedding_dim=64, char_hidden_size=128, \n",
        "                         seq_hidden_size=32, lr=0.001, epochs=1000, batch_size=1024, \n",
        "                         ckpt_root=str(drive_path)):\n",
        "    print(\"Adding config to file - %s.\" % config_path)\n",
        "    model = \"sequence\"\n",
        "    config = {\n",
        "     \"model\": model,\n",
        "     \"w2v.embedding_dim\": embedding_dim,\n",
        "     \"char.hidden_size\": char_hidden_size,\n",
        "     \"seq.hidden_size\": seq_hidden_size,\n",
        "     \"lr\": lr,\n",
        "     \"epochs\": epochs,\n",
        "     \"batch_size\": batch_size,\n",
        "     \"ckpt_root\": ckpt_root\n",
        "    }\n",
        "    configs = []\n",
        "    try:\n",
        "        configs = read_json(config_path)\n",
        "    except FileNotFoundError:\n",
        "        print(\"File Not exist, creating new file.\")\n",
        "        check_create_parent(config_path)\n",
        "    for _config in configs:\n",
        "        if config == config:\n",
        "            print(\"Config exists in file.\")\n",
        "            break\n",
        "    else:\n",
        "        configs.append(config)\n",
        "        with open(config_path, \"w\") as fp:\n",
        "            json.dump(configs, fp)\n",
        "        print(\"Adding successful.\")\n",
        "\n",
        "    return config\n",
        "\n",
        "\n",
        "def extract_seq_model_performances(runs):\n",
        "    performance_df = pd.DataFrame(columns=[\"epoch\", \"lr\", \"hidden_size\", \"dropout\", \"val_loss\", \n",
        "                                           \"val_accuracy\", \"val_f1\", \"val_precision\", \"val_recall\"])\n",
        "    for run in runs:\n",
        "        history = run.scan_history(keys=[\"val_loss\", \"val_accuracy\", \"val_f1\", \n",
        "                                         \"val_precision\", \"val_recall\", \"epoch\"])\n",
        "        lr = run.config[\"seq_lr\"]\n",
        "        hidden_size = run.config[\"seq_hidden_size\"]\n",
        "        dropout = run.config[\"seq_dropout\"]\n",
        "        rnn_type = run.config[\"seq_rnn_type\"]\n",
        "        num_layers = run.config[\"seq_num_layers\"]\n",
        "        val_loss = [row[\"val_loss\"] for row in history]\n",
        "        val_accuracy = [row[\"val_accuracy\"] for row in history]\n",
        "        val_f1 = [row[\"val_f1\"] for row in history]\n",
        "        val_precision = [row[\"val_precision\"] for row in history]\n",
        "        val_recall = [row[\"val_recall\"] for row in history]\n",
        "        epoch = [row[\"epoch\"] for row in history]\n",
        "\n",
        "        for i in range(len(val_loss)):\n",
        "            performance_df.append(dict(\n",
        "                lr=lr,\n",
        "                hidden_size=hidden_size,\n",
        "                dropout=dropout,\n",
        "                val_loss=val_loss[i],\n",
        "                val_accuracy=val_accuracy[i],\n",
        "                val_f1=val_f1[i],\n",
        "                val_precision=val_precision[i],\n",
        "                val_recall=val_recall[i],\n",
        "                epoch=epoch[i],\n",
        "            ), ignore_index=True)\n",
        "\n",
        "    performance_df.columns = [\"Epoch\", \"Learning Rate\", \"Hidden size\", \"Dropout\", \"Loss\", \n",
        "                              \"Accuracy\", \"F1 Score\", \"Precision\", \"Recall\"]\n",
        "    return performance_df\n",
        "\n",
        "\n",
        "def plot_seq_performances(df):\n",
        "    fig, axes = plt.subplots(nrows=5, ncols=1, figsize=[10, 30])\n",
        "    iter_axes = iter(axes)\n",
        "    for data_type in (\"Loss\", \"Accuracy\", \"F1 Score\", \"Precision\", \"Recall\"):\n",
        "        sns.lineplot(data=df,\n",
        "                    x=\"Epoch\",\n",
        "                    y=data_type,\n",
        "                    hue=\"Hidden size\",\n",
        "                    size=\"Learning Rate\",\n",
        "                    # style=\"Dropout\",\n",
        "                    legend=\"full\",\n",
        "                    ax=next(iter_axes)\n",
        "                    )\n",
        "    return fig"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpGJDQJr9jlf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# List of generic hyperparameters\n",
        "# optimizer: lr, *args\n",
        "# epochs, batch_size\n",
        "# w2v: embedding_dim, window, drop_prob\n",
        "# char: ?[gru, lstm, rnn], hidden_size, dropout, num_layers\n",
        "# seq: ?[gru, lstm, rnn], hidden_size, dropout, num_layers\n",
        "\n",
        "# Configure the sweep – specify the parameters to search through, the search strategy, \n",
        "# the optimization metric et all.\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85as-bOvOdQR",
        "colab_type": "code",
        "outputId": "5f272367-ed3f-428f-9ae0-cefbf73c4c02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def sweep_w2v_model():\n",
        "    config_defaults = {\n",
        "        \"w2v_lr\": 1e-3,\n",
        "        \"w2v_epochs\": 50,\n",
        "        \"w2v_batch_size\": 1024,\n",
        "        \"w2v_embedding_dim\": 64,\n",
        "        \"w2v_window\": 5,\n",
        "        \"w2v_drop_prob\": 0.5,\n",
        "        \"ckpt_root\": drive_path,\n",
        "        \"model\": \"w2v\"\n",
        "    }\n",
        "    run = wandb_init(config_defaults, tags=[\"w2v_sweep\"], notes=\"Sweep run for w2v\")\n",
        "    config = wandb.config\n",
        "\n",
        "    tokens_train, label_train, sentiments_train = load_feather(train_path)\n",
        "    tokens_test, label_test, sentiments_test = load_feather(test_path)\n",
        "    ckpt_root = config.ckpt_root\n",
        "\n",
        "    w2v_model = make_w2v_model(tokens_train, embedding_dim=config.w2v_embedding_dim, ckpt_root=ckpt_root)\n",
        "    print(\"==================== Start training ====================\")\n",
        "    print(str(config))\n",
        "    w2v_model.train(train_data=tokens_train, epochs=config.w2v_epochs, batch_size=config.w2v_batch_size, \n",
        "                    epoch_display_interval=1, ckpt_interval=1, wandb_log=True, return_trail=False)\n",
        "\n",
        "w2v_sweep_config = {\n",
        "    \"method\": \"random\", #grid, random\n",
        "    \"metric\": {\n",
        "      \"name\": \"train_loss\",\n",
        "      \"goal\": \"minimize\",\n",
        "    },\n",
        "    \"early_terminate\": \"hyperband\",\n",
        "    \"parameters\": {\n",
        "        \"w2v_drop_prob\": {\n",
        "            \"values\": [0, 0.5, 0.8]\n",
        "        },\n",
        "        \"w2v_lr\": {\n",
        "            \"values\": [1e-2, 1e-3, 1e-4, 3e-4, 3e-5, 1e-5]\n",
        "        },\n",
        "        \"w2v_epochs\": {\n",
        "            \"values\": [25, 50, 100]\n",
        "        },\n",
        "        \"w2v_window\": {\n",
        "            \"values\": [2, 4, 6]\n",
        "        },\n",
        "        \"w2v_embedding_dim\": {\n",
        "            \"values\": [32, 64, 128]\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "w2v_sweep_id = wandb.sweep(w2v_sweep_config)\n",
        "wandb.agent(w2v_sweep_id, sweep_w2v_model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Create sweep with ID: 5ql786u0\n",
            "Sweep URL: https://app.wandb.ai/dovermore/comp5046-assignment1/sweeps/5ql786u0\n",
            "wandb: Agent Starting Run: 00exmu4p with config:\n",
            "\tw2v_drop_prob: 0.8\n",
            "\tw2v_embedding_dim: 32\n",
            "\tw2v_epochs: 100\n",
            "\tw2v_lr: 1e-05\n",
            "\tw2v_window: 4\n",
            "wandb: Agent Started Run: 00exmu4p\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/dovermore/comp5046-assignment1\" target=\"_blank\">https://app.wandb.ai/dovermore/comp5046-assignment1</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/dovermore/comp5046-assignment1/runs/188wj1yk\" target=\"_blank\">https://app.wandb.ai/dovermore/comp5046-assignment1/runs/188wj1yk</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "==================== Start training ====================\n",
            "wandb_version: 1\n",
            "\n",
            "_wandb:\n",
            "  desc: null\n",
            "  value:\n",
            "    cli_version: 0.8.31\n",
            "    is_jupyter_run: true\n",
            "    is_kaggle_kernel: false\n",
            "    python_version: 3.6.9\n",
            "ckpt_root:\n",
            "  desc: null\n",
            "  value: /content/drive/My Drive/COMP5046-assignment1\n",
            "model:\n",
            "  desc: null\n",
            "  value: w2v\n",
            "w2v_batch_size:\n",
            "  desc: null\n",
            "  value: 1024\n",
            "w2v_drop_prob:\n",
            "  desc: null\n",
            "  value: 0.5\n",
            "w2v_embedding_dim:\n",
            "  desc: null\n",
            "  value: 64\n",
            "w2v_epochs:\n",
            "  desc: null\n",
            "  value: 50\n",
            "w2v_lr:\n",
            "  desc: null\n",
            "  value: 0.001\n",
            "w2v_window:\n",
            "  desc: null\n",
            "  value: 5\n",
            "\n",
            "Saving net to:  /content/drive/My Drive/COMP5046-assignment1/word/zhua9812_word0.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl-c pressed. Waiting for runs to end. Press ctrl-c again to terminate them.\n",
            "Process Process-5:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/wandb/wandb_agent.py\", line 64, in _start\n",
            "    function()\n",
            "  File \"<ipython-input-254-a3c7364f6d54>\", line 23, in sweep_w2v_model\n",
            "    epoch_display_interval=1, ckpt_interval=1, wandb_log=True, return_trail=False)\n",
            "  File \"<ipython-input-243-7be92b921f30>\", line 81, in train\n",
            "    outputs, loss = self.train_step(X_batch, y_batch)\n",
            "  File \"<ipython-input-243-7be92b921f30>\", line 31, in train_step\n",
            "    outputs = self.net.forward(X_batch)\n",
            "  File \"<ipython-input-245-12a1c890b487>\", line 260, in forward\n",
            "    X = self.forward_layer(X)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 532, in __call__\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/linear.py\", line 87, in forward\n",
            "    return F.linear(input, self.weight, self.bias)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\", line 1372, in linear\n",
            "    output = input.matmul(weight.t())\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Error in callback <function _init_jupyter.<locals>.cleanup at 0x7ff361dd47b8> (for post_run_cell):\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/wandb/__init__.py\u001b[0m in \u001b[0;36mcleanup\u001b[0;34m()\u001b[0m\n\u001b[1;32m    486\u001b[0m         \u001b[0;31m# shutdown async logger because _user_process_finished isn't called in jupyter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m         \u001b[0mshutdown_async_log_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 488\u001b[0;31m         \u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop_jupyter_agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m     \u001b[0mipython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'post_run_cell'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcleanup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/wandb/wandb_run.py\u001b[0m in \u001b[0;36m_stop_jupyter_agent\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_stop_jupyter_agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jupyter_agent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/wandb/jupyter.py\u001b[0m in \u001b[0;36mstop\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpaused\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munmirror_stdout_stderr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m             \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpaused\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/wandb/run_manager.py\u001b[0m in \u001b[0;36mshutdown\u001b[0;34m(self, exitcode)\u001b[0m\n\u001b[1;32m   1083\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cloud\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"stopping streaming files and file change observer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1085\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_end_file_syncing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexitcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1086\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/wandb/run_manager.py\u001b[0m in \u001b[0;36m_end_file_syncing\u001b[0;34m(self, exitcode)\u001b[0m\n\u001b[1;32m    668\u001b[0m         \u001b[0;31m# TODO: there was a case where _file_event_handlers was getting modified in the loop.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file_event_handlers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m             \u001b[0mhandler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    671\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file_pusher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/wandb/run_manager.py\u001b[0m in \u001b[0;36mfinish\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfinish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tailer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tailer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tailer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/wandb/run_manager.py\u001b[0m in \u001b[0;36mstop\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1070\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# already determined that the C code is done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1072\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1073\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYFLaVoIOxRY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}