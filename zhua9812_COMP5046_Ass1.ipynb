{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "zhua9812_COMP5046_Ass1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dovermore/COMP5046-ass1/blob/master/zhua9812_COMP5046_Ass1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGHoy6KpQDfZ",
        "colab_type": "text"
      },
      "source": [
        "# COMP5046 Assignment 1\n",
        "*Make sure you change the file name with your unikey.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTf21j_oQIiD",
        "colab_type": "text"
      },
      "source": [
        "# Readme\n",
        "*If there is something to be noted for the user, please mention here.* \n",
        "\n",
        "*If you are planning to implement a program with Object Oriented Programming style*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXbQohXLKSgO",
        "colab_type": "text"
      },
      "source": [
        "***Visualising the comparison of different results is a good way to justify your decision.***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34DVNKgqQY21",
        "colab_type": "text"
      },
      "source": [
        "# 1 - Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cWUxAQrGlq6",
        "colab_type": "text"
      },
      "source": [
        "## 1.1. Download Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7C4snIcNl22",
        "colab_type": "code",
        "outputId": "d85ca700-3548-4d84-a4d6-9133207e6c37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Code to download file into Colaboratory:\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "id = '1vF3FqgBC1Y-RPefeVmY8zetdZG1jmHzT'\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('imdb_train.csv')\n",
        "\n",
        "id = '1XhaV8YMuQeSwozQww8PeyiWMJfia13G6'\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('imdb_test.csv')\n",
        "\n",
        "import pandas as pd\n",
        "df_train = pd.read_csv(\"imdb_train.csv\")\n",
        "df_test = pd.read_csv(\"imdb_test.csv\")\n",
        "\n",
        "reviews_train = df_train['review'].tolist()\n",
        "sentiments_train = df_train['sentiment'].tolist()\n",
        "reviews_test = df_test['review'].tolist()\n",
        "sentiments_test = df_test['sentiment'].tolist()\n",
        "\n",
        "print(\"Training set number:\",len(reviews_train))\n",
        "print(\"Testing set number:\",len(reviews_test))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training set number: 25000\n",
            "Testing set number: 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9gBSgBCQh24",
        "colab_type": "text"
      },
      "source": [
        "## 1.2. Preprocess data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8RdKI8E2KRwe",
        "colab_type": "text"
      },
      "source": [
        "*You are required to describe which data preprocessing techniques were conducted with justification of your decision. *"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFZbZzDOOT8X",
        "colab_type": "code",
        "outputId": "93cc5056-5c46-470d-e2cb-556f39564159",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "!pip install beautifulsoup4\n",
        "!pip install contractions"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (4.6.3)\n",
            "Requirement already satisfied: contractions in /usr/local/lib/python3.6/dist-packages (0.0.24)\n",
            "Requirement already satisfied: textsearch in /usr/local/lib/python3.6/dist-packages (from contractions) (0.0.17)\n",
            "Requirement already satisfied: Unidecode in /usr/local/lib/python3.6/dist-packages (from textsearch->contractions) (1.1.1)\n",
            "Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.6/dist-packages (from textsearch->contractions) (1.4.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emyl1lWxGr12",
        "colab_type": "code",
        "outputId": "85bbb437-ced2-453b-88ef-aa738861c245",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# Please comment your code\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.base import TransformerMixin\n",
        "\n",
        "import copy\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "import contractions\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "# nltk.download('stopwords')\n",
        "# from nltk.corpus import stopwords as sw\n",
        "\n",
        "# eng_stopwords = sw.words(\"english\")\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "\n",
        "def remove_punctuation(x):\n",
        "    \"\"\"\n",
        "    Removes punctuation from a string x\n",
        "    \"\"\"\n",
        "    x = re.sub(r'[^\\w\\s]','',x)\n",
        "    return x\n",
        "\n",
        "def preprocess_texts(X):\n",
        "    # Use beautiful soup to remove html tags if any\n",
        "    X = [BeautifulSoup(s).get_text() for s in X]\n",
        "\n",
        "    # expand contactions (english only) to normalise text (this before lower case because this will give uppercase)\n",
        "    X = [contractions.fix(s) for s in X]\n",
        "\n",
        "    # Case folding is necessary to reduce the unique words and removing some irregular case formulation for words. \n",
        "    # Though this may cause the loss of some information (for instance, all CAPPED words have strong emotion), \n",
        "    # it is generally beneficial to smooth the occurances of words\n",
        "    X = [s.lower() for s in X]\n",
        "\n",
        "    # Remove punctuations is necessary for almost the same reason as the case folding. Here because each tweet is self \n",
        "    # contained, no need to add end of sentence token.\n",
        "    X = [remove_punctuation(s) for s in X]\n",
        "\n",
        "    # Tokenization is important to extract each individual words instead of feeding in raw sentences.\n",
        "    X = [word_tokenize(sent) for sent in X]\n",
        "\n",
        "    # Stop words are NOT removed (yet) for they sometimes affect the sentiment by a lot (like word not, wouldn't)\n",
        "    # If I can get better list and spend more time understanding the data then I will remove them\n",
        "\n",
        "    # Lemmatise tokens to reduce the number of unique words, and make the training process easier by reducing the labels\n",
        "    X = [[lemmatizer.lemmatize(w) for w in tokens] for tokens in X]\n",
        "    \n",
        "    return X\n",
        "\n",
        "\n",
        "class TextPreprocessTransformer(TransformerMixin):\n",
        "    \"\"\n",
        "    def fit(self, X, y=None, **fit_params):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X, y=None, **fit_params):\n",
        "        return preprocess_texts(X)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcGFbmqUog4E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tpt = TextPreprocessTransformer()\n",
        "texts_train = tpt.fit_transform(reviews_train)\n",
        "texts_test = tpt.fit_transform(reviews_test)\n",
        "print(texts_train[:2])\n",
        "print(texts_test[:2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bi9n4bYwondw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_encoder = LabelEncoder()\n",
        "label_train = label_encoder.fit_transform(sentiments_train)\n",
        "label_test = label_encoder.transform(sentiments_test)\n",
        "print(label_train[:50])\n",
        "print(label_test[:50])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIu_lkJwQ55g",
        "colab_type": "text"
      },
      "source": [
        "# 2 - Model Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "daDvAftceIvr",
        "colab_type": "text"
      },
      "source": [
        "## 2.1. Word Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbzm-NWBTmM-",
        "colab_type": "text"
      },
      "source": [
        "*You are required to describe which model was implemented (i.e. Word2Vec with CBOW, FastText with SkipGram, etc.) with justification of your decision *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXgFpxIgl-_G",
        "colab_type": "text"
      },
      "source": [
        "### 2.1.1. Data Preprocessing for Word Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJrVHGYSmYMg",
        "colab_type": "text"
      },
      "source": [
        "*You are required to describe which preprocessing techniques were used with justification of your decision.*\n",
        "\n",
        "**Important**: If you are going to use the code from lab3 word2vec preprocessing. Please note that `word_list = list(set(word_list)) ` has randomness. So to make sure the word_list is the same every time you run it, you can put `word_list.sort()` after that line of code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cM4rlYkHefJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.base import TransformerMixin\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "# The following code implements Word2Vec with Skip-gram. For it is simple and straightforward to implement and there\n",
        "# is previous code base in previous labs\n",
        "\n",
        "# First define a dataset generator\n",
        "class SkipGramTransformer(TransformerMixin):\n",
        "    def __init__(self, window=10):\n",
        "        self.window = window\n",
        "        self.token_list = []\n",
        "        self.token_dict = {}\n",
        "\n",
        "    def fit(self, X, y=None, **fit_params):\n",
        "        refit = fit_params.get(\"refit\", False)\n",
        "        token_set = set()\n",
        "        for tokens in X:\n",
        "            token_set |= set(tokens)\n",
        "        if refit:\n",
        "            self.token_list = list(token_set)\n",
        "        else:\n",
        "            token_set -= set(self.token_list)\n",
        "            self.token_list += list(token_set)\n",
        "        self.token_dict = {w: i for i, w in enumerate(self.token_list)}\n",
        "        return self\n",
        "    \n",
        "    def transform(self, X, y=None):\n",
        "        skip_grams = []\n",
        "        for tokens in X:\n",
        "            for i in range(len(tokens)):\n",
        "                target = self.token_dict.get(tokens[i], None)\n",
        "                if target is None: continue\n",
        "                for k in range(max(i - self.window, 0), min(i + self.window, len(tokens))):\n",
        "                    if k == i:\n",
        "                        continue\n",
        "                    context = self.token_dict.get(tokens[k], None)\n",
        "                    if context is None: continue\n",
        "                    skip_grams.append([target, context])\n",
        "        return list(zip(*skip_grams))\n",
        "\n",
        "    def generator(self, X, batch_size=1024, pool_size=5120):\n",
        "        skip_gram_pool = np.zeros((0, 2), dtype=int)\n",
        "        idx = 0\n",
        "        while True:\n",
        "            end_epoch = False\n",
        "            while skip_gram_pool.shape[0] < pool_size:\n",
        "                tokens = X[idx]\n",
        "                skip_grams = []\n",
        "                for i in range(len(tokens)):\n",
        "                    target = self.token_dict.get(tokens[i], None)\n",
        "                    if target is None: continue\n",
        "                    for k in range(max(i - self.window, 0), min(i + self.window, len(tokens))):\n",
        "                        if k == i:\n",
        "                            continue\n",
        "                        context = self.token_dict.get(tokens[k], None)\n",
        "                        if context is None: continue\n",
        "                        skip_grams.append([target, context])\n",
        "                skip_gram_pool = np.concatenate([skip_gram_pool, skip_grams], axis=0)\n",
        "                idx += 1\n",
        "                if idx >= len(X):\n",
        "                    end_epoch = True\n",
        "                idx %= len(X)\n",
        "            batch_idx = np.random.choice(skip_gram_pool.shape[0], size=batch_size, replace=False)\n",
        "            yield skip_gram_pool[batch_idx, 0], skip_gram_pool[batch_idx, 1].reshape(-1), end_epoch \n",
        "            skip_gram_pool = np.delete(skip_gram_pool, batch_idx, axis=0)\n",
        "\n",
        "\n",
        "    def fit_transform(self, X, y=None, **fit_params):\n",
        "        self.fit(X, y, **fit_params)\n",
        "        return self.transform(X, y)\n",
        "\n",
        "\n",
        "from sklearn.pipeline import make_pipeline, Pipeline\n",
        "skip_gram_pipeline = make_pipeline(TextPreprocessTransformer(), SkipGramTransformer())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uDh28ZM8a3ma",
        "colab": {}
      },
      "source": [
        "# Test\n",
        "sgt = SkipGramTransformer()\n",
        "test_data = np.array(range(10)).reshape(5, 2).tolist()\n",
        "sgt.fit(test_data)\n",
        "i = 0\n",
        "for i, (a, b, c) in enumerate(sgt.generator(test_data, 2, 10)):\n",
        "    print(i, a, b, c)\n",
        "    if i > 20:\n",
        "        break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbUw3gEwGqa7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Profile time\n",
        "sgt = SkipGramTransformer()\n",
        "sgt.fit(texts_train)\n",
        "datagen = sgt.generator(texts_train)\n",
        "%timeit next(datagen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhAgWf_AmbZ8",
        "colab_type": "text"
      },
      "source": [
        "### 2.1.2. Build Word Embeddings Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJ8rU7JbiBVS",
        "colab_type": "text"
      },
      "source": [
        "*You are required to describe how hyperparameters were decided with justification of your decision.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVPuwWgvNjOU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils import data\n",
        "from torch.optim import Adam\n",
        "from datetime import datetime\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "class BaseModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # store optimizer\n",
        "        self.optimizer = None \n",
        "\n",
        "    def train_step(self, X_batch, y_batch):\n",
        "        # zero the parameter gradients\n",
        "        self.optimizer.zero_grad()\n",
        "    \n",
        "        # forward + backward + optimize\n",
        "        outputs = self.forward(X_batch)\n",
        "        loss = self.loss_fn(outputs, y_batch)\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "        return outputs, loss\n",
        "\n",
        "    def train(self, data, epochs, batch_size=1024, batch_display_interval=10000, epoch_display_interval=100, data_gen_dict={}):\n",
        "        if batch_display_interval <= 0:\n",
        "            batch_display_interval = 1000000000\n",
        "        if epoch_display_interval <= 0:\n",
        "            epoch_display_interval = 1000000000\n",
        "        data_gen = self.data_generator(data, batch_size=batch_size, **data_gen_dict)\n",
        "        batch = 0\n",
        "        for epoch in range(epochs):\n",
        "            epoch_loss = 0\n",
        "            epoch_size = 0\n",
        "            for X_batch, y_batch, end_epoch in data_gen:\n",
        "                X_batch = torch.from_numpy(X_batch).to(device)\n",
        "                y_batch = torch.from_numpy(y_batch).to(device)\n",
        "                # Train\n",
        "                outputs, loss = self.train_step(X_batch, y_batch)\n",
        "                epoch_loss += loss * batch_size\n",
        "                epoch_size += batch_size\n",
        "                batch += 1\n",
        "                if batch % batch_display_interval == batch_display_interval: \n",
        "                    print('    Batch: %d, loss: %.4f' %(batch, loss))\n",
        "                if end_epoch:\n",
        "                    break\n",
        "            epoch_loss /= epoch_size\n",
        "            if epoch % epoch_display_interval == epoch_display_interval - 1: \n",
        "                print('Epoch: %d, loss: %.4f' %(epoch + 1, epoch_loss))\n",
        "\n",
        "    def data_generator(self, X, batch_size, **kwargs):\n",
        "        pass\n",
        "\n",
        "    def set_optimizer(self, optimizer):\n",
        "        self.optimizer = optimizer\n",
        "\n",
        "\n",
        "# Define model\n",
        "class W2VSkipGram(BaseModel):\n",
        "    def __init__(self, num_embeddings, embedding_dim, window=10, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        # linear embedding\n",
        "        self.embedding_layer = nn.Embedding(num_embeddings, embedding_dim)\n",
        "        # linear mapping\n",
        "        self.forward_layer = nn.Linear(embedding_dim, num_embeddings, bias=False)\n",
        "        # text transformer\n",
        "        self.skip_gram_transformer = SkipGramTransformer(window)\n",
        "        self.loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "    def forward(self, X):\n",
        "        # forward pass\n",
        "        return self.forward_layer(self.embedding_layer(X))\n",
        "\n",
        "    def data_generator(self, X, batch_size, **kwargs):\n",
        "        # Fit vocab only if training\n",
        "        if self.training:\n",
        "            self.skip_gram_transformer.fit(X)\n",
        "        return self.skip_gram_transformer.generator(X, batch_size=batch_size, **kwargs)\n",
        "\n",
        "    def predict(self, X):\n",
        "        output = self.forward(X)\n",
        "        return output.argmax(dim=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZiCbqdxA4lgV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data = np.array(range(4)).reshape(2, 2).tolist()\n",
        "test_model = W2VSkipGram(4, 4).to(device)\n",
        "optimizer = Adam(test_model.parameters())\n",
        "test_model.set_optimizer(optimizer)\n",
        "datagen = test_model.data_generator(test_data, batch_size=2, pool_size=4)\n",
        "next(datagen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7eDG7Zb7Sju",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_X = torch.from_numpy(np.array([0, 1, 2, 3])).to(device)\n",
        "_y = torch.from_numpy(np.array([1, 0, 3, 2]))\n",
        "# Before\n",
        "print(test_model.forward(_X), test_model.predict(_X))\n",
        "test_model.train(test_data, 1000, 2, batch_display_interval=0, epoch_display_interval=0, data_gen_dict={\"pool_size\":2})\n",
        "# After\n",
        "# Overfit the small dataset\n",
        "print(test_model.forward(_X), test_model.predict(_X))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wG_rbQxPHsWk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# profile step time\n",
        "sgt = SkipGramTransformer().fit(texts_train)\n",
        "num_embeddings = len(sgt.token_list)\n",
        "test_model = W2VSkipGram(num_embeddings, 64).to(device)\n",
        "optimizer = Adam(test_model.parameters())\n",
        "test_model.set_optimizer(optimizer)\n",
        "datagen = test_model.data_generator(texts_train, batch_size=1024, pool_size=5000)\n",
        "X_batch, y_batch, _ = next(datagen)\n",
        "X_batch = torch.from_numpy(X_batch).to(device)\n",
        "y_batch = torch.from_numpy(y_batch).to(device)\n",
        "%timeit -n 10 test_model.train_step(X_batch, y_batch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNys5HOdISK-",
        "colab_type": "text"
      },
      "source": [
        "### 2.1.3. Train Word Embeddings Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ae8i7Z2kIef-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sgt = SkipGramTransformer().fit(texts_train)\n",
        "num_embeddings = len(sgt.token_list)\n",
        "embedding_dim = 64\n",
        "w2v_model = W2VSkipGram(num_embeddings, embedding_dim)\n",
        "optimizer = Adam(w2v_model.parameters())\n",
        "w2v_model.set_optimizer(optimizer)\n",
        "w2v_model.train(texts_train, 2, batch_display_interval=100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMCv3YI1IfUo",
        "colab_type": "text"
      },
      "source": [
        "### 2.1.4. Save Word Embeddings Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OwicNPkIqd1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Please comment your code"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yn16xrDrIs8B",
        "colab_type": "text"
      },
      "source": [
        "### 2.1.5. Load Word Embeddings Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IebpYFsIvgh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Please comment your code"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "T0ap96aeGlIk"
      },
      "source": [
        "## 2.2. Character Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "d16v3oKaGlI0"
      },
      "source": [
        "### 2.2.1. Data Preprocessing for Character Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AKbLnN-3GlI1"
      },
      "source": [
        "*You are required to describe which preprocessing techniques were used with justification of your decision.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "i2CUCL1cGlI2",
        "colab": {}
      },
      "source": [
        "# Please comment your code"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zgiOPcsTGlI6"
      },
      "source": [
        "### 2.2.2. Build Character Embeddings Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4NtqFFcjGlI7"
      },
      "source": [
        "*You are required to describe how hyperparameters were decided with justification of your decision.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jj3YZ3PWGlI8",
        "colab": {}
      },
      "source": [
        "# Please comment your code"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "46W0zFfWGlI_"
      },
      "source": [
        "### 2.1.4. Train Character Embeddings Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UWQn-VyNGlJA",
        "colab": {}
      },
      "source": [
        "# Please comment your code"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "R5Bym9bBGlJE"
      },
      "source": [
        "### 2.1.5. Save Character Embeddings Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ggTsYIm7GlJF",
        "colab": {}
      },
      "source": [
        "# Please comment your code"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JwOI-wIKGlJI"
      },
      "source": [
        "### 2.1.6. Load Character Embeddings Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-jyj-lOHWWj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Please comment your code"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlCeWT8eeLnd",
        "colab_type": "text"
      },
      "source": [
        "## 2.3. Sequence model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwA-NN3EJ4Ig",
        "colab_type": "text"
      },
      "source": [
        "### 2.3.1. Apply/Import Word Embedding and Character Embedding Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UAMJrxx-iOVn",
        "colab_type": "text"
      },
      "source": [
        "*You are required to describe how hyperparameters were decided with justification of your decision.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7PKX1gIePA2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Please comment your code"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpYCL17JKZxl",
        "colab_type": "text"
      },
      "source": [
        "### 2.3.2. Build Sequence Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R204UIyDKhZ4",
        "colab_type": "text"
      },
      "source": [
        "*You are required to describe how hyperparameters were decided with justification of your decision.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13eCtR_SLUG6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Please comment your code"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BaOiaGRLW7R",
        "colab_type": "text"
      },
      "source": [
        "### 2.3.3. Train Sequence Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVQnUSX1LZ6C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Please comment your code"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2feNpG-LZx2",
        "colab_type": "text"
      },
      "source": [
        "### 2.3.4. Save Sequence Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sflUAgV4L1o8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Please comment your code"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zFo6YppL6w3",
        "colab_type": "text"
      },
      "source": [
        "### 2.3.5. Load Sequence Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtNxLzDGMCan",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Please comment your code"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4mpRpocePLN",
        "colab_type": "text"
      },
      "source": [
        "# 3 - Evaluation\n",
        "\n",
        "(*Please show your empirical evidence*)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEW1zMgVMREr",
        "colab_type": "text"
      },
      "source": [
        "## 3.1. Performance Evaluation\n",
        "\n",
        "\n",
        "You are required to provide the table with precision, recall, f1 of test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPHCb-bneTI9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Please comment your code"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P28Z1k36MZuo",
        "colab_type": "text"
      },
      "source": [
        "## 3.2. Hyperparameter Testing\n",
        "*You are required to draw a graph(y-axis: f1, x-axis: epoch) for test set and explain the optimal number of epochs based on the learning rate you have already chosen.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTLyQEeZMZ2f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Please comment your code"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfv8rWTKPzeb",
        "colab_type": "text"
      },
      "source": [
        "## Object Oriented Programming codes here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TS23AjBRSZaX",
        "colab_type": "text"
      },
      "source": [
        "*You can use multiple code snippets. Just add more if needed* "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1hVmx4E52dXS",
        "colab": {}
      },
      "source": [
        "# If you used OOP style, use this section"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}