{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "zhua9812_COMP5046_Ass1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dovermore/COMP5046-ass1/blob/master/zhua9812_COMP5046_Ass1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsMZ0F9bbExL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Space for my pyautogui script to keep colab alive\n",
        "# Hello world!\n",
        "# Hello world!\n",
        "# Hello world!\n",
        "# Hello \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGHoy6KpQDfZ",
        "colab_type": "text"
      },
      "source": [
        "# COMP5046 Assignment 1\n",
        "*Make sure you change the file name with your unikey.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTf21j_oQIiD",
        "colab_type": "text"
      },
      "source": [
        "# Readme\n",
        "*If there is something to be noted for the user, please mention here.* \n",
        "\n",
        "*If you are planning to implement a program with Object Oriented Programming style*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXbQohXLKSgO",
        "colab_type": "text"
      },
      "source": [
        "***Visualising the comparison of different results is a good way to justify your decision.***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34DVNKgqQY21",
        "colab_type": "text"
      },
      "source": [
        "# 1 - Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cWUxAQrGlq6",
        "colab_type": "text"
      },
      "source": [
        "## 1.1. Download Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7C4snIcNl22",
        "colab_type": "code",
        "outputId": "fde44d70-799f-4a2f-d3fa-e26da8944b8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Code to download file into Colaboratory:\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "id = '1vF3FqgBC1Y-RPefeVmY8zetdZG1jmHzT'\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('imdb_train.csv')\n",
        "\n",
        "id = '1XhaV8YMuQeSwozQww8PeyiWMJfia13G6'\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('imdb_test.csv')\n",
        "\n",
        "import pandas as pd\n",
        "df_train = pd.read_csv(\"imdb_train.csv\")\n",
        "df_test = pd.read_csv(\"imdb_test.csv\")\n",
        "\n",
        "reviews_train = df_train['review'].tolist()\n",
        "sentiments_train = df_train['sentiment'].tolist()\n",
        "reviews_test = df_test['review'].tolist()\n",
        "sentiments_test = df_test['sentiment'].tolist()\n",
        "\n",
        "print(\"Training set number:\",len(reviews_train))\n",
        "print(\"Testing set number:\",len(reviews_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training set number: 25000\n",
            "Testing set number: 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFZbZzDOOT8X",
        "colab_type": "code",
        "outputId": "d24ba01b-5f81-4b23-c7c6-1fa22207b06f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "# install some other necessary libraries\n",
        "# Expand contractions\n",
        "!pip install contractions\n",
        "!pip install feather-format\n",
        "\n",
        "# Setup saving and loading\n",
        "from google.colab import files, drive\n",
        "from pathlib import Path\n",
        "drive.mount('/content/drive')\n",
        "drive_path = Path(\"/content/drive/My Drive/COMP5046-assignment1/\")\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: contractions in /usr/local/lib/python3.6/dist-packages (0.0.24)\n",
            "Requirement already satisfied: textsearch in /usr/local/lib/python3.6/dist-packages (from contractions) (0.0.17)\n",
            "Requirement already satisfied: Unidecode in /usr/local/lib/python3.6/dist-packages (from textsearch->contractions) (1.1.1)\n",
            "Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.6/dist-packages (from textsearch->contractions) (1.4.0)\n",
            "Requirement already satisfied: feather-format in /usr/local/lib/python3.6/dist-packages (0.4.0)\n",
            "Requirement already satisfied: pyarrow>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from feather-format) (0.14.1)\n",
            "Requirement already satisfied: numpy>=1.14 in /usr/local/lib/python3.6/dist-packages (from pyarrow>=0.4.0->feather-format) (1.18.2)\n",
            "Requirement already satisfied: six>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from pyarrow>=0.4.0->feather-format) (1.12.0)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9gBSgBCQh24",
        "colab_type": "text"
      },
      "source": [
        "## 1.2. Preprocess data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8RdKI8E2KRwe",
        "colab_type": "text"
      },
      "source": [
        "*You are required to describe which data preprocessing techniques were conducted with justification of your decision. *"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emyl1lWxGr12",
        "colab_type": "code",
        "outputId": "418cae5f-0b69-4056-8e1c-e00bdbe1b2f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.base import TransformerMixin\n",
        "\n",
        "import copy\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "import contractions\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords as sw\n",
        "from nltk import FreqDist\n",
        "\n",
        "# These words affect the reasoning of the sentence\n",
        "negative_words = set([\"no\", \"nor\", \"not\", \"but\"])\n",
        "stop_words = set(sw.words()) - negative_words\n",
        "# Lemmatise the words\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "\n",
        "def remove_punctuation(x):\n",
        "    \"\"\"\n",
        "    Remove all non white space or word character in function x\n",
        "    :param x: The sentence to process\n",
        "    :return: str with all non white space or word character removed\n",
        "    \"\"\"\n",
        "    x = re.sub(r'[^\\w\\s]',' ',x)\n",
        "    return x\n",
        "\n",
        "def convert_numbers(x):\n",
        "    \"\"\"\n",
        "    Convert numbers to number token\n",
        "    :param x: The sentence to process\n",
        "    :return: str with all numbers converted accordingly\n",
        "    \"\"\"\n",
        "    # Replace digit of different length with corresponding token\n",
        "    x = re.sub(r'[0-9]{5,}', '<4+NUM>', x)\n",
        "    x = re.sub(r'[0-9]{4}', '<4NUM>', x)\n",
        "    x = re.sub(r'[0-9]{3}', '<3NUM>', x)\n",
        "    x = re.sub(r'[0-9]{2}', '<2NUM>', x)\n",
        "    # Remove fraction symbols (and other other category symbol)\n",
        "    x = re.sub(r'[½¾]', '', x)\n",
        "    return x\n",
        "\n",
        "def preprocess_texts(X, rm_htmltag=True, expand_contraction=True, to_lower=True, rm_punctuation=True,\n",
        "                     cv_numbers=True, stop_words=stop_words, lemmatize=True, min_count=5):\n",
        "    \"\"\"\n",
        "    Preprocess texts with the specified preprocessing procedures\n",
        "    :param X: A list of texts to be processed\n",
        "    :param rm_htmltag: If html tags should be removed\n",
        "    :param expand_contraction: If contraction should be expanded\n",
        "    :param to_lower: If cases should be converted to lower case\n",
        "    :param rm_punctuation: If punctuation should be removed\n",
        "    :param lemmatize: If tokens should be lemmatized\n",
        "    :return: list[list[processed token]]\n",
        "    \"\"\"\n",
        "    if rm_htmltag:\n",
        "        # Use beautiful soup to remove html tags if any\n",
        "        X = [BeautifulSoup(s).get_text() for s in X]\n",
        "\n",
        "    if expand_contraction:\n",
        "        # expand contactions (english only) to normalise text (this before lower case because this will give uppercase)\n",
        "        X = [contractions.fix(s) for s in X]\n",
        "\n",
        "    if to_lower:\n",
        "        # Case folding is necessary to reduce the unique words and removing some irregular case formulation for words.\n",
        "        # Though this may cause the loss of some information (for instance, all CAPPED words have strong emotion),\n",
        "        # it is generally beneficial to smooth the occurances of words\n",
        "        X = [s.lower() for s in X]\n",
        "\n",
        "    if rm_punctuation:\n",
        "        # Remove punctuations is necessary for almost the same reason as the case folding. Here because each tweet is self\n",
        "        # contained, no need to add end of sentence token.\n",
        "        X = [remove_punctuation(s) for s in X]\n",
        "\n",
        "    if cv_numbers:\n",
        "        X = [convert_numbers(s) for s in X]\n",
        "\n",
        "    # Tokenization is necessary to extract each individual words instead of feeding in raw sentences.\n",
        "    X = [word_tokenize(sent) for sent in X]\n",
        "\n",
        "    # Stop words are NOT removed (yet) for they sometimes affect the sentiment by a lot (like word not, wouldn't)\n",
        "    # If I can get better list and spend more time understanding the data then I will remove them\n",
        "    if stop_words is not False and len(stop_words):\n",
        "        X = [[w for w in tokens if not w in stop_words] for tokens in X]\n",
        "\n",
        "    if lemmatize:\n",
        "        # Lemmatise tokens to reduce the number of unique words, and make the training process easier by reducing the labels\n",
        "        X = [[lemmatizer.lemmatize(w) for w in tokens] for tokens in X]\n",
        "    \n",
        "    if min_count > 1:\n",
        "        all_tokens = [w for tokens in X for w in tokens]\n",
        "        token_set = set(k for k, v in FreqDist(all_tokens).items() if v >= min_count)\n",
        "        X = [[w for w in tokens if w in token_set] for tokens in X]\n",
        "\n",
        "    return X\n",
        "\n",
        "\n",
        "class TextPreprocessTransformer(TransformerMixin):\n",
        "    \"\"\"\n",
        "    Simple transformer class to wrap the previous transformation\n",
        "    \"\"\"\n",
        "    def __init__(self, **kwargs):\n",
        "        self.kwargs = kwargs\n",
        "\n",
        "    def fit(self, X, y=None, **fit_params):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X, y=None):\n",
        "        return preprocess_texts(X, **self.kwargs)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTH6GzgF4hrd",
        "colab_type": "code",
        "outputId": "39d141a9-e30d-4885-f8ed-63ad52d23012",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# Import necessary libraries\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9J9jBjDj4WUY",
        "colab_type": "text"
      },
      "source": [
        "### Observe raw distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tQn9d2wNvft0",
        "colab": {}
      },
      "source": [
        "raw_tokens = preprocess_texts(reviews_train, rm_htmltag=False, expand_contraction=False, \n",
        "                              to_lower=False, rm_punctuation=False, cv_numbers=False,\n",
        "                              stop_words=False, lemmatize=False, min_count=1)\n",
        "raw_tokens = [w for tokens in raw_tokens for w in tokens]\n",
        "raw_fd = FreqDist(raw_tokens)\n",
        "sns.distplot(list(raw_fd.values()), bins=10, norm_hist=False)\n",
        "len(list(raw_fd.keys()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51JQ_tLI4cDQ",
        "colab_type": "text"
      },
      "source": [
        "#### Observe processed Distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtWPqYLL4ak0",
        "colab_type": "code",
        "outputId": "7d51d18f-178b-42aa-9cbe-d83aae352415",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "processed_tokens = preprocess_texts(reviews_train, min_count=5)\n",
        "processed_tokens = [w for tokens in processed_tokens for w in tokens]\n",
        "processed_fd = FreqDist(processed_tokens)\n",
        "sns.distplot([v for v in processed_fd.values() if v < 1000], bins=10, norm_hist=False)\n",
        "len(list(processed_fd.keys()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25350"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 217
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcGFbmqUog4E",
        "colab_type": "code",
        "outputId": "3484ce16-c26e-42ca-9c9d-9cea1dac39f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "tpt = TextPreprocessTransformer()\n",
        "tokens_train = tpt.fit_transform(reviews_train)\n",
        "tokens_test = tpt.transform(reviews_test)\n",
        "\n",
        "total_len_train = 0\n",
        "for tokens in tokens_train:\n",
        "    total_len_train += len(tokens)\n",
        "\n",
        "total_len_test = 0\n",
        "for tokens in tokens_test:\n",
        "    total_len_test += len(tokens)\n",
        "\n",
        "print(tokens_train[:2])\n",
        "print(tokens_test[:2])\n",
        "\n",
        "print(total_len_train)\n",
        "print(total_len_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['enjoyed', 'movie', 'not', 'seen', 'andy', 'griffith', 'age', 'felt', 'fit', 'role', 'perfectly', 'associated', 'comedy', 'but', 'pleased', 'see', 'versatile', 'not', 'troubled', 'dotty', 'anxiety', 'disorder', 'may', 'not', 'verbatim', 'psychiatric', 'textbook', 'zillion', 'whatever', 'phobia', 'neurosis', 'broad', 'variety', 'form', 'clearly', 'sensitive', 'extra', 'sensory', 'power', 'understood', 'local', 'indian', 'but', 'not', 'anglos', 'not', 'surprising', 'character', 'vulnerable', 'eccentric', 'although', 'taken', 'light', 'family', 'movie', 'actually', 'sophisticated', 'seems', 'twist', 'came', 'pleasant', 'surprise', 'tied', 'preceding', 'action', 'together', 'bundle', 'fun', 'contemplate', 'possibility', 'spiritual', 'guidance'], ['whole', 'not', 'even', 'close', 'sum', 'part', 'no', 'problem', 'film', 'feature', 'line', 'creative', 'director', 'time', 'really', 'famous', 'name', 'cast', 'segment', 'devised', 'around', 'theme', 'love', 'paris', 'but', 'resemblance', 'end', 'actually', 'considering', 'approach', 'theme', 'different', 'director', 'take', 'many', 'form', 'amazing', 'even', 'feel', 'still', 'watching', 'film', 'no', 'great', 'effort', 'made', 'turn', 'comprehensive', 'whole', 'many', 'great', 'ingredient', 'glad', 'nobody', 'tried', 'put', 'single', 'dish']]\n",
            "[['course', 'going', 'think', 'great', 'movie', 'recognized', 'several', 'people', 'not', 'see', 'filming', 'playing', 'guard', 'hour', 'movie', 'death', 'row', 'exercise', 'yard', 'asking', 'light', 'cigarette', 'changed', 'scene', 'originally', 'set', 'go', 'rec', 'yard', 'straighten', 'inmate', 'turn', 'around', 'walk', 'director', 'said', 'taking', 'long', 'would', 'said', 'need', 'go', 'hook', 'arm', 'drag', 'backwards', 'way', 'camera', 'stay', 'set', 'lived', 'prison', 'young', 'child', 'father', 'assistant', 'warden', 'security', 'current', 'employee', 'tennessee', 'correction', 'supervisor', 'maximum', 'security', 'institution', 'even', 'though', 'lot', 'movie', 'joke', 'part', 'reality', 'enough', 'bar', 'scene', 'dancer', 'kicking', 'high', 'air', 'leaving', 'stage', 'actual', 'stripper', 'use', 'work', 'club', 'called', 'classic'], ['never', 'understood', 'type', 'spoof', 'movie', 'get', 'serious', 'semi', 'serious', 'movie', 'everyone', 'know', 'take', 'seriousness', 'immature', 'fart', 'joke', 'seen', 'many', 'many', 'time', 'never', 'really', 'funny', 'easy', 'way', 'laugh', 'something', 'not', 'understand', 'opinion', 'seems', 'obscure', 'le', 'liked', 'genre', 'though', 'honestly', 'not', 'see', 'anything', 'much', 'worse', 'spy', 'hard', 'hot', 'shot', 'movie', 'clearly', 'understood', 'simply', 'title', 'concentrate', 'making', 'childish', 'fun', 'pulp', 'fiction', 'main', 'reason', 'decided', 'watch', 'found', 'film', 'overly', 'indulgent', 'tarantino', 'sick', 'mind', 'powerfully', 'overrated', 'hoped', 'two', 'good', 'joke', 'making', 'fun', 'overly', 'violent', 'pointless', 'type', 'movie', 'pulp', 'fiction', 'every', 'aspect', 'anything', 'but', 'humble', 'opinion', 'sorely', 'disappointed', 'plot', 'pretty', 'much', 'rip', 'tarantino', 'film', 'scene', 'spoofing', 'often', 'better', 'film', 'childish', 'humorless', 'fashion', 'pacing', 'poor', 'often', 'able', 'guess', 'outcome', 'every', 'scene', 'predicting', 'every', 'joke', 'often', 'thinking', 'better', 'spot', 'bored', 'mind', 'acting', 'bad', 'character', 'clichés', 'stereotype', 'intentionally', 'paper', 'thin', 'order', 'make', 'fun', 'character', 'based', 'problem', 'not', 'work', 'make', 'movie', 'much', 'harder', 'humor', 'juvenile', 'lame', 'positive', 'thing', 'say', 'film', 'managed', 'find', 'actor', 'looked', 'like', 'people', 'supposed', 'look', 'like', 'film', 'awful', 'waste', 'actual', 'real', 'actor', 'involved', 'possibly', 'slightly', 'entertaining', 'fan', 'typical', 'spoof', 'movie', 'kind', 'recommend', 'people', 'truly', 'loathed', 'pulp', 'fiction', 'fan', 'zucker', 'parody', 'film', 'everyone', 'else', 'avoid', '1', '<', '2NUM', '>']]\n",
            "3036037\n",
            "2962455\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bi9n4bYwondw",
        "colab_type": "code",
        "outputId": "6e2bdbae-2307-4619-eae2-b2a0a8f61cca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(sorted(list(set(sentiments_train))))\n",
        "label_train = label_encoder.transform(sentiments_train)\n",
        "label_test = label_encoder.transform(sentiments_test)\n",
        "print(label_train[:50])\n",
        "print(label_test[:50])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 1 1 0 0 0 1 1 0 0 0 0 1 1 0 0 1 0 0 0 0 1 0 1 0 0 1 1 1 1 0 1 0 0 0 0 0\n",
            " 0 0 0 0 1 1 0 0 1 0 0 1 1]\n",
            "[1 0 0 0 0 0 1 1 0 1 0 1 0 1 1 0 0 1 1 1 0 1 1 0 1 1 0 0 0 1 1 0 1 0 0 1 0\n",
            " 1 1 1 0 0 0 0 1 0 0 0 1 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQY--32dJKpz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "def check_create_parent(path: Path):\n",
        "    if not (path.parent.exists() and path.parent.is_dir()):\n",
        "        path.parent.mkdir(parents=True, exist_ok=False)\n",
        "\n",
        "# Create df to store the data\n",
        "def save_feather(tokens, labels, sentiments, path):\n",
        "    df = pd.DataFrame(columns=[\"tokens\", \"labels\", \"sentiments\"])\n",
        "    df[\"tokens\"] = [\" \".join(t) for t in tokens]\n",
        "    df[\"labels\"] = labels \n",
        "    df[\"sentiments\"] = sentiments\n",
        "    check_create_parent(path)\n",
        "    df.to_feather(path)\n",
        "\n",
        "def load_feather(path):\n",
        "    df = pd.read_feather(path)\n",
        "    tokens = df[\"tokens\"]\n",
        "    labels = df[\"labels\"]\n",
        "    sentiments = df[\"sentiments\"]\n",
        "    tokens = [t.split(\" \") for t in tokens]\n",
        "    return tokens, labels, sentiments\n",
        "\n",
        "\n",
        "train_path = drive_path/\"data\"/\"train.feather\"\n",
        "test_path = drive_path/\"data\"/\"test.feather\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AgZ1ozZiI3L_",
        "colab_type": "code",
        "outputId": "ed0fdcd5-32a7-49d7-f60d-a790abcc703b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        }
      },
      "source": [
        "# Save processed data\n",
        "save_feather(tokens_train, label_train, sentiments_train, train_path)\n",
        "save_feather(tokens_test, label_test, sentiments_test, test_path)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-4c842665da8c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msave_feather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentiments_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msave_feather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentiments_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tokens_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gB8pPuMAVP7g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load from processed data\n",
        "tokens_train, label_train, sentiments_train = load_feather(train_path)\n",
        "tokens_test, label_test, sentiments_test = load_feather(test_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NAYv0ThQVhlY"
      },
      "source": [
        "# 2 - Model Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "daDvAftceIvr",
        "colab_type": "text"
      },
      "source": [
        "## 2.1. Word Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbzm-NWBTmM-",
        "colab_type": "text"
      },
      "source": [
        "*You are required to describe which model was implemented (i.e. Word2Vec with CBOW, FastText with SkipGram, etc.) with justification of your decision *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXgFpxIgl-_G",
        "colab_type": "text"
      },
      "source": [
        "### 2.1.1. Data Preprocessing for Word Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJrVHGYSmYMg",
        "colab_type": "text"
      },
      "source": [
        "*You are required to describe which preprocessing techniques were used with justification of your decision.*\n",
        "\n",
        "**Important**: If you are going to use the code from lab3 word2vec preprocessing. Please note that `word_list = list(set(word_list)) ` has randomness. So to make sure the word_list is the same every time you run it, you can put `word_list.sort()` after that line of code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cM4rlYkHefJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.base import TransformerMixin\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from random import shuffle\n",
        "# np.random.seed(0)\n",
        "\n",
        "# Token -> Ordinal\n",
        "class VocabCardinalTransformer(TransformerMixin):\n",
        "    \"\"\"\n",
        "    Base transformer handling vocabulary related tasks by fitting a vocabulary\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.token_list = []\n",
        "        self.token_dict = {}\n",
        "\n",
        "    def fit(self, X, y=None, **fit_params):\n",
        "        \"\"\"\n",
        "        Fit this transformer with training data to obtain vocabulary\n",
        "        :param X: Training data to be fitted\n",
        "        :param y: Ignored\n",
        "        :param refit: Specifies if this fit should be a refit (reinitialise vocab list) or build upon previous vocab list\n",
        "        :return: itself for chaining\n",
        "        \"\"\"\n",
        "        refit = fit_params.get(\"refit\", False)\n",
        "        token_set = set()\n",
        "        for tokens in X:\n",
        "            token_set |= set(tokens)\n",
        "        if refit:\n",
        "            self.token_list = sorted(token_set)\n",
        "        else:\n",
        "            token_set -= set(self.token_list)\n",
        "            self.token_list += sorted(token_set)\n",
        "        self.token_dict = {w: i for i, w in enumerate(self.token_list)}\n",
        "        return self\n",
        "\n",
        "    def transform(self, X, y=None):\n",
        "        mapped_tokens = []\n",
        "        for tokens in X:\n",
        "            mapped_tokens.append([self.token_dict[t] for t in tokens if t in self.token_dict])\n",
        "        return mapped_tokens\n",
        "\n",
        "\n",
        "# First define a dataset generator\n",
        "class SkipGramTransformer(TransformerMixin):\n",
        "    \"\"\"\n",
        "    Transformer class to convert raw list of list of tokens to data to be trained for skipgram model\n",
        "    \"\"\"\n",
        "    def __init__(self, window=10, drop_prob=0):\n",
        "        \"\"\"\n",
        "        Init this transformer with a given window size for sampling skip grams\n",
        "        :param window: The window size for sampling. Note this is the size of one side,\n",
        "            the total number of context sampled is 2 * window\n",
        "        :param drop_prob: Probability dropping a target word, used to increase the stochasticity\n",
        "            and mixing the training data better\n",
        "        \"\"\"\n",
        "        self.window = window\n",
        "        self.drop_prob = drop_prob\n",
        "\n",
        "    def fit(self, X, y=None, **fit_params):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X, y=None):\n",
        "        \"\"\"\n",
        "        Transforms a given dataset (list of list of tokens) to negative gram data (target, context) pair\n",
        "        :param X: The input data\n",
        "        :param y: Ignored\n",
        "        :return: One array of targets and one array of contexts\n",
        "        \"\"\"\n",
        "        skip_grams = []\n",
        "        for tokens in X:\n",
        "            for i in range(len(tokens)):\n",
        "                target = tokens[i]\n",
        "                if np.random.uniform() < self.drop_prob: continue\n",
        "                for k in range(max(i - self.window, 0), min(i + self.window + 1, len(tokens))):\n",
        "                    if k == i: continue\n",
        "                    context = tokens[k]\n",
        "                    skip_grams.append([target, context])\n",
        "        X, y = list(zip(*skip_grams))\n",
        "        return np.array(X), np.array(y)\n",
        "\n",
        "    def generator(self, X, batch_size=1024): \n",
        "        \"\"\" \n",
        "        Generates a generator for transforming a given dataset (list of list of tokens) to negative \n",
        "        gram data (target, context) pair. The generated generator will generate an array of \n",
        "        target words and array of context words both of shape (batch_size, ). \n",
        "        This is needed because the previous way of generating will exceed the memory \n",
        "        capacity \n",
        "        :param X: The input data \n",
        "        :param y: Ignored \n",
        "        :return: A generator whose __next__ output the following data:\n",
        "            Array of targets, array of contexts, flag specifying if this is the end of a epoch \n",
        "        \"\"\" \n",
        "        # TODO optimise the running time of this\n",
        "        X = copy.deepcopy(X)\n",
        "        skip_gram_pool = np.zeros((0, 2), dtype=int)\n",
        "        idx = 0\n",
        "        while True:\n",
        "            # While the pool is not filled and the data is not cycled to the end, populate pool\n",
        "            # and advance the idx\n",
        "            while skip_gram_pool.shape[0] < batch_size * 3 and idx < len(X):\n",
        "                tokens = X[idx]\n",
        "                skip_grams = []\n",
        "                for i in range(len(tokens)):\n",
        "                    target = tokens[i]\n",
        "                    if np.random.uniform() < self.drop_prob: continue\n",
        "                    for k in range(max(i - self.window, 0), min(i + self.window + 1, len(tokens))):\n",
        "                        if k == i: continue\n",
        "                        context = tokens[k]\n",
        "                        skip_grams.append([target, context])\n",
        "                if len(skip_grams):\n",
        "                    skip_gram_pool = np.concatenate([skip_gram_pool, skip_grams], axis=0)\n",
        "                # Advance idx\n",
        "                idx += 1\n",
        "\n",
        "            # Batch sampling of index\n",
        "            batch_idx = np.random.choice(skip_gram_pool.shape[0], \n",
        "                                         size=min(batch_size, skip_gram_pool.shape[0]), \n",
        "                                         replace=False)\n",
        "            # Epoch end if the data has been cycled through and pool will be empty\n",
        "            end_epoch = (idx >= len(X) and batch_size >= skip_gram_pool.shape[0])\n",
        "            # print(end_epoch, skip_gram_pool.shape[0])\n",
        "            yield skip_gram_pool[batch_idx, 0], skip_gram_pool[batch_idx, 1].reshape(-1), end_epoch\n",
        "            # If this epoch ended, start a new cycle\n",
        "            if end_epoch:\n",
        "                idx %= len(X)\n",
        "                shuffle(X)\n",
        "            skip_gram_pool = np.delete(skip_gram_pool, batch_idx, axis=0)\n",
        "\n",
        "    def generator2(self, X, batch_size=1024): \n",
        "        \"\"\" \n",
        "        Generates a generator for transforming a given dataset (list of list of tokens) to negative \n",
        "        gram data (target, context) pair. The generated generator will generate an array of \n",
        "        target words and array of context words both of shape (batch_size, ). \n",
        "        This is needed because the previous way of generating will exceed the memory \n",
        "        capacity \n",
        "        :param X: The input data \n",
        "        :param y: Ignored \n",
        "        :return: A generator whose __next__ output the following data:\n",
        "            Array of targets, array of contexts, flag specifying if this is the end of a epoch \n",
        "        \"\"\" \n",
        "        X = deepcopy(X)\n",
        "        shuffle(X)\n",
        "        skip_gram_pool = np.zeros((0, 2), dtype=int)\n",
        "        idx = 0\n",
        "        while True:\n",
        "            # While the pool is not filled and the data is not cycled to the end, populate pool\n",
        "            # and advance the idx\n",
        "            while skip_gram_pool.shape[0] < batch_size and idx < len(X):\n",
        "                tokens = X[idx]\n",
        "                skip_grams = []\n",
        "                for i in range(len(tokens)):\n",
        "                    target = tokens[i]\n",
        "                    if np.random.uniform() < self.drop_prob: continue\n",
        "                    for k in range(max(i - self.window, 0), min(i + self.window + 1, len(tokens))):\n",
        "                        if k == i: continue\n",
        "                        context = tokens[k]\n",
        "                        skip_grams.append([target, context])\n",
        "                if len(skip_grams):\n",
        "                    skip_gram_pool = np.concatenate([skip_gram_pool, skip_grams], axis=0)\n",
        "                # Advance idx\n",
        "                idx += 1\n",
        "\n",
        "            # Epoch end if the data has been cycled through and pool will be empty\n",
        "            end_epoch = (idx >= len(X) and batch_size >= skip_gram_pool.shape[0])\n",
        "            # print(end_epoch, skip_gram_pool.shape[0])\n",
        "            yield skip_gram_pool[:batch_size, 0], skip_gram_pool[:batch_size, 1].reshape(-1), end_epoch\n",
        "            # If this epoch ended, start a new cycle\n",
        "            if end_epoch:\n",
        "                idx %= len(X)\n",
        "                shuffle(X)\n",
        "            skip_gram_pool = skip_gram_pool[batch_size:]\n",
        "\n",
        "\n",
        "class VocabSkipGramTransformer(TransformerMixin):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        self.vocab_transformer = VocabCardinalTransformer()\n",
        "        self.skip_gram_transformer = SkipGramTransformer(*args, **kwargs)\n",
        "    \n",
        "    def fit(self, X, y=None, **fit_params):\n",
        "        self.vocab_transformer.fit(X, y, **fit_params)\n",
        "        return self\n",
        "\n",
        "    def transform(self, X, y=None):\n",
        "        return self.skip_gram_transformer.transform(self.vocab_transformer.transform(X))\n",
        "\n",
        "    def generator(self, X, batch_size=1024):\n",
        "        return (self.skip_gram_transformer\n",
        "                .generator(self.vocab_transformer.transform(X), \n",
        "                           batch_size=batch_size))\n",
        "    \n",
        "    def get_token_list(self):\n",
        "        return self.vocab_transformer.token_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uDh28ZM8a3ma",
        "outputId": "396ac6a8-031c-49d2-fe22-8c1dd9bdb8b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "# Test\n",
        "sgt = VocabSkipGramTransformer(drop_prob=0)\n",
        "test_data = np.array(range(10)).reshape(5, 2).tolist()\n",
        "sgt.fit(test_data)\n",
        "i = 0\n",
        "for i, (a, b, c) in enumerate(sgt.generator(test_data, 2)):\n",
        "    print(i, a, b, c)\n",
        "    if i > 20:\n",
        "        break\n",
        "print(sgt.get_token_list())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 [2 0] [3 1] False\n",
            "1 [3 7] [2 6] False\n",
            "2 [4 6] [5 7] False\n",
            "3 [9 8] [8 9] False\n",
            "4 [5 1] [4 0] True\n",
            "5 [6 9] [7 8] False\n",
            "6 [3 7] [2 6] False\n",
            "7 [5 1] [4 0] False\n",
            "8 [4 0] [5 1] False\n",
            "9 [2 8] [3 9] True\n",
            "10 [4 7] [5 6] False\n",
            "11 [0 6] [1 7] False\n",
            "12 [3 1] [2 0] False\n",
            "13 [8 2] [9 3] False\n",
            "14 [5 9] [4 8] True\n",
            "15 [1 9] [0 8] False\n",
            "16 [7 6] [6 7] False\n",
            "17 [5 3] [4 2] False\n",
            "18 [2 8] [3 9] False\n",
            "19 [4 0] [5 1] True\n",
            "20 [2 0] [3 1] False\n",
            "21 [7 1] [6 0] False\n",
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbUw3gEwGqa7",
        "colab_type": "code",
        "outputId": "fd71ac7f-5bef-4080-fb32-2f03e19fe92c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Profile time\n",
        "sgt = VocabSkipGramTransformer(drop_prob=0)\n",
        "sgt.fit(tokens_train)\n",
        "datagen = sgt.generator(tokens_train)\n",
        "%timeit -n 1000 next(datagen)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000 loops, best of 3: 1.15 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhAgWf_AmbZ8",
        "colab_type": "text"
      },
      "source": [
        "### 2.1.2. Build Word Embeddings Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJ8rU7JbiBVS",
        "colab_type": "text"
      },
      "source": [
        "*You are required to describe how hyperparameters were decided with justification of your decision.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVPuwWgvNjOU",
        "colab_type": "code",
        "outputId": "6c251717-b765-446d-d302-ca41ee82e5c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "import time\n",
        "import math\n",
        "import torch\n",
        "# torch.manual_seed(0)\n",
        "from torch import nn\n",
        "from torch.utils import data\n",
        "from torch.optim import Adam\n",
        "from datetime import datetime\n",
        "from copy import deepcopy\n",
        "\n",
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device = torch.device(\"cpu\")\n",
        "print(\"device is \", device)\n",
        "\n",
        "\n",
        "# https://pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html\n",
        "def time_since(since):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def get_net_dict(net):\n",
        "    return deepcopy(net.state_dict())\n",
        "\n",
        "\n",
        "class FileNameGenerator:\n",
        "    def __init__(self, prefix, postfix=\".pt\"):\n",
        "        self.prefix = prefix\n",
        "        self.postfix = postfix\n",
        "\n",
        "    def _gen_fname(self, offset=0):\n",
        "        i = 0\n",
        "        path = self._format_path(i)\n",
        "        while path.exists():\n",
        "            i += 1\n",
        "            path = self._format_path(i)\n",
        "        if i + offset < 0:\n",
        "            return None\n",
        "        return self._format_path(i + offset)\n",
        "    \n",
        "    def read_fname(self, serial=None):\n",
        "        if serial is None:\n",
        "            return self._gen_fname(offset=-1)\n",
        "        return self._format_path(serial)\n",
        "\n",
        "    def write_fname(self, serial=None):\n",
        "        if serial is None:\n",
        "            return self._gen_fname()\n",
        "        return self._format_path(serial)\n",
        "    \n",
        "    def _format_path(self, serial):\n",
        "        return Path(\"%s%d%s\" % (self.prefix, serial, self.postfix))\n",
        "\n",
        "\n",
        "\n",
        "# TODO refactor this class\n",
        "class BaseModel:\n",
        "    def __init__(self, net:nn.Module, optimizer, ckpt_fname_gen:FileNameGenerator, device=device):\n",
        "        super().__init__()\n",
        "        # Store model\n",
        "        self.net = net \n",
        "        # store optimizer\n",
        "        self.optimizer = optimizer\n",
        "        # ckpt name generator\n",
        "        self.ckpt_fname_gen = ckpt_fname_gen\n",
        "        # loss (should be overridden if needed)\n",
        "        self.loss = nn.CrossEntropyLoss()\n",
        "        # device this is trained on\n",
        "        self.device = device\n",
        "        # State of the model\n",
        "        self.training = True\n",
        "        self.best_net_dict = None\n",
        "        if self.net is not None:\n",
        "            # Send to the device\n",
        "            self.net.to(self.device)\n",
        "            self.best_net_dict = None\n",
        "            self.best_net_dict = get_net_dict(self.net)\n",
        "\n",
        "    def train_step(self, X_batch, y_batch):\n",
        "        # zero the parameter gradients\n",
        "        self.optimizer.zero_grad()\n",
        "    \n",
        "        # forward + backward + optimize\n",
        "        outputs = self.net.forward(X_batch)\n",
        "        loss = self.loss(outputs, y_batch)\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "        #print(\"--------------------\")\n",
        "        #print(outputs.size())\n",
        "        #print(y_batch.size())\n",
        "        return outputs, loss\n",
        "\n",
        "    def train(self, data, epochs, batch_size=1024, data_gen_dict={}, batch_display_interval=10000, \n",
        "                    epoch_display_interval=100, ckpt_interval=1):\n",
        "        if batch_display_interval <= 0:\n",
        "            batch_display_interval = 1000000000\n",
        "        if epoch_display_interval <= 0:\n",
        "            epoch_display_interval = 1000000000\n",
        "        if ckpt_interval <= 0:\n",
        "            ckpt_interval = 1000000000\n",
        "\n",
        "        self.net.to(self.device)\n",
        "        data_gen = self.data_generator(data, batch_size=batch_size, **data_gen_dict)\n",
        "        batch = 0\n",
        "        start = time.time()\n",
        "\n",
        "        best_net_loss = np.inf\n",
        "        self.save_model(0)\n",
        "        for epoch in range(epochs):\n",
        "            epoch_loss = 0\n",
        "            epoch_size = 0\n",
        "            for X_batch, y_batch, end_epoch in data_gen:\n",
        "                # Send data to the device\n",
        "                X_batch = X_batch.to(self.device)\n",
        "                y_batch = y_batch.to(self.device)\n",
        "                # Train\n",
        "                outputs, loss = self.train_step(X_batch, y_batch)\n",
        "                epoch_loss += loss * batch_size\n",
        "                epoch_size += batch_size\n",
        "                if batch % batch_display_interval == batch_display_interval - 1: \n",
        "                    print('    (%s) Batch: %d, loss: %.4f' %(time_since(start), batch + 1, loss))\n",
        "                batch += 1\n",
        "                if end_epoch:\n",
        "                    break\n",
        "            epoch_loss /= epoch_size\n",
        "            if epoch % epoch_display_interval == epoch_display_interval - 1: \n",
        "                print('(%s) Epoch: %d, loss: %.4f' %(time_since(start), epoch + 1, epoch_loss))\n",
        "            if epoch_loss < best_net_loss:\n",
        "                best_net_loss = epoch_loss\n",
        "                self.best_net_dict = get_net_dict(self.net)\n",
        "            if epoch % ckpt_interval == ckpt_interval - 1: \n",
        "                self.save_model((epoch+1) / ckpt_interval)\n",
        "            \n",
        "    def data_generator(self, X, batch_size, **kwargs):\n",
        "        return \n",
        "\n",
        "    def save_model(self, serial=None):\n",
        "        path = Path(self.ckpt_fname_gen.write_fname(serial))\n",
        "        print(\"Saving to: \" , path)\n",
        "        check_create_parent(path)\n",
        "        torch.save(self.net, path)\n",
        "\n",
        "    def load_model(self, serial=None):\n",
        "        path = self.ckpt_fname_gen.read_fname(serial)\n",
        "        print(\"Loading from: \" , path)\n",
        "        self.net = torch.load(path, map_location=self.device)\n",
        "\n",
        "    def mode(self, training=True):\n",
        "        self.training = training\n",
        "        self.net.train(training)\n",
        "\n",
        "\n",
        "class W2VSkipGramModel(BaseModel):\n",
        "    def __init__(self, window=10, drop_prob=0, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        # text transformer\n",
        "        self.drop_prob = drop_prob\n",
        "        self.vocab_skip_gram_transformer = VocabSkipGramTransformer(window, drop_prob)\n",
        "\n",
        "    def data_generator(self, X, batch_size, **kwargs):\n",
        "        # Fit vocab only if training\n",
        "        if self.training:\n",
        "            self.fit_transformer(X)\n",
        "        datagen = self.vocab_skip_gram_transformer.generator(X, batch_size=batch_size, **kwargs)\n",
        "        while True:\n",
        "            X_batch, y_batch, end_epoch = next(datagen)\n",
        "            X_batch = torch.from_numpy(X_batch)\n",
        "            y_batch = torch.from_numpy(y_batch)\n",
        "            yield X_batch, y_batch, end_epoch\n",
        "\n",
        "    def predict(self, X, topk=1, cardinal=False):\n",
        "        with torch.no_grad():\n",
        "            output = self.net.forward(X)\n",
        "            args = torch.argsort(output, dim=1, descending=True).numpy()[:, :topk]\n",
        "            if cardinal:\n",
        "                return args\n",
        "            # single token list\n",
        "            token_list = np.array(self.vocab_skip_gram_transformer.get_token_list())\n",
        "            token_lists = np.repeat(token_list[None,...], args.shape[0], axis=0)\n",
        "            return np.take_along_axis(token_lists, args, axis=1)\n",
        "\n",
        "    def lookup(self, X):\n",
        "        with torch.no_grad():\n",
        "            return self.net.embedding_layer(X)\n",
        "\n",
        "    def mode(self, training=True):\n",
        "        super().mode(training)\n",
        "        if not self.training:\n",
        "            self.vocab_skip_gram_transformer.drop_prob = 0\n",
        "        else:\n",
        "            self.vocab_skip_gram_transformer.drop_prob = self.drop_prob\n",
        "    \n",
        "    def fit_transformer(self, X):\n",
        "        self.vocab_skip_gram_transformer.fit(X)\n",
        "\n",
        "\n",
        "class W2VSkipGramNet(nn.Module):\n",
        "    def __init__(self, num_embeddings, embedding_dim):\n",
        "        super().__init__()\n",
        "        # linear embedding\n",
        "        self.embedding_layer = nn.Embedding(num_embeddings, embedding_dim)\n",
        "        # linear mapping\n",
        "        self.forward_layer = nn.Linear(embedding_dim, num_embeddings, bias=False)\n",
        "\n",
        "    def forward(self, X):\n",
        "        # forward pass\n",
        "        X = self.embedding_layer(X)\n",
        "        X = self.forward_layer(X)\n",
        "        return X\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "device is  cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZiCbqdxA4lgV",
        "colab_type": "code",
        "outputId": "a2d92028-65fb-46bd-ce3e-c37fcaf1727a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "test_w2v_fname_gen = FileNameGenerator(drive_path/\"test_w2v/model\")\n",
        "test_data = np.array(range(20)).reshape(1, -1).tolist()\n",
        "print(test_data)\n",
        "test_w2v_net = W2VSkipGramNet(20, 2)\n",
        "optimizer = Adam(test_w2v_net.parameters())\n",
        "test_model = W2VSkipGramModel(2, 0, test_w2v_net, optimizer, test_w2v_fname_gen, device)\n",
        "datagen = test_model.data_generator(test_data, batch_size=2)\n",
        "next(datagen), next(datagen), next(datagen), next(datagen), next(datagen), next(datagen), next(datagen), next(datagen)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((tensor([16, 13]), tensor([15, 14]), False),\n",
              " (tensor([18,  0]), tensor([16,  1]), False),\n",
              " (tensor([8, 2]), tensor([10,  0]), False),\n",
              " (tensor([19, 17]), tensor([18, 15]), False),\n",
              " (tensor([17, 17]), tensor([19, 18]), False),\n",
              " (tensor([ 8, 11]), tensor([9, 9]), False),\n",
              " (tensor([9, 3]), tensor([10,  4]), False),\n",
              " (tensor([1, 3]), tensor([3, 5]), False))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 321
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s--xRYKFg71C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.manifold import TSNE\n",
        "\n",
        "\n",
        "def plot_annotate(x, y, labels, ax=None):\n",
        "    for i in range(len(x)):\n",
        "        plt.scatter(x[i], y[i])\n",
        "        plt.annotate(labels[i],\n",
        "                    xy=(x[i], y[i]),\n",
        "                    xytext=(5, 2),\n",
        "                    textcoords='offset points',\n",
        "                    ha='right',\n",
        "                    va='bottom')\n",
        "\n",
        "def plot_tsne_embedding(embedding, labels):\n",
        "    embedding_data = embedding.weight.detach().numpy()\n",
        "    tsne = TSNE()\n",
        "    tsne_embedding = tsne.fit_transform(embedding_data).tolist()\n",
        "    plot_annotate(*list(zip(*tsne_embedding)), labels)\n",
        "    plt.show()\n",
        "    return tsne_embedding, embedding_data, tsne"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7eDG7Zb7Sju",
        "colab_type": "code",
        "outputId": "358a1435-3646-4ab8-b1ac-5b17f208dfca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        }
      },
      "source": [
        "_X = torch.from_numpy(np.array(range(10))).to(device)\n",
        "# Before\n",
        "vocab_list = test_model.vocab_skip_gram_transformer.get_token_list()\n",
        "# plot_tsne_embedding(test_model.net.embedding_layer, vocab_list)\n",
        "plot_annotate(*list(zip(*test_model.net.embedding_layer.weight.detach().numpy())), vocab_list)\n",
        "plt.show()\n",
        "print(test_model.predict(_X, -1))\n",
        "test_model.train(test_data, 1000, 2, batch_display_interval=0, \n",
        "                 epoch_display_interval=100, ckpt_interval=500,\n",
        "                 data_gen_dict={})\n",
        "# After\n",
        "test_model.load_model()\n",
        "# Overfit the small dataset\n",
        "# plot_tsne_embedding(test_model.net.embedding_layer, vocab_list)\n",
        "plot_annotate(*list(zip(*test_model.net.embedding_layer.weight.detach().numpy())), vocab_list)\n",
        "plt.show()\n",
        "print(test_model.predict(_X, topk=-1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-3072685e8e85>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0m_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# Before\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mvocab_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_skip_gram_transformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_token_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# plot_tsne_embedding(test_model.net.embedding_layer, vocab_list)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplot_annotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wG_rbQxPHsWk",
        "colab_type": "code",
        "outputId": "8d8812d9-8346-4aeb-b41e-4fac856e93ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# profile step time\n",
        "sgt = VocabSkipGramTransformer().fit(tokens_train)\n",
        "num_embeddings = len(sgt.get_token_list())\n",
        "\n",
        "test_w2v_fname_gen = FileNameGenerator(drive_path/\"test_w2v/model\")\n",
        "test_w2v_net = W2VSkipGramNet(num_embeddings, 64)\n",
        "optimizer = Adam(test_w2v_net.parameters())\n",
        "test_model = W2VSkipGramModel(5, 0.5, test_w2v_net, optimizer, test_w2v_fname_gen)\n",
        "\n",
        "datagen = test_model.data_generator(test_data, batch_size=1024)\n",
        "\n",
        "X_batch, y_batch, _ = next(datagen)\n",
        "X_batch = X_batch.to(device)\n",
        "y_batch = y_batch.to(device)\n",
        "%timeit -n 10 test_model.train_step(X_batch, y_batch)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10 loops, best of 3: 37.4 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNys5HOdISK-",
        "colab_type": "text"
      },
      "source": [
        "### 2.1.3. Train Word Embeddings Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0DdvEHVokpL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Setup\n",
        "sgt = VocabCardinalTransformer().fit(tokens_train)\n",
        "num_embeddings = len(sgt.token_list)\n",
        "embedding_dim = 64\n",
        "window = 5\n",
        "\n",
        "w2vnet = W2VSkipGramNet(num_embeddings, embedding_dim)\n",
        "w2v_fname_gen = FileNameGenerator(drive_path/\"w2v/model\")\n",
        "optimizer = Adam(w2vnet.parameters())\n",
        "w2vmodel = W2VSkipGramModel(window, 0, w2vnet, optimizer, w2v_fname_gen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ae8i7Z2kIef-",
        "colab_type": "code",
        "outputId": "4ecabef2-1643-41ed-f37d-5ecb94ee6d13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666
        }
      },
      "source": [
        "w2vmodel.train(tokens_train, 50, batch_size=1024, batch_display_interval=5000,\n",
        "               epoch_display_interval=1, ckpt_interval=1, \n",
        "               data_gen_dict={})"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving to:  /content/drive/My Drive/COMP5046-assignment1/w2v/model0.pt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type W2VSkipGramNet. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "    (36m 26s) Batch: 5000, loss: 7.9750\n",
            "    (73m 4s) Batch: 10000, loss: 7.8274\n",
            "    (105m 56s) Batch: 15000, loss: 7.9352\n",
            "    (138m 11s) Batch: 20000, loss: 7.7522\n",
            "    (170m 26s) Batch: 25000, loss: 7.7320\n",
            "(195m 41s) Epoch: 1, loss: 8.1061\n",
            "Saving to:  /content/drive/My Drive/COMP5046-assignment1/w2v/model1.pt\n",
            "    (202m 44s) Batch: 30000, loss: 8.0123\n",
            "    (235m 16s) Batch: 35000, loss: 8.3887\n",
            "    (267m 44s) Batch: 40000, loss: 8.0347\n",
            "    (301m 4s) Batch: 45000, loss: 7.3844\n",
            "    (333m 38s) Batch: 50000, loss: 8.1320\n",
            "    (366m 19s) Batch: 55000, loss: 8.1483\n",
            "(384m 49s) Epoch: 2, loss: 7.9899\n",
            "Saving to:  /content/drive/My Drive/COMP5046-assignment1/w2v/model2.pt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-215-26eef41801a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m w2vmodel.train(tokens_train, 50, batch_size=1024, batch_display_interval=5000,\n\u001b[1;32m      2\u001b[0m                \u001b[0mepoch_display_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                data_gen_dict={})\n\u001b[0m",
            "\u001b[0;32m<ipython-input-209-5a00df1f9f1f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, data, epochs, batch_size, data_gen_dict, batch_display_interval, epoch_display_interval, ckpt_interval)\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m                 \u001b[0;31m# Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m                 \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m                 \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m                 \u001b[0mepoch_size\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-209-5a00df1f9f1f>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, X_batch, y_batch)\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;31m# forward + backward + optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    914\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0;32m--> 916\u001b[0;31m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[0m\u001b[1;32m    917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2019\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2020\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2021\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2023\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlog_softmax\u001b[0;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[1;32m   1315\u001b[0m         \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_softmax_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'log_softmax'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1317\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMCv3YI1IfUo",
        "colab_type": "text"
      },
      "source": [
        "### 2.1.4. Save Word Embeddings Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LwsGbOFBQsZ",
        "colab_type": "code",
        "outputId": "2b4c5136-d318-4899-ad6b-9194e8a1d146",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "w2vmodel.save_model()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving to:  /content/drive/My Drive/COMP5046-assignment1/w2v/model0.pt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type W2VSkipGramNet. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yn16xrDrIs8B",
        "colab_type": "text"
      },
      "source": [
        "### 2.1.5. Load Word Embeddings Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IebpYFsIvgh",
        "colab_type": "code",
        "outputId": "87a6727a-08c0-4999-a1a1-7436f8233cbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "w2v_fname_gen = FileNameGenerator(drive_path/\"w2v/model\")\n",
        "w2vmodel_load = W2VSkipGramModel(window, 0, None, optimizer, w2v_fname_gen)\n",
        "w2vmodel_load.load_model()\n",
        "w2vmodel_load.fit_transformer(tokens_train)\n",
        "w2vmodel_load.mode(False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading from:  /content/drive/My Drive/COMP5046-assignment1/w2v/model2.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78H-1y-HchBM",
        "colab_type": "code",
        "outputId": "b0795ca5-e03b-4501-af1d-52d08e2c0ac0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25350, 64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 297
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-cNxWVBTcz-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "T0ap96aeGlIk"
      },
      "source": [
        "## 2.2. Character Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "d16v3oKaGlI0"
      },
      "source": [
        "### 2.2.1. Data Preprocessing for Character Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AKbLnN-3GlI1"
      },
      "source": [
        "*You are required to describe which preprocessing techniques were used with justification of your decision.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "i2CUCL1cGlI2",
        "colab": {}
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "\n",
        "class VocabCharacterTransformer(VocabCardinalTransformer):\n",
        "    \"\"\"\n",
        "    Transformer class to convert raw list of list of tokens to data for character embeddig model\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.character_list = []\n",
        "        self.character_dict = {}\n",
        "\n",
        "    def fit(self, X, y=None, **fit_params):\n",
        "        super().fit(X, y, **fit_params)\n",
        "        refit = fit_params.get(\"refit\", False)\n",
        "        character_set = set()\n",
        "        for token in self.token_list:\n",
        "            character_set |= set(token)\n",
        "        if refit:\n",
        "            self.character_list = sorted(character_set)\n",
        "        else:\n",
        "            # get new characters\n",
        "            character_set -= set(self.character_list)\n",
        "            self.character_list += sorted(character_set)\n",
        "        self.character_dict = {w: i for i, w in enumerate(self.character_list)}\n",
        "        return self\n",
        "\n",
        "    def transform(self, X, y=None, include_token=True):\n",
        "        \"\"\"\n",
        "        Transforms a given dataset (list of list of tokens) to character embedding model data\n",
        "        :param X: The input data\n",
        "        :param y: Ignored\n",
        "        :return: One array of cardinal characters and one array of cardinal tokens\n",
        "        \"\"\"\n",
        "        # Only keep the tokens fitted before\n",
        "        token_list = [token for tokens in X for token in tokens]\n",
        "        # Transform to characters/tokens\n",
        "        characters_list = []\n",
        "        max_len = max([len(token) for token in token_list])\n",
        "\n",
        "        # TODO: Should add checking and throw error if character not found\n",
        "        for token in token_list:\n",
        "            characters_list.append([self.character_dict[c] for c in token])\n",
        "        \n",
        "        if include_token:\n",
        "            cardinal_token_list = [self.token_dict[token] for token in token_list \n",
        "                                   if token in self.token_dict]\n",
        "            return characters_list, cardinal_token_list\n",
        "        return characters_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNu7LLBF4oRL",
        "colab_type": "code",
        "outputId": "9760978f-f2fc-41e9-ea98-0f48010e6462",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# Test embed transformer\n",
        "test_data = [tokens_train[0][:5], tokens_train[1][:3]]\n",
        "print(test_data)\n",
        "cet = VocabCharacterTransformer().fit(test_data)\n",
        "cet.transform(test_data)\n",
        "# It works"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['enjoyed', 'movie', 'not', 'seen', 'andy'], ['whole', 'not', 'even']]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([[2, 8, 5, 9, 14, 2, 1],\n",
              "  [7, 9, 12, 4, 2],\n",
              "  [8, 9, 11],\n",
              "  [10, 2, 2, 8],\n",
              "  [0, 8, 1, 14],\n",
              "  [13, 3, 9, 6, 2],\n",
              "  [8, 9, 11],\n",
              "  [2, 12, 2, 8]],\n",
              " [1, 3, 4, 5, 0, 6, 4, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zgiOPcsTGlI6"
      },
      "source": [
        "### 2.2.2. Build Character Embeddings Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4NtqFFcjGlI7"
      },
      "source": [
        "*You are required to describe how hyperparameters were decided with justification of your decision.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jj3YZ3PWGlI8",
        "colab": {}
      },
      "source": [
        "from torch.nn import functional as f\n",
        "from torch.nn.utils.rnn import pack_sequence\n",
        "\n",
        "def mysorted(seq, key=None, reverse=False):\n",
        "    idxs, seq = list(zip(*sorted(enumerate(seq), key=lambda x: key(x[1]), reverse=reverse)))\n",
        "    return seq, list(idxs)\n",
        "\n",
        "class CharacterEmbedModel(BaseModel):\n",
        "    def __init__(self, embedding, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.vocab_character_transformer = VocabCharacterTransformer()\n",
        "        self.__loss = nn.MSELoss()\n",
        "        self.loss = self._loss\n",
        "        # embedding for words (freeze the layer to prevent update)\n",
        "        self.embedding = copy.deepcopy(embedding)\n",
        "        if embedding:\n",
        "            # Embedding stored on cpu for easier access\n",
        "            embedding.to(torch.device(self.device))\n",
        "            for param in self.embedding.parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "    def _loss(self, input, target):\n",
        "        target = self.embedding(target)\n",
        "        return self.__loss(input, target)\n",
        "\n",
        "    def data_generator(self, X, batch_size):\n",
        "        if self.training:\n",
        "            self.fit_transformer(X)\n",
        "        X, y = self.vocab_character_transformer.transform(X)\n",
        "        batch_per_epoch = math.ceil(len(y)//batch_size)\n",
        "        while True:\n",
        "            shuffle(X)\n",
        "            shuffle(y)\n",
        "            for m in range(batch_per_epoch):\n",
        "                X_batch = X[m * batch_size : (m + 1) * batch_size]\n",
        "                y_batch = y[m * batch_size : (m + 1) * batch_size]\n",
        "                X_batch, y_batch = self.process_batch(X_batch, y_batch)\n",
        "                end_epoch = False\n",
        "                if m == batch_per_epoch - 1: end_epoch = True \n",
        "                yield X_batch, y_batch, end_epoch\n",
        "\n",
        "    def predict(self, X):\n",
        "        X = [X]\n",
        "        X, y = self.vocab_character_transformer.transform(X)\n",
        "        X, y = self.process_batch(X, y)\n",
        "        X = X.to(device)\n",
        "        with torch.no_grad():\n",
        "            return self.net.forward(X)\n",
        "\n",
        "    def get_embedding(self, X):\n",
        "        X = [X]\n",
        "        X, y = self.vocab_character_transformer.transform(X)\n",
        "        X, y = self.process_batch(X, y)\n",
        "        y = y.to(device)\n",
        "        return self.embedding(y)\n",
        "\n",
        "    def process_batch(self, X, y=None):\n",
        "        # Sort by length and convert to tensor\n",
        "        X, idxs = mysorted([torch.from_numpy(np.array(x)) for x in X], \n",
        "                                    key=lambda x:len(x), reverse=True)\n",
        "        # Change to one hot encoding and word vector\n",
        "        X = pack_sequence([f.one_hot(seq, num_classes=\n",
        "                                     len(self.vocab_character_transformer\n",
        "                                         .character_list)).float() \n",
        "                                         for seq in X])\n",
        "        if y is not None:\n",
        "            y = torch.from_numpy(np.array(y)[idxs])\n",
        "        return X, y\n",
        "\n",
        "    def fit_transformer(self, X):\n",
        "        self.vocab_character_transformer.fit(X)\n",
        "\n",
        "\n",
        "class CharacterEmbedNet(nn.Module):\n",
        "    def __init__(self, n_input, hidden_size, dropout=0, num_layers=1):\n",
        "        super().__init__()\n",
        "        self.n_input = n_input\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        \n",
        "        # LSTM\n",
        "        self.lstm = nn.LSTM(self.n_input, self.hidden_size, self.num_layers, \n",
        "                            bidirectional=True, dropout=dropout)\n",
        "\n",
        "    def forward(self, X):\n",
        "        # h_n of shape (num_layers * num_directions, batch, hidden_size): \n",
        "        #     tensor containing the hidden state for t = seq_len.\n",
        "        lstm_out, (h_n, c_n) = self.lstm(X)\n",
        "        # concat the last hidden state from two direction\n",
        "        h_n = h_n.view(self.num_layers, 2, -1, self.hidden_size)\n",
        "        out = torch.cat((h_n[-1,0,:,:],h_n[-1,1,:,:]),1)\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bu95_tXs3Pwl",
        "colab_type": "code",
        "outputId": "d0fa6c66-eac3-4fe0-f3de-d08a4e78f3b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "source": [
        "test_data = [tokens_train[0][:5], tokens_train[1][:3]]\n",
        "cet = VocabCharacterTransformer().fit(test_data)\n",
        "embedding = nn.Embedding(len(cet.token_list), 8)\n",
        "test_char_net = CharacterEmbedNet(len(cet.character_list), 4)\n",
        "test_char_fname_gen = FileNameGenerator(drive_path/\"test_char/model\")\n",
        "optimizer = torch.optim.Adam(test_char_net.parameters(), lr=0.00001)\n",
        "cem = CharacterEmbedModel(embedding, test_char_net, optimizer, test_char_fname_gen, device)\n",
        "datagen = cem.data_generator(test_data, 5)\n",
        "next(datagen)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(PackedSequence(data=tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), batch_sizes=tensor([5, 5, 5, 4, 1, 1, 1]), sorted_indices=None, unsorted_indices=None),\n",
              " tensor([4, 4, 2, 6, 1]),\n",
              " True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 196
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HJ9uT34Fz6LY",
        "colab": {}
      },
      "source": [
        "test_sample_pred = cem.predict(['enjoyed', 'movie', 'not', 'seen', 'andy'])\n",
        "test_sample_y = cem.get_embedding(['enjoyed', 'movie', 'not', 'seen', 'andy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "15252718-10f5-4119-d482-ef2610429a79",
        "id": "33j-vz8iz6La",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "test_sample_pred - test_sample_y"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.8197,  1.0607, -0.8532, -1.3545, -2.1701,  1.1993, -1.1948,  0.2102],\n",
              "        [ 1.2042, -0.2256, -0.2702,  0.2083, -0.0103,  0.3242, -0.7454, -0.1567],\n",
              "        [-0.5731, -0.9531, -0.3410, -0.9688,  0.6995, -2.1276, -0.8299, -0.6764],\n",
              "        [ 1.8439, -1.0896,  0.4704, -0.8555,  1.5944, -0.7583,  0.4001,  1.2402],\n",
              "        [-1.3861, -0.8515,  0.4253,  0.4684,  0.7077, -1.9317,  1.2157, -0.4260]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 198
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muXKeTGE4T6a",
        "colab_type": "code",
        "outputId": "5b5d08ef-2f0b-4fac-edcd-8e1bfa6f0c48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "cem.train(test_data, 20, 1, {}, 1, 1, ckpt_interval=5000)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving to:  /content/drive/My Drive/COMP5046-assignment1/test_char/model0.pt\n",
            "    (0m 0s) Batch: 1, loss: 1.1992\n",
            "    (0m 0s) Batch: 2, loss: 0.2822\n",
            "    (0m 0s) Batch: 3, loss: 1.1121\n",
            "    (0m 0s) Batch: 4, loss: 0.9332\n",
            "    (0m 0s) Batch: 5, loss: 0.9596\n",
            "    (0m 0s) Batch: 6, loss: 1.3630\n",
            "    (0m 0s) Batch: 7, loss: 0.3663\n",
            "    (0m 0s) Batch: 8, loss: 0.9276\n",
            "(0m 0s) Epoch: 1, loss: 0.8929\n",
            "    (0m 0s) Batch: 9, loss: 0.9332\n",
            "    (0m 0s) Batch: 10, loss: 0.9544\n",
            "    (0m 0s) Batch: 11, loss: 1.1121\n",
            "    (0m 0s) Batch: 12, loss: 1.1162\n",
            "    (0m 0s) Batch: 13, loss: 0.4124\n",
            "    (0m 0s) Batch: 14, loss: 1.1991\n",
            "    (0m 0s) Batch: 15, loss: 1.3630\n",
            "    (0m 0s) Batch: 16, loss: 0.3587\n",
            "(0m 0s) Epoch: 2, loss: 0.9311\n",
            "    (0m 0s) Batch: 17, loss: 1.0671\n",
            "    (0m 0s) Batch: 18, loss: 0.9275\n",
            "    (0m 0s) Batch: 19, loss: 1.0724\n",
            "    (0m 0s) Batch: 20, loss: 1.0570\n",
            "    (0m 0s) Batch: 21, loss: 1.2433\n",
            "    (0m 0s) Batch: 22, loss: 0.3651\n",
            "    (0m 0s) Batch: 23, loss: 0.2881\n",
            "    (0m 0s) Batch: 24, loss: 1.2652\n",
            "(0m 0s) Epoch: 3, loss: 0.9107\n",
            "    (0m 0s) Batch: 25, loss: 0.3399\n",
            "    (0m 0s) Batch: 26, loss: 0.4518\n",
            "    (0m 0s) Batch: 27, loss: 0.9274\n",
            "    (0m 0s) Batch: 28, loss: 0.9595\n",
            "    (0m 0s) Batch: 29, loss: 1.4071\n",
            "    (0m 0s) Batch: 30, loss: 1.0804\n",
            "    (0m 0s) Batch: 31, loss: 1.1161\n",
            "    (0m 0s) Batch: 32, loss: 1.1970\n",
            "(0m 0s) Epoch: 4, loss: 0.9349\n",
            "    (0m 0s) Batch: 33, loss: 1.0434\n",
            "    (0m 0s) Batch: 34, loss: 1.5612\n",
            "    (0m 0s) Batch: 35, loss: 1.0199\n",
            "    (0m 0s) Batch: 36, loss: 0.9098\n",
            "    (0m 0s) Batch: 37, loss: 1.2937\n",
            "    (0m 0s) Batch: 38, loss: 0.9571\n",
            "    (0m 0s) Batch: 39, loss: 0.4518\n",
            "    (0m 0s) Batch: 40, loss: 0.2822\n",
            "(0m 0s) Epoch: 5, loss: 0.9399\n",
            "    (0m 0s) Batch: 41, loss: 1.1019\n",
            "    (0m 0s) Batch: 42, loss: 1.2433\n",
            "    (0m 0s) Batch: 43, loss: 0.3543\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type CharacterEmbedNet. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "    (0m 0s) Batch: 44, loss: 0.9273\n",
            "    (0m 0s) Batch: 45, loss: 0.9816\n",
            "    (0m 0s) Batch: 46, loss: 0.9544\n",
            "    (0m 0s) Batch: 47, loss: 0.3857\n",
            "    (0m 0s) Batch: 48, loss: 1.2653\n",
            "(0m 0s) Epoch: 6, loss: 0.9017\n",
            "    (0m 0s) Batch: 49, loss: 1.0548\n",
            "    (0m 0s) Batch: 50, loss: 1.2936\n",
            "    (0m 0s) Batch: 51, loss: 0.3857\n",
            "    (0m 0s) Batch: 52, loss: 1.4983\n",
            "    (0m 0s) Batch: 53, loss: 0.2822\n",
            "    (0m 0s) Batch: 54, loss: 0.9097\n",
            "    (0m 0s) Batch: 55, loss: 1.0433\n",
            "    (0m 0s) Batch: 56, loss: 1.0048\n",
            "(0m 0s) Epoch: 7, loss: 0.9340\n",
            "    (0m 0s) Batch: 57, loss: 1.0433\n",
            "    (0m 0s) Batch: 58, loss: 1.3631\n",
            "    (0m 0s) Batch: 59, loss: 0.2822\n",
            "    (0m 0s) Batch: 60, loss: 1.1160\n",
            "    (0m 0s) Batch: 61, loss: 1.0624\n",
            "    (0m 0s) Batch: 62, loss: 0.3942\n",
            "    (0m 0s) Batch: 63, loss: 1.0196\n",
            "    (0m 0s) Batch: 64, loss: 1.2936\n",
            "(0m 0s) Epoch: 8, loss: 0.9468\n",
            "    (0m 0s) Batch: 65, loss: 0.3942\n",
            "    (0m 0s) Batch: 66, loss: 0.9096\n",
            "    (0m 0s) Batch: 67, loss: 1.1018\n",
            "    (0m 0s) Batch: 68, loss: 1.3631\n",
            "    (0m 0s) Batch: 69, loss: 1.0195\n",
            "    (0m 0s) Batch: 70, loss: 1.2432\n",
            "    (0m 0s) Batch: 71, loss: 0.2823\n",
            "    (0m 0s) Batch: 72, loss: 0.9543\n",
            "(0m 0s) Epoch: 9, loss: 0.9085\n",
            "    (0m 0s) Batch: 73, loss: 0.3662\n",
            "    (0m 0s) Batch: 74, loss: 0.9271\n",
            "    (0m 0s) Batch: 75, loss: 1.0800\n",
            "    (0m 0s) Batch: 76, loss: 0.9095\n",
            "    (0m 0s) Batch: 77, loss: 1.2432\n",
            "    (0m 0s) Batch: 78, loss: 1.3539\n",
            "    (0m 0s) Batch: 79, loss: 1.0670\n",
            "    (0m 0s) Batch: 80, loss: 0.2823\n",
            "(0m 0s) Epoch: 10, loss: 0.9036\n",
            "    (0m 0s) Batch: 81, loss: 1.2432\n",
            "    (0m 0s) Batch: 82, loss: 0.3649\n",
            "    (0m 0s) Batch: 83, loss: 0.9570\n",
            "    (0m 0s) Batch: 84, loss: 1.4984\n",
            "    (0m 0s) Batch: 85, loss: 1.0718\n",
            "    (0m 0s) Batch: 86, loss: 0.2823\n",
            "    (0m 0s) Batch: 87, loss: 1.0431\n",
            "    (0m 0s) Batch: 88, loss: 0.9328\n",
            "(0m 0s) Epoch: 11, loss: 0.9242\n",
            "    (0m 0s) Batch: 89, loss: 0.9270\n",
            "    (0m 0s) Batch: 90, loss: 1.2431\n",
            "    (0m 0s) Batch: 91, loss: 1.4073\n",
            "    (0m 0s) Batch: 92, loss: 0.4123\n",
            "    (0m 0s) Batch: 93, loss: 1.0624\n",
            "    (0m 0s) Batch: 94, loss: 0.2823\n",
            "    (0m 0s) Batch: 95, loss: 0.9328\n",
            "    (0m 0s) Batch: 96, loss: 1.0798\n",
            "(0m 0s) Epoch: 12, loss: 0.9184\n",
            "    (0m 0s) Batch: 97, loss: 1.0624\n",
            "    (0m 0s) Batch: 98, loss: 1.2431\n",
            "    (0m 0s) Batch: 99, loss: 1.4985\n",
            "    (0m 0s) Batch: 100, loss: 1.1016\n",
            "    (0m 0s) Batch: 101, loss: 1.0073\n",
            "    (0m 0s) Batch: 102, loss: 0.2823\n",
            "    (0m 0s) Batch: 103, loss: 0.3941\n",
            "    (0m 0s) Batch: 104, loss: 1.0566\n",
            "(0m 0s) Epoch: 13, loss: 0.9557\n",
            "    (0m 0s) Batch: 105, loss: 1.2654\n",
            "    (0m 0s) Batch: 106, loss: 1.0543\n",
            "    (0m 0s) Batch: 107, loss: 0.3401\n",
            "    (0m 0s) Batch: 108, loss: 1.2431\n",
            "    (0m 0s) Batch: 109, loss: 0.3661\n",
            "    (0m 0s) Batch: 110, loss: 1.0566\n",
            "    (0m 0s) Batch: 111, loss: 0.9594\n",
            "    (0m 0s) Batch: 112, loss: 0.9269\n",
            "(0m 0s) Epoch: 14, loss: 0.9015\n",
            "    (0m 0s) Batch: 113, loss: 0.9093\n",
            "    (0m 0s) Batch: 114, loss: 1.2844\n",
            "    (0m 0s) Batch: 115, loss: 0.4517\n",
            "    (0m 0s) Batch: 116, loss: 0.2823\n",
            "    (0m 0s) Batch: 117, loss: 0.9543\n",
            "    (0m 0s) Batch: 118, loss: 1.0715\n",
            "    (0m 0s) Batch: 119, loss: 0.9326\n",
            "    (0m 0s) Batch: 120, loss: 1.4985\n",
            "(0m 0s) Epoch: 15, loss: 0.9231\n",
            "    (0m 0s) Batch: 121, loss: 1.0669\n",
            "    (0m 0s) Batch: 122, loss: 1.2652\n",
            "    (0m 0s) Batch: 123, loss: 1.3632\n",
            "    (0m 0s) Batch: 124, loss: 0.4122\n",
            "    (0m 0s) Batch: 125, loss: 1.1157\n",
            "    (0m 0s) Batch: 126, loss: 1.1112\n",
            "    (0m 0s) Batch: 127, loss: 0.9092\n",
            "    (0m 0s) Batch: 128, loss: 0.3588\n",
            "(0m 0s) Epoch: 16, loss: 0.9503\n",
            "    (0m 0s) Batch: 129, loss: 1.5614\n",
            "    (0m 0s) Batch: 130, loss: 1.0623\n",
            "    (0m 0s) Batch: 131, loss: 1.1156\n",
            "    (0m 0s) Batch: 132, loss: 1.1111\n",
            "    (0m 0s) Batch: 133, loss: 0.3141\n",
            "    (0m 0s) Batch: 134, loss: 0.3825\n",
            "    (0m 0s) Batch: 135, loss: 1.1014\n",
            "    (0m 0s) Batch: 136, loss: 1.2651\n",
            "(0m 0s) Epoch: 17, loss: 0.9892\n",
            "    (0m 0s) Batch: 137, loss: 0.9594\n",
            "    (0m 0s) Batch: 138, loss: 0.3940\n",
            "    (0m 0s) Batch: 139, loss: 1.1156\n",
            "    (0m 0s) Batch: 140, loss: 0.2884\n",
            "    (0m 0s) Batch: 141, loss: 1.2843\n",
            "    (0m 0s) Batch: 142, loss: 0.9807\n",
            "    (0m 0s) Batch: 143, loss: 1.2655\n",
            "    (0m 0s) Batch: 144, loss: 0.9267\n",
            "(0m 0s) Epoch: 18, loss: 0.9018\n",
            "    (0m 0s) Batch: 145, loss: 0.9569\n",
            "    (0m 0s) Batch: 146, loss: 0.3544\n",
            "    (0m 0s) Batch: 147, loss: 0.9267\n",
            "    (0m 0s) Batch: 148, loss: 1.1109\n",
            "    (0m 0s) Batch: 149, loss: 1.2651\n",
            "    (0m 0s) Batch: 150, loss: 1.2655\n",
            "    (0m 0s) Batch: 151, loss: 1.1013\n",
            "    (0m 0s) Batch: 152, loss: 0.3647\n",
            "(0m 0s) Epoch: 19, loss: 0.9182\n",
            "    (0m 0s) Batch: 153, loss: 1.0564\n",
            "    (0m 0s) Batch: 154, loss: 1.4986\n",
            "    (0m 0s) Batch: 155, loss: 0.3939\n",
            "    (0m 0s) Batch: 156, loss: 1.0048\n",
            "    (0m 0s) Batch: 157, loss: 1.1013\n",
            "    (0m 0s) Batch: 158, loss: 1.2650\n",
            "    (0m 0s) Batch: 159, loss: 1.1109\n",
            "    (0m 0s) Batch: 160, loss: 0.3401\n",
            "(0m 0s) Epoch: 20, loss: 0.9714\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmQzIWbQqXf2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_sample_pred = cem.predict(['enjoyed', 'movie', 'not', 'seen', 'andy'])\n",
        "test_sample_y = cem.get_embedding(['enjoyed', 'movie', 'not', 'seen', 'andy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FibhaH-uyp2L",
        "colab_type": "code",
        "outputId": "a56b6aed-059f-4249-92af-d3d831ec1a74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "test_sample_pred - test_sample_y"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.6880,  0.3759, -1.7318,  0.6074],\n",
              "        [ 0.5791, -1.7351,  0.5999,  1.2882],\n",
              "        [-0.8290,  0.6785, -0.7636, -1.3389],\n",
              "        [ 0.6997, -2.4482,  1.4950,  0.8189],\n",
              "        [ 0.1052,  1.0683,  0.5024, -0.3471]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "46W0zFfWGlI_"
      },
      "source": [
        "### 2.1.4. Train Character Embeddings Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UWQn-VyNGlJA",
        "colab": {}
      },
      "source": [
        "cet = VocabCharacterTransformer().fit(tokens_train)\n",
        "embedding = w2vmodel_load.net.embedding_layer\n",
        "\n",
        "char_net = CharacterEmbedNet(len(cet.character_list), embedding.embedding_dim//2)\n",
        "char_fname_gen = FileNameGenerator(drive_path/\"char/model\")\n",
        "optimizer = torch.optim.Adam(char_net.parameters())\n",
        "\n",
        "char_model = CharacterEmbedModel(embedding, char_net, optimizer, char_fname_gen, device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jwQU73bVjh_",
        "colab_type": "code",
        "outputId": "512936d8-bfba-4c56-ada5-6a73fb4664ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "sample_data = tokens_train[1]\n",
        "char_model.fit_transformer(tokens_train)\n",
        "print(\"====================\")\n",
        "sample_y = char_model.get_embedding(sample_data)\n",
        "print(sample_y)\n",
        "sample_preds = []\n",
        "for i in range(10):\n",
        "    char_model.train(tokens_train, 1, batch_display_interval=5000, epoch_display_interval=1)\n",
        "    sample_pred = char_model.predict(sample_data)\n",
        "    sample_preds.append(sample_pred)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "====================\n",
            "tensor([[-0.8035, -0.1558,  0.3829,  ..., -0.9517, -0.0875,  0.6368],\n",
            "        [-0.5078,  0.8483, -1.2538,  ..., -0.2390,  1.0600, -0.7308],\n",
            "        [-0.1757, -0.5183,  0.1043,  ..., -0.3448,  0.7336, -0.0575],\n",
            "        ...,\n",
            "        [-1.8242,  0.5258,  0.7257,  ...,  0.7602,  0.4065, -0.8558],\n",
            "        [ 0.1176, -0.3256, -0.6180,  ..., -0.3130, -0.6201, -0.7858],\n",
            "        [ 0.1176, -0.3256, -0.6180,  ..., -0.3130, -0.6201, -0.7858]])\n",
            "Saving to:  /content/drive/My Drive/COMP5046-assignment1/char/model0.pt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type CharacterEmbedNet. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(7m 3s) Epoch: 1, loss: 0.8437\n",
            "Saving to:  /content/drive/My Drive/COMP5046-assignment1/char/model1.pt\n",
            "--------------------\n",
            "tensor([[ 0.0296,  0.0087,  0.0176,  ...,  0.0428,  0.1125, -0.0877],\n",
            "        [ 0.0318,  0.0101,  0.0128,  ...,  0.0373,  0.1028, -0.0805],\n",
            "        [ 0.0259,  0.0080,  0.0100,  ...,  0.0424,  0.1124, -0.0842],\n",
            "        ...,\n",
            "        [ 0.0285,  0.0102,  0.0092,  ...,  0.0411,  0.1085, -0.0834],\n",
            "        [ 0.0364,  0.0070,  0.0061,  ...,  0.0403,  0.1081, -0.0742],\n",
            "        [ 0.0364,  0.0070,  0.0061,  ...,  0.0403,  0.1081, -0.0742]])\n",
            "tensor([[ 0.8331,  0.1645, -0.3653,  ...,  0.9946,  0.2000, -0.7245],\n",
            "        [ 0.5396, -0.8382,  1.2666,  ...,  0.2763, -0.9572,  0.6503],\n",
            "        [ 0.2016,  0.5263, -0.0943,  ...,  0.3872, -0.6212, -0.0267],\n",
            "        ...,\n",
            "        [ 1.8527, -0.5156, -0.7165,  ..., -0.7191, -0.2980,  0.7724],\n",
            "        [-0.0812,  0.3326,  0.6241,  ...,  0.3533,  0.7282,  0.7116],\n",
            "        [-0.0812,  0.3326,  0.6241,  ...,  0.3533,  0.7282,  0.7116]])\n",
            "tensor(0.8409)\n",
            "Saving to:  /content/drive/My Drive/COMP5046-assignment1/char/model0.pt\n",
            "(6m 40s) Epoch: 1, loss: 0.8437\n",
            "Saving to:  /content/drive/My Drive/COMP5046-assignment1/char/model1.pt\n",
            "--------------------\n",
            "tensor([[ 0.0419,  0.0092,  0.0189,  ...,  0.0451,  0.1082, -0.0874],\n",
            "        [ 0.0421,  0.0097,  0.0171,  ...,  0.0453,  0.1114, -0.0832],\n",
            "        [ 0.0431,  0.0117,  0.0136,  ...,  0.0449,  0.1076, -0.0852],\n",
            "        ...,\n",
            "        [ 0.0479,  0.0100,  0.0170,  ...,  0.0509,  0.1059, -0.0766],\n",
            "        [ 0.0334,  0.0132,  0.0130,  ...,  0.0481,  0.1105, -0.0823],\n",
            "        [ 0.0334,  0.0132,  0.0130,  ...,  0.0481,  0.1105, -0.0823]])\n",
            "tensor([[ 0.8454,  0.1650, -0.3640,  ...,  0.9968,  0.1957, -0.7242],\n",
            "        [ 0.5499, -0.8387,  1.2709,  ...,  0.2843, -0.9485,  0.6477],\n",
            "        [ 0.2188,  0.5300, -0.0906,  ...,  0.3897, -0.6259, -0.0277],\n",
            "        ...,\n",
            "        [ 1.8721, -0.5158, -0.7087,  ..., -0.7093, -0.3006,  0.7792],\n",
            "        [-0.0842,  0.3388,  0.6309,  ...,  0.3611,  0.7306,  0.7035],\n",
            "        [-0.0842,  0.3388,  0.6309,  ...,  0.3611,  0.7306,  0.7035]])\n",
            "tensor(0.8407)\n",
            "Saving to:  /content/drive/My Drive/COMP5046-assignment1/char/model0.pt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-154-76d26db89b07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0msample_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mchar_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_display_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_display_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0msample_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchar_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"--------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-103-5e5a66712ea3>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, data, epochs, batch_size, data_gen_dict, batch_display_interval, epoch_display_interval, ckpt_interval)\u001b[0m\n\u001b[1;32m    118\u001b[0m                 \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0;31m# Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m                 \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m                 \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m                 \u001b[0mepoch_size\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-103-5e5a66712ea3>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, X_batch, y_batch)\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;31m#print(\"--------------------\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "R5Bym9bBGlJE"
      },
      "source": [
        "### 2.1.5. Save Character Embeddings Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ggTsYIm7GlJF",
        "colab": {}
      },
      "source": [
        "char_model.save_model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JwOI-wIKGlJI"
      },
      "source": [
        "### 2.1.6. Load Character Embeddings Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-jyj-lOHWWj",
        "colab_type": "code",
        "outputId": "e15b4e3d-791c-4363-9689-1c32abcbae96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        }
      },
      "source": [
        "char_fname_gen = FileNameGenerator(drive_path/\"char/model\")\n",
        "char_model_load = CharacterEmbedModel(embedding, None, optimizer, char_fname_gen)\n",
        "char_model_load.load_model()\n",
        "char_model.fit_transformer(tokens_train)\n",
        "char_model_load.mode(False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-302-dd79a3ac95c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mchar_fname_gen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFileNameGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrive_path\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m\"char/model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mchar_model_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCharacterEmbedModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchar_fname_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mchar_model_load\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mchar_model_load\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'CharacterEmbedModel' object has no attribute 'load'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlCeWT8eeLnd",
        "colab_type": "text"
      },
      "source": [
        "## 2.3. Sequence model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwA-NN3EJ4Ig",
        "colab_type": "text"
      },
      "source": [
        "### 2.3.1. Apply/Import Word Embedding and Character Embedding Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UAMJrxx-iOVn",
        "colab_type": "text"
      },
      "source": [
        "*You are required to describe how hyperparameters were decided with justification of your decision.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7PKX1gIePA2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Please comment your code"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpYCL17JKZxl",
        "colab_type": "text"
      },
      "source": [
        "### 2.3.2. Build Sequence Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R204UIyDKhZ4",
        "colab_type": "text"
      },
      "source": [
        "*You are required to describe how hyperparameters were decided with justification of your decision.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13eCtR_SLUG6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Please comment your code"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BaOiaGRLW7R",
        "colab_type": "text"
      },
      "source": [
        "### 2.3.3. Train Sequence Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVQnUSX1LZ6C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Please comment your code"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2feNpG-LZx2",
        "colab_type": "text"
      },
      "source": [
        "### 2.3.4. Save Sequence Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sflUAgV4L1o8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Please comment your code"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zFo6YppL6w3",
        "colab_type": "text"
      },
      "source": [
        "### 2.3.5. Load Sequence Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtNxLzDGMCan",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Please comment your code"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4mpRpocePLN",
        "colab_type": "text"
      },
      "source": [
        "# 3 - Evaluation\n",
        "\n",
        "(*Please show your empirical evidence*)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEW1zMgVMREr",
        "colab_type": "text"
      },
      "source": [
        "## 3.1. Performance Evaluation\n",
        "\n",
        "\n",
        "You are required to provide the table with precision, recall, f1 of test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPHCb-bneTI9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Please comment your code"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P28Z1k36MZuo",
        "colab_type": "text"
      },
      "source": [
        "## 3.2. Hyperparameter Testing\n",
        "*You are required to draw a graph(y-axis: f1, x-axis: epoch) for test set and explain the optimal number of epochs based on the learning rate you have already chosen.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTLyQEeZMZ2f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Please comment your code"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfv8rWTKPzeb",
        "colab_type": "text"
      },
      "source": [
        "## Object Oriented Programming codes here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TS23AjBRSZaX",
        "colab_type": "text"
      },
      "source": [
        "*You can use multiple code snippets. Just add more if needed* "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1hVmx4E52dXS",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.base import TransformerMixin\n",
        "\n",
        "import copy\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "import contractions\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords as sw\n",
        "from nltk import FreqDist\n",
        "\n",
        "# These words affect the reasoning of the sentence\n",
        "negative_words = set([\"no\", \"nor\", \"not\", \"but\"])\n",
        "stop_words = set(sw.words()) - negative_words\n",
        "# Lemmatise the words\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "\n",
        "def remove_punctuation(x):\n",
        "    \"\"\"\n",
        "    Remove all non white space or word character in function x\n",
        "    :param x: The sentence to process\n",
        "    :return: str with all non white space or word character removed\n",
        "    \"\"\"\n",
        "    x = re.sub(r'[^\\w\\s]',' ',x)\n",
        "    return x\n",
        "\n",
        "def convert_numbers(x):\n",
        "    \"\"\"\n",
        "    Convert numbers to number token\n",
        "    :param x: The sentence to process\n",
        "    :return: str with all numbers converted accordingly\n",
        "    \"\"\"\n",
        "    # Replace digit of different length with corresponding token\n",
        "    x = re.sub(r'[0-9]{5,}', '<4+NUM>', x)\n",
        "    x = re.sub(r'[0-9]{4}', '<4NUM>', x)\n",
        "    x = re.sub(r'[0-9]{3}', '<3NUM>', x)\n",
        "    x = re.sub(r'[0-9]{2}', '<2NUM>', x)\n",
        "    # Remove fraction symbols (and other other category symbol)\n",
        "    x = re.sub(r'[½¾]', '', x)\n",
        "    return x\n",
        "\n",
        "def preprocess_texts(X, rm_htmltag=True, expand_contraction=True, to_lower=True, rm_punctuation=True,\n",
        "                     cv_numbers=True, stop_words=stop_words, lemmatize=True, min_count=5):\n",
        "    \"\"\"\n",
        "    Preprocess texts with the specified preprocessing procedures\n",
        "    :param X: A list of texts to be processed\n",
        "    :param rm_htmltag: If html tags should be removed\n",
        "    :param expand_contraction: If contraction should be expanded\n",
        "    :param to_lower: If cases should be converted to lower case\n",
        "    :param rm_punctuation: If punctuation should be removed\n",
        "    :param lemmatize: If tokens should be lemmatized\n",
        "    :return: list[list[processed token]]\n",
        "    \"\"\"\n",
        "    if rm_htmltag:\n",
        "        # Use beautiful soup to remove html tags if any\n",
        "        X = [BeautifulSoup(s).get_text() for s in X]\n",
        "\n",
        "    if expand_contraction:\n",
        "        # expand contactions (english only) to normalise text (this before lower case because this will give uppercase)\n",
        "        X = [contractions.fix(s) for s in X]\n",
        "\n",
        "    if to_lower:\n",
        "        # Case folding is necessary to reduce the unique words and removing some irregular case formulation for words.\n",
        "        # Though this may cause the loss of some information (for instance, all CAPPED words have strong emotion),\n",
        "        # it is generally beneficial to smooth the occurances of words\n",
        "        X = [s.lower() for s in X]\n",
        "\n",
        "    if rm_punctuation:\n",
        "        # Remove punctuations is necessary for almost the same reason as the case folding. Here because each tweet is self\n",
        "        # contained, no need to add end of sentence token.\n",
        "        X = [remove_punctuation(s) for s in X]\n",
        "\n",
        "    if cv_numbers:\n",
        "        X = [convert_numbers(s) for s in X]\n",
        "\n",
        "    # Tokenization is necessary to extract each individual words instead of feeding in raw sentences.\n",
        "    X = [word_tokenize(sent) for sent in X]\n",
        "\n",
        "    # Stop words are NOT removed (yet) for they sometimes affect the sentiment by a lot (like word not, wouldn't)\n",
        "    # If I can get better list and spend more time understanding the data then I will remove them\n",
        "    if stop_words is not False and len(stop_words):\n",
        "        X = [[w for w in tokens if not w in stop_words] for tokens in X]\n",
        "\n",
        "    if lemmatize:\n",
        "        # Lemmatise tokens to reduce the number of unique words, and make the training process easier by reducing the labels\n",
        "        X = [[lemmatizer.lemmatize(w) for w in tokens] for tokens in X]\n",
        "    \n",
        "    if min_count > 1:\n",
        "        all_tokens = [w for tokens in X for w in tokens]\n",
        "        token_set = set(k for k, v in FreqDist(all_tokens).items() if v >= min_count)\n",
        "        X = [[w for w in tokens if w in token_set] for tokens in X]\n",
        "\n",
        "    return X\n",
        "\n",
        "\n",
        "class TextPreprocessTransformer(TransformerMixin):\n",
        "    \"\"\"\n",
        "    Simple transformer class to wrap the previous transformation\n",
        "    \"\"\"\n",
        "    def __init__(self, **kwargs):\n",
        "        self.kwargs = kwargs\n",
        "\n",
        "    def fit(self, X, y=None, **fit_params):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X, y=None):\n",
        "        return preprocess_texts(X, **self.kwargs)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}